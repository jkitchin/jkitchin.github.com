---
title: Using autograd to plot implicit functions
date: 2019/10/02 21:30:46
updated: 2019/10/02 21:30:46
categories: autograd, nonlinear-algebra, implicit-function
tags: 
---


<p>
Consider the solution to these equations (adapted from <a href="https://www.mathworks.com/help/optim/ug/fsolve.html">https://www.mathworks.com/help/optim/ug/fsolve.html</a>):
</p>

<p>
\(e^{-e^{-(x_1 + x_2)}} = x_2 (1 + x_1^2)\)
</p>

<p>
and
</p>

<p>
\(x_1 \cos(x_2) + x_2 \sin(x_1) = 1/2\)
</p>

<p>
It is not clear how many solutions there are to this set of equations, or what you should guess for the initial guess. Usually, the best way to see where a solution might be is to plot the equations and see where they intersect. These equations are implicit though, and it is not easy to plot them because we cannot solve for \(x_2\) in terms of \(x_1\) in either case. Here we explore a strategy to get plots so we can see where solutions could be.
</p>

<p>
The idea is that we find one solution to each equation independently. Then, we derive a differential equation for each equation so we can integrate it to find the curve that is defined by the implicit function.  First, we find a solution for each equation. We guess a value for \(x_2\) and then find the value of \(x_1\) that solves each equation independently.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">import</span> autograd.numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">from</span> scipy.optimize <span style="color: #0000FF;">import</span> fsolve

<span style="color: #0000FF;">def</span> <span style="color: #006699;">f1</span>(x1, x2):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> np.exp(-np.exp(-(x1 + x2))) - x2 * (1 + x1**2)

<span style="color: #0000FF;">def</span> <span style="color: #006699;">f2</span>(x1, x2):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> x1 * np.cos(x2) + x2 * np.sin(x1) - 0.5

<span style="color: #BA36A5;">x2_1</span> = 0.6
x1_1, = fsolve(f1, 0, args=(x2_1,))
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'f1: '</span>, x1_1, x2_1)

<span style="color: #BA36A5;">x2_2</span> = 1.0
x1_2, = fsolve(f2, 0 ,args=(x2_2,))
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'f2: '</span>, x1_2, x2_2)
</pre>
</div>

<p>
f1:  0.08638978040861575 0.6
f2:  0.32842406163614396 1.0
</p>

<p>
Next, we need a differential equation that is \(dx_2/dx_1\). If we had that, we could just integrate it from one of the starting points above, and get the curve we want. The functions are implicit, so we have to use the implicit derivative, which for the first equation is \(dx_2/dx_1 = -df1/dx_1 / df1/dx_2\). We will get these gradients from autograd. Then, we just integrate the solution. Here we do this for the first equation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">from</span> scipy.integrate <span style="color: #0000FF;">import</span> solve_ivp
<span style="color: #0000FF;">from</span> autograd <span style="color: #0000FF;">import</span> grad

<span style="color: #BA36A5;">df1dx1</span> = grad(f1, 0)
<span style="color: #BA36A5;">df1dx2</span> = grad(f1, 1)

<span style="color: #0000FF;">def</span> <span style="color: #006699;">dx2dx1_1</span>(x1, x2):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> -df1dx1(x1, x2) / df1dx2(x1, x2)

<span style="color: #BA36A5;">x1_span</span> = (x1_1, 1)
<span style="color: #BA36A5;">x2_0</span> = (x2_1, )
<span style="color: #BA36A5;">sol1</span> = solve_ivp(dx2dx1_1, x1_span, x2_0, max_step=0.1)
</pre>
</div>

<p>
And then, we do it for the second equation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #BA36A5;">df2dx1</span> = grad(f2, 0)
<span style="color: #BA36A5;">df2dx2</span> = grad(f2, 1)

<span style="color: #0000FF;">def</span> <span style="color: #006699;">dx2dx1_2</span>(x1, x2):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> -df2dx1(x1, x2) / df2dx2(x1, x2)

<span style="color: #BA36A5;">x1_span</span> = (x1_2, 1)
<span style="color: #BA36A5;">x2_0</span> = (x2_2, )
<span style="color: #BA36A5;">sol2</span> = solve_ivp(dx2dx1_2, x1_span, x2_0, max_step=0.1)
</pre>
</div>

<p>
Finally, we plot the two solutions.
</p>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
<span style="color: #0000FF;">import</span> matplotlib.pyplot <span style="color: #0000FF;">as</span> plt
plt.plot(sol1.t, sol1.y.T)
plt.plot(sol2.t, sol2.y.T)
plt.xlabel(<span style="color: #008000;">'$x_1$'</span>)
plt.ylabel(<span style="color: #008000;">'$x_2$'</span>)
plt.legend([<span style="color: #008000;">'f1'</span>, <span style="color: #008000;">'f2'</span>])
</pre>
</div>

<pre class="example">
&lt;Figure size 432x288 with 1 Axes&gt;
</pre>


<p>
<figure><img src="/media/b770a79094dc5fa34b51ebeed23401d697cc0f01.png"></figure> 
</p>

<p>
You can see now that in this range, there is only one intersection, i.e. one solution, and it is near \(x_1=0.4, x_2=0.6\). We can finally use that as an initial guess to find the only solution in this region, with confidence we are not missing any solutions.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">def</span> <span style="color: #006699;">objective</span>(X):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">x1</span>, <span style="color: #BA36A5;">x2</span> = X
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> [f1(x1, x2), f2(x1, x2)]

fsolve(objective, [0.4, 0.6])
</pre>
</div>

<pre class="example">
array([0.35324662, 0.60608174])
</pre>

<p>
That is the same solution as reported at the Matlab site. Another use of autograd for the win here.
</p>
<p>Copyright (C) 2019 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2019/10/02/Using-autograd-to-plot-implicit-functions.org">org-mode source</a></p>
<p>Org-mode version = 9.2.3</p>