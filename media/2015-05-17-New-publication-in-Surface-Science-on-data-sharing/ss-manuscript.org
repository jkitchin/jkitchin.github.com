#+LATEX_CLASS: elsarticle
#+LATEX_CLASS_OPTIONS: [number, sort&compress, review, 12pt]
#+EXPORT_EXCLUDE_TAGS: noexport
#+OPTIONS: toc:nil ^:{} author:nil

#+latex_header: \usepackage[utf8]{inputenc}
#+latex_header: \usepackage{fixltx2e}
#+latex_header: \usepackage{url}
#+latex_header: \usepackage[version=3]{mhchem}
#+latex_header: \usepackage{graphicx}
#+latex_header: \usepackage{tcolorbox}
#+latex_header: \usepackage{color}
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{textcomp}
#+latex_header: \usepackage{wasysym}
#+latex_header: \usepackage{latexsym}
#+latex_header: \usepackage{amssymb}
#+LATEX_HEADER: \usepackage[linktocpage,
#+LATEX_HEADER:   pdfstartview=FitH,
#+LATEX_HEADER:   colorlinks,
#+LATEX_HEADER:   linkcolor=blue,
#+LATEX_HEADER:   anchorcolor=blue,
#+LATEX_HEADER:   citecolor=blue,
#+LATEX_HEADER:   filecolor=blue,
#+LATEX_HEADER:   menucolor=blue,
#+LATEX_HEADER:   urlcolor=blue]{hyperref}
#+latex_header: \usepackage{attachfile}
#+latex_header: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usemintedstyle{emacs}
#+LATEX_HEADER: \newminted{python}{fontsize=\footnotesize}

\begin{frontmatter}
\title{Data sharing in Surface Science}
\author[cmu]{John R. Kitchin\corref{cor}}
\ead{jkitchin@andrew.cmu.edu}
\address[cmu]{Department of Chemical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213}
\cortext[cor]{Corresponding author}

\begin{abstract}
Surface Science has an editorial policy that atomic positions that are determined in a publication (experimental and computational) be made accessible to its readers. In this Prospective, we suggest an even broader need in data and methodology sharing. We illustrate an approach we have used to embed experimental and computational data as well as code in manuscripts and supporting information files, and we show how it results in reusable data and code.
\end{abstract}
\end{frontmatter}

* Introduction
In 2010, there was a letter from the editor of Surface Science reminding us of the editorial policy "that all the atomic positions be made accessible to the reader" cite:campbell-2010-cryst-part1. As part of that letter, a Prospective was written advocating for the use of the CIF format cite:marks-2010, followed by another Prospective identifying the need for further options and highlighting the difficulty in mandating a single standard data format cite:hove-2010,campbell-2010-cryst-part2. Since then the need for data sharing has grown well beyond the needs of sharing atomic positions. Federal agencies are now requiring data sharing plans (NSF cite:foundation-nsf-data, NIH cite:health-nih-data, DOE cite:energy-statem-digit).

In this Prospective, we discuss a new approach to data sharing that we have been using in our publications. In this approach, the data is human readable, and machine addressable, and embedded in the supporting information of the manuscripts. On one hand, the PDFs of the manuscript and supporting information files are indistinguishable from other published works. These files are meant to be read by people interested in the ideas they contain. On the other hand, a machine (computer) can extract and reuse the embedded data and code from the supporting information file. We will illustrate how this works by examples from the supporting information of a recent paper we published in Surface Science cite:boes-2015-core-cu. The supporting information can be downloaded [[http://www.sciencedirect.com/science/MiamiMultiMediaURL/1-s2.0-S0039602815000461/1-s2.0-S0039602815000461-mmc1.pdf/271619/FULL/S0039602815000461/105c81e66b1391dade1d439c4afec4bb/mmc1.pdf][here]]. We have renamed the file to supporting-information.pdf in the following discussion.


* Using embedded data from the supporting information
The data is embedded in the supporting information PDF in two files: supporting-information.org and data.json. The files appear in the PDF as a thumbtack, which can be double-clicked to open the file in pdf readers that support attachments. Not all PDF viewers support attachments. Alternatively, these files can be unpacked from the PDF using pdftk, a command-line toolkit for PDF files cite:labs-pdftk. This is shown in Listing ref:lst-unpack where a shell command is shown that extracts these files. In some cases, a command-line utility may be required. For example, some pdf readers will not allow one to unpack a zip-file for security reasons.

#+caption: Shell command to extract the attached files from a supporting-information.pdf file. label:lst-unpack
#+BEGIN_SRC sh :results silent
pdftk supporting-information.pdf unpack_files
#+END_SRC

** Using the JSON data file

JSON is a Javascript Object Notation structured data format that is in plain text. The JSON file was generated in this example using the Atomic Simulation Environment cite:ase database module as described in the supporting information of Ref. citenum:boes-2015-core-cu. In Listing ref:lst-json we print the first few entries in the database. One might use an approach like this to see what is in the database, or to identify an interesting calculation in the database. The metadata (i.e. data about the data that explains what it is) for this JSON file is the associated manuscript and supporting information file. We use Python cite:python,millman-2011-python-scien-engin,perkel-2015-progr in this example, because the ASE database module provides a convenient interface to use. It is important to note that any language that reads JSON can be used for this purpose. JSON can even be viewed in a web browser, e.g. by uploading the file to https://www.jsoneditoronline.org. A very astute reader will note the code in Listing ref:lst-json is not the same as the code described in the supporting information file. The ASE database changed from the time we prepared that supporting information file to the time we prepared this Prospective, one can no longer search by keywords the way we did in the supporting information file. This only affects how specific results are obtained. There is a lesson here, and that is that data formats evolve. A second lesson is that this does not have to destroy data, or make it unusable; we use exactly the same data from the supporting information file. It is still in JSON form, and can be read independently of the ASE database.

#+caption: Python script to list the first five entries and their keywords in the data.json database. label:lst-json
#+BEGIN_SRC python
from ase.db import connect

db = connect('data.json')

# Select a specific entry in the database
for i, entry in enumerate(db.select()):
    print(entry['id'], entry['keywords'])
    if i==4: break
#+END_SRC

#+RESULTS:
: (1, [u'fcc', u'GS', u'72atom', u'1cl', u'0.88Cu'])
: (2, [u'fcc', u'GS', u'72atom', u'1cl', u'0.75Cu'])
: (3, [u'fcc', u'GS', u'72atom', u'1cl', u'0.62Cu'])
: (4, [u'fcc', u'GS', u'72atom', u'1cl', u'0.50Cu'])
: (5, [u'fcc', u'GS', u'72atom', u'1cl', u'0.38Cu'])

From this information, and the details in the supporting information file, one can identify specific calculations to retrieve information about. To illustrate the utility of the ASE database, and ease that the data can be reused, in Listing ref:lst-cif we retrieve the atomic geometry for the entry with =id= of 4, and generate a CIF file for it, and in Listing ref:lst-cif-contents we show the first thirty lines of the newly created file.

#+caption: Python script to generate a CIF file from the ASE database. label:lst-cif
#+BEGIN_SRC python
from ase.db import connect
from ase.io import write
db = connect('data.json')

# Select a specific entry in the database
atoms = db.get_atoms(id=4)
write('atoms.cif', atoms)
#+END_SRC

#+caption: Shell script to view the first thirty lines of the atoms.cif file. label:lst-cif-contents
#+BEGIN_SRC sh
head -n 30 atoms.cif
#+END_SRC

#+RESULTS:
#+begin_example
data_image0
_cell_length_a       11.4973
_cell_length_b       8.62296
_cell_length_c       9.98795
_cell_angle_alpha    90
_cell_angle_beta     90
_cell_angle_gamma    90

_symmetry_space_group_name_H-M    P 1
_symmetry_int_tables_number       1

loop_
  _symmetry_equiv_pos_as_xyz
  'x, y, z'

loop_
  _atom_site_label
  _atom_site_occupancy
  _atom_site_fract_x
  _atom_site_fract_y
  _atom_site_fract_z
  _atom_site_thermal_displace_type
  _atom_site_B_iso_or_equiv
  _atom_site_type_symbol
  Pd1      1.0000 0.12500  0.16667  0.16667  Biso   1.000  Pd
  Cu1      1.0000 -0.00000  0.00000  -0.00000  Biso   1.000  Cu
  Cu2      1.0000 0.00000  0.00000  0.33333  Biso   1.000  Cu
  Cu3      1.0000 0.00000  0.00000  0.66667  Biso   1.000  Cu
  Cu4      1.0000 -0.00000  0.33333  -0.00000  Biso   1.000  Cu
  Cu5      1.0000 -0.00000  0.33333  0.33333  Biso   1.000  Cu
#+end_example

In the next code block (Listing ref:code-pars), we retrieve some of the data needed to recreate the DFT calculation in VASP with =id= of =4=. There are 72 atoms in this calculation, so we only print the first five positions for brevity.

#+CAPTION: Python script to extract computational parameters and results for the entry with id=4 from the JSON database. label:code-pars
#+BEGIN_SRC python
from ase.db import connect
from textwrap import fill
import numpy as np
np.set_printoptions(precision=3)

db = connect('data.json')

# Select a specific entry in the database
example = db.select(id=4)

# ASE database utilizes generator objects. To access the first,
# and only entry in this generator, we use '.next()'.
example = example.next()

# Specific information can be pulled from the database by
# specifying the appropriate sub-dictionary name. This is
# shown for the INCAR parameters:
print('The INCAR parameters:')
print(fill(str(example.calculator_parameters.incar)))

print('Other input')
print(fill(str(example.calculator_parameters.input)))
print('The unit cell')
print(example.cell)

print('\nThe Cartesian positions:')
for sym, pos in zip(example.symbols, example.positions)[0:5]:
    print('{0} [{1: 7.3f} {2: 7.3f} {3: 7.3f}]'.format(sym, *np.array(pos)))

print('The total energy: {0} eV'.format(example.energy))
#+END_SRC

#+RESULTS:
#+begin_example
The INCAR parameters:
{u'cll': 1, u'cln': 2, u'doc': u'INCAR parameters', u'prec':
u'Normal', u'nsim': 4, u'clnt': 0, u'nbands': 456, u'encut': 400.0,
u'clz': 1.0, u'ediff': 1e-06, u'icorelevel': 2, u'lplane': True,
u'npar': 4, u'ibrion': -1}
Other input
{u'kpts': array([4, 6, 4]), u'kpts_nintersections': None,
u'reciprocal': False, u'setups': {0: u'Cu'}, u'xc': u'PBE', u'txt':
u'-', u'gamma': False}
The unit cell
[[  0.000e+00  -8.130e+00   8.130e+00]
 [  0.000e+00   6.097e+00   6.097e+00]
 [ -9.988e+00   3.000e-16   0.000e+00]]

The Cartesian positions:
Pd [ -1.665  -0.000   2.032]
Cu [  0.000   0.000   0.000]
Cu [ -3.329   0.000   0.000]
Cu [ -6.659   0.000   0.000]
Cu [  0.000   2.032   2.032]
The total energy: -614.293938 eV
#+end_example

The critical point in this example is that a computer is able to extract the json file from the supporting information, then read the json file, and finally use the data. Through scripting, one could recreate the actual input files used by VASP to rerun calculations, or start new ones in a different code.

There are, of course, other options for the data format than the ASE database. In  Ref. citenum:mehta-2014-ident-poten we used a custom, fit-for-purpose json data format. In Ref.  citenum:curnan-2014-effec-concen we developed a fit-for-purpose database in comma-separated value (csv) files that was implemented in sqlite. In Ref.  citenum:hallenbeck-2013-effec-o2 we even embedded Excel spreadsheets in the supporting information. The computational materials repository  cite:landis-2012-comput-mater-repos offers an alternative XML-based format that data can be stored in. The important point is that the data is embedded in the supporting information files, and it is machine readable. Compared to our old approach of printing tables of these parameters in tabular form cite:inoglu-2011-ident-sulfur, this new approach is considerably more useful in our opinion.

** An alternative way to store data using org-mode

The previous example showed the use of data in a common, machine-readable data format. We next illustrate a different approach of embedding data within an org-mode document. org-mode is a plain text, lightweight markup language  cite:Dominik201408,schulte-2011-activ-docum,schulte-2012-multi-languag.  org-mode enables the deep integration of narrative scientific text, figures, tables, equations, citations, data and interactive code. An org-file can be exported to a variety of formats including LaTeX and HTML, and others. These features make org-mode well-suited for creating scientific manuscripts. Data can be embedded in the exported LaTeX file using the attachfile package cite:pakin-attachfile.  This manuscript was prepared in org-mode, and exported to LaTeX.

Any editor can be used to create org-mode documents, but org-mode is most fully supported by the Emacs editor cite:emacs, which provides a rich set of functions to create, edit and interact with org-mode documents, as well as integration with code and the computer operating system. In our hands and in Emacs, org-mode documents are rich, functional documents that provide functional citations (e.g. they are clickable to access Web of Science citing or related articles and other resources), that contain interactive, executable code blocks, and that are first-class scientific documents due to a customized software environment we have developed cite:jmax. With this tool, we have written and published nine publications in a variety of journals over the past two years, and we continue to prepare manuscripts in this form cite:hallenbeck-2013-effec-o2,curnan-2014-effec-concen,miller-2014-simul-temper,xu-2014-probin-cover,xu-2014-relat,mehta-2014-ident-poten,xu-2015-relat,xu-2015-linear-respon,boes-2015-estim-bulk.

A table in org-mode is rendered as a regular table in LaTeX, but it also serves as a source of data. For example, there is a table labeled =gellman= in the supporting information which has the composition and experimentally measured core-level shift from the composition spread alloy film. Here (Listing ref:lst-cls), we read the data /directly/ from the org-file, print some of it, and plot it (Fig. ref:fig-cls).

#+caption: Python script to extract tabular data from supporting-information.org and plot it. label:lst-cls
#+name: py-exp
#+BEGIN_SRC python :var data=supporting-information.org:gellman
import numpy as np

DATA = np.array(data)[:,[0,1]]
print(DATA[0:5])

import matplotlib.pyplot as plt
from matplotlib.ticker import MultipleLocator, FormatStrFormatter

majorLocator   = MultipleLocator(0.2)

plt.figure(figsize=(3, 4))
plt.plot(DATA[:, 0], DATA[:, 1])
plt.xlabel('$x_{Pd}$')
plt.ylabel('CLS (eV)')
plt.tight_layout()

ax = plt.gca()
ax.xaxis.set_major_locator(majorLocator)

plt.savefig('cls.png', dpi=300)
plt.show()
#+END_SRC

#+RESULTS: py-exp
: [[ 0.0269813 -0.035    ]
:  [ 0.0297052 -0.043    ]
:  [ 0.0298903 -0.039    ]
:  [ 0.0306752 -0.031    ]
:  [ 0.0320379 -0.037    ]]



#+caption: Cu Core-level shifts of a Cu-Pd alloy film as a function of the composition. label:fig-cls
[[./cls.png]]

The key point here is that the data was read by a computer from the supporting information file, and then reused to create a new figure. We have used this approach to embed both computational and experimental temperature programmed desorption data in supporting information cite:miller-2014-simul-temper, and experimental reactivity and segregation data cite:boes-2015-estim-bulk,boes-2015-estim-bulk-si. The approach is highly flexible, and can be used for a broad range of data.

It is not necessary for the code to appear in the exported manuscript. The export can be made selective, and we chose to show the code in this manuscript to illustrate how it is used. For supporting information files, we view it as an advantage that it is so easy to embed data, code and analysis in one document. We typically put the scripts that generate the figures in the supporting information file, which leaves a transparent record of what data went into a figure, and how the figure was made.

** Reusing code from manuscripts
When the org-file is opened in Emacs (that has been configured to enable this), the code blocks are actually executable. One can modify and rerun the code blocks, or easily copy them to new documents for new use. It is even possible to "call" a code block from another org-file, and insert the results into another org-file. Thus, in addition to being data repositories, org-files may also serve as code repositories.

org-mode also supports a practice known as literate programming cite:knuth-1992-liter-progr. In this approach, narrative text and source code are intermingled. Utility functions exist to "tangle" out the source code into a code-only file. We used this approach, for example, in Ref. citenum:boes-2015-estim-bulk, where a python library can be extracted from the supporting information file for use in analysis. This is a prototype example of machine-readable code-sharing through the supporting information of a manuscript.

** Large datasets and code bases

Some data sets and code bases are too large to conveniently store in supporting information files. There are a growing number of options for this situation. For example, in Ref. citenum:xu-2015-linear-respon  we wanted to share about 1.8 GB of raw computational results. This was achieved using Zenodo cite:zenodo-zenod to create a citable data set cite:xu-suppor, from a GitHUB repository cite:github. This could also have been achieved using an institutional data repository. Others have addressed this through centralized databases cite:jain-2013-mater-projec,nomad-repos, or customized institutional repositories cite:comput-mater-repos. It is still an open question of these resources survive into the future, but in the near term they can provide access to this data. We have a lot of confidence that data embedded in published manuscripts will be available for a very long time.


* Conclusions
In this Prospective we have presented a new approach to a long-standing need in the community related to data and methodology sharing. We illustrated an approach to embedding both experimental and computational data and code into manuscripts and supporting information. In the approach we leverage existing capabilities of existing document formats (PDF) that support attachments. The attachments can be ordinary data files which can be extracted and used like ordinary data files. This is an approach that any author can use today. Access to data does not make it useful though; most data needs context around it, and examples of how it was used. Manuscripts and their supporting information files can and should provide that context.

org-mode provides an interesting alternative data sharing approach that augments existing capabilities. org-mode is a different approach to using LaTeX or MS Word for manuscript preparation. It is not just a new way to write a paper though. org-mode enables the integration of interactive code and data in ways that are not currently possible in LaTeX and Word. org-mode facilitates data sharing by integrating data analysis into the manuscript preparation. When used consistently, there is little additional work to prepare the data for publication; it is already part of the completed work.

For certain, data sharing approaches will continue to evolve. org-mode is not perfect, but it has met all of our needs for the past several years. org-mode does not prevent mistakes from being made, nor does it enforce data sharing. This remains up to the authors to ensure the work is correct, and the relevant data is included. org-mode simply makes it easier to include data, and to write manuscripts that deeply integrate data and code with the science being reported. Our approach (and org-mode) has evolved significantly over the past two years, and both continue to improve. Some approaches will not turn out to be helpful, and they will fade into obscurity. The most useful approaches are likely to gain traction, even if adoption is slow. Improving the current sharing practices will take time for authors to learn new tools; the standard, existing tools, do not facilitate data sharing as described in this Prospective.


\section*{Acknowledgement}
JRK gratefully acknowledges support from the DOE Office of Science Early Career Research program (DE-SC0004031) under which most of this data sharing strategy was developed. We also acknowledge support from the Simon Initiative at Carnegie Mellon University, and the Phillip L. Dowd teaching fellowship for support.

bibliographystyle:elsarticle-num
bibliography:~/Dropbox/bibliography/references.bib

* build					:noexport:

#+BEGIN_SRC emacs-lisp
;; custom table format to list table name
(defun my-table-format (table contents info)
  (let ((tblname (org-element-property :name table))
        (results (car (org-element-property :results table))))

    (cond
     ((eq (elt (plist-get info :back-end) 2) 'latex)
      (concat
       (when tblname
         (format "TBLNAME: name=%s\\\\\n" tblname))
       (when results
         (format "Results From Listing: \\ref{%s}\\\\\n" results))
       (org-latex-table table contents info))))))

(setq org-latex-minted-options
           '(("frame" "lines")
             ("fontsize" "\\scriptsize")))

;; custom code block format to indicate input variables
(defun my-src-block (src-block contents info)
  (cond
   ((eq (elt (plist-get info :back-end) 2) 'latex)
    (concat
     "\\begin{tcolorbox}
"
     (format
      (concat
       (when (org-element-property :name src-block)
	 (format "src block name: %s\\\\" (org-element-property :name src-block)))
       "language: %s")
      (org-element-property :language src-block))
     (org-latex-src-block src-block contents info)
"
\\end{tcolorbox}"))))

;; custom exporter
(org-export-define-derived-backend 'my-latex 'latex
  :translate-alist '((src-block . my-src-block)
		     (table . my-table-format)))

(org-export-to-file 'my-latex "manuscript.tex" nil nil nil nil nil)
(ox-manuscript-latex-pdf-process "manuscript.tex")
(ox-manuscript-remove-image-extensions)
(ox-manuscript-bibliography-to-bbl)

(ox-manuscript-make-submission-archive)
#+END_SRC

#+RESULTS:



file:manuscript.pdf


#+BEGIN_SRC sh :results silent
latexdiff manuscript-submitted.tex manuscript.tex > revised-manuscript.tex

pdflatex -shell-escape revised-manuscript
pdflatex -shell-escape revised-manuscript
open revised-manuscript.pdf
#+END_SRC

#+RESULTS:
