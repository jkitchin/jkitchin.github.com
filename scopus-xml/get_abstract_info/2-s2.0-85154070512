<?xml version="1.0" encoding="UTF-8"?><abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85154070512</prism:url><dc:identifier>SCOPUS_ID:85154070512</dc:identifier><eid>2-s2.0-85154070512</eid><prism:doi>10.1038/s41524-023-01016-5</prism:doi><article-number>64</article-number><dc:title>TransPolymer: a Transformer-based language model for polymer property predictions</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>4</citedby-count><prism:publicationName>npj Computational Materials</prism:publicationName><dc:publisher>Nature Research</dc:publisher><source-id>21100850798</source-id><prism:issn>20573960</prism:issn><prism:volume>9</prism:volume><prism:issueIdentifier>1</prism:issueIdentifier><prism:coverDate>2023-12-01</prism:coverDate><openaccess>1</openaccess><openaccessFlag>true</openaccessFlag><dc:creator><author seq="1" auid="57885860600"><ce:initials>C.</ce:initials><ce:indexed-name>Xu C.</ce:indexed-name><ce:surname>Xu</ce:surname><ce:given-name>Changwen</ce:given-name><preferred-name><ce:initials>C.</ce:initials><ce:indexed-name>Xu C.</ce:indexed-name><ce:surname>Xu</ce:surname><ce:given-name>Changwen</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57885860600</author-url><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>Â© 2023, The Author(s).</publishercopyright><ce:para>Accurate and efficient prediction of polymer properties is of great significance in polymer design. Conventionally, expensive and time-consuming experiments or simulations are required to evaluate polymer functions. Recently, Transformer models, equipped with self-attention mechanisms, have exhibited superior performance in natural language processing. However, such methods have not been investigated in polymer sciences. Herein, we report TransPolymer, a Transformer-based language model for polymer property prediction. Our proposed polymer tokenizer with chemical awareness enables learning representations from polymer sequences. Rigorous experiments on ten polymer property prediction benchmarks demonstrate the superior performance of TransPolymer. Moreover, we show that TransPolymer benefits from pretraining on large unlabeled dataset via Masked Language Modeling. Experimental results further manifest the important role of self-attention in modeling polymer sequences. We highlight this model as a promising computational tool for promoting rational polymer design and understanding structure-property relationships from a data science view.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85154070512" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85154070512&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85154070512&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"><affilname>Carnegie Mellon University</affilname><affiliation-city>Pittsburgh</affiliation-city><affiliation-country>United States</affiliation-country></affiliation><authors><author seq="1" auid="57885860600"><ce:initials>C.</ce:initials><ce:indexed-name>Xu C.</ce:indexed-name><ce:surname>Xu</ce:surname><ce:given-name>Changwen</ce:given-name><preferred-name><ce:initials>C.</ce:initials><ce:indexed-name>Xu C.</ce:indexed-name><ce:surname>Xu</ce:surname><ce:given-name>Changwen</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57885860600</author-url><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/></author><author seq="2" auid="58523086500"><ce:initials>Y.</ce:initials><ce:indexed-name>Wang Y.</ce:indexed-name><ce:surname>Wang</ce:surname><ce:given-name>Yuyang</ce:given-name><preferred-name><ce:initials>Y.</ce:initials><ce:indexed-name>Wang Y.</ce:indexed-name><ce:surname>Wang</ce:surname><ce:given-name>Yuyang</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/58523086500</author-url><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/></author><author seq="3" auid="37067199500"><ce:initials>A.</ce:initials><ce:indexed-name>Barati Farimani A.</ce:indexed-name><ce:surname>Barati Farimani</ce:surname><ce:given-name>Amir</ce:given-name><preferred-name><ce:initials>A.</ce:initials><ce:indexed-name>Barati Farimani A.</ce:indexed-name><ce:surname>Barati Farimani</ce:surname><ce:given-name>Amir</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/37067199500</author-url><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/></author></authors></abstracts-retrieval-response>