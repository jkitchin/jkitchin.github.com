<?xml version="1.0" encoding="UTF-8"?><abstracts-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:dn="http://www.elsevier.com/xml/svapi/abstract/dtd" xmlns:ait="http://www.elsevier.com/xml/ani/ait" xmlns:ce="http://www.elsevier.com/xml/ani/common" xmlns:cto="http://www.elsevier.com/xml/cto/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/abstract/scopus_id/85094614441</prism:url><dc:identifier>SCOPUS_ID:85094614441</dc:identifier><eid>2-s2.0-85094614441</eid><pii>S0098135419313225</pii><prism:doi>10.1016/j.compchemeng.2020.107132</prism:doi><article-number>107132</article-number><dc:title>Active metric learning for supervised classification</dc:title><prism:aggregationType>Journal</prism:aggregationType><srctype>j</srctype><subtype>ar</subtype><subtypeDescription>Article</subtypeDescription><citedby-count>1</citedby-count><prism:publicationName>Computers and Chemical Engineering</prism:publicationName><dc:publisher>Elsevier Ltd</dc:publisher><source-id>24600</source-id><prism:issn>00981354</prism:issn><prism:volume>144</prism:volume><prism:coverDate>2021-01-04</prism:coverDate><openaccess>2</openaccess><openaccessFlag/><dc:creator><author seq="1" auid="7006922701"><ce:initials>K.</ce:initials><ce:indexed-name>Kumaran K.</ce:indexed-name><ce:surname>Kumaran</ce:surname><ce:given-name>Krishnan</ce:given-name><preferred-name><ce:initials>K.</ce:initials><ce:indexed-name>Kumaran K.</ce:indexed-name><ce:surname>Kumaran</ce:surname><ce:given-name>Krishnan</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7006922701</author-url><affiliation id="60021814" href="https://api.elsevier.com/content/affiliation/affiliation_id/60021814"/></author></dc:creator><dc:description><abstract xmlns="" original="y" xml:lang="eng"><publishercopyright>© 2020</publishercopyright><ce:para>Clustering and classification critically rely on distance metrics that provide meaningful comparisons between data points. To this end, learning optimal distance functions from data, known as metric learning, aims to facilitate supervised classification, particularly in high-dimensional spaces where visualization is challenging or infeasible. In particular, the Mahalanobis metric is the default choice due to simplicity and interpretability as a transformation of the simple Euclidean metric using a combination of rotation and scaling. In this work, we present several novel contributions to metric learning, both by way of formulation as well as solution methods. Our approach is motivated by agglomerative clustering with certain novel modifications that enable natural interpretation of the user-defined classes as clusters with the optimal metric. Our approach generalizes and improves upon leading methods by removing reliance on pre-designated “target neighbors,” “triplets,” and “similarity pairs.” Starting with the definition of a generalized metric that has the Mahalanobis metric as the second order term, we propose an objective function for metric selection that does not aim to isolate classes from each other like most previous work, but tries to distort the space minimally by aggregating co-class members into local clusters. Further, we formulate the problem as a mixed-integer optimization that can be solved efficiently for small/medium datasets and approximated for larger datasets. Another salient feature of our method is that it facilitates active learning by recommending precise regions to sample using the optimal metric to improve classification performance. These regions are indicated by boundary and outlier points of the dataset as defined by the metric. This targeted acquisition can significantly reduce computation and data acquisition by ensuring training data completeness, representativeness, and economy, which could also provide advantages in training data selection for other established methods like Deep Learning and Random Forests. We demonstrate classification and computational performance of our approach through several simple and intuitive examples, followed by results on real image and benchmark datasets.</ce:para></abstract></dc:description><link href="https://api.elsevier.com/content/abstract/scopus_id/85094614441" rel="self"/><link href="https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&amp;scp=85094614441&amp;origin=inward" rel="scopus"/><link href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&amp;scp=85094614441&amp;origin=inward" rel="scopus-citedby"/></coredata><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"><affilname>Carnegie Mellon University</affilname><affiliation-city>Pittsburgh</affiliation-city><affiliation-country>United States</affiliation-country></affiliation><affiliation id="60021814" href="https://api.elsevier.com/content/affiliation/affiliation_id/60021814"><affilname>Exxon Mobil Corporation</affilname><affiliation-city>Irving</affiliation-city><affiliation-country>United States</affiliation-country></affiliation><affiliation id="60000060" href="https://api.elsevier.com/content/affiliation/affiliation_id/60000060"><affilname>Lehigh University</affilname><affiliation-city>Bethlehem</affiliation-city><affiliation-country>United States</affiliation-country></affiliation><authors><author seq="1" auid="7006922701"><ce:initials>K.</ce:initials><ce:indexed-name>Kumaran K.</ce:indexed-name><ce:surname>Kumaran</ce:surname><ce:given-name>Krishnan</ce:given-name><preferred-name><ce:initials>K.</ce:initials><ce:indexed-name>Kumaran K.</ce:indexed-name><ce:surname>Kumaran</ce:surname><ce:given-name>Krishnan</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/7006922701</author-url><affiliation id="60021814" href="https://api.elsevier.com/content/affiliation/affiliation_id/60021814"/></author><author seq="2" auid="22941672700"><ce:initials>D.J.</ce:initials><ce:indexed-name>Papageorgiou D.J.</ce:indexed-name><ce:surname>Papageorgiou</ce:surname><ce:given-name>Dimitri J</ce:given-name><preferred-name><ce:initials>D.J.</ce:initials><ce:indexed-name>Papageorgiou D.J.</ce:indexed-name><ce:surname>Papageorgiou</ce:surname><ce:given-name>Dimitri J.</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/22941672700</author-url><affiliation id="60021814" href="https://api.elsevier.com/content/affiliation/affiliation_id/60021814"/></author><author seq="3" auid="57203176046"><ce:initials>M.</ce:initials><ce:indexed-name>Takac M.</ce:indexed-name><ce:surname>Takac</ce:surname><ce:given-name>Martin</ce:given-name><preferred-name><ce:initials>M.</ce:initials><ce:indexed-name>Takac M.</ce:indexed-name><ce:surname>Takac</ce:surname><ce:given-name>Martin</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57203176046</author-url><affiliation id="60000060" href="https://api.elsevier.com/content/affiliation/affiliation_id/60000060"/></author><author seq="4" auid="57219651218"><ce:initials>L.</ce:initials><ce:indexed-name>Lueg L.</ce:indexed-name><ce:surname>Lueg</ce:surname><ce:given-name>Laurens</ce:given-name><preferred-name><ce:initials>L.</ce:initials><ce:indexed-name>Lueg L.</ce:indexed-name><ce:surname>Lueg</ce:surname><ce:given-name>Laurens</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57219651218</author-url><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/></author><author seq="5" auid="57204102656"><ce:initials>N.V.</ce:initials><ce:indexed-name>Sahinidis N.V.</ce:indexed-name><ce:surname>Sahinidis</ce:surname><ce:given-name>Nicolas V</ce:given-name><preferred-name><ce:initials>N.V.</ce:initials><ce:indexed-name>Sahinidis N.V.</ce:indexed-name><ce:surname>Sahinidis</ce:surname><ce:given-name>Nicolas V.</ce:given-name></preferred-name><author-url>https://api.elsevier.com/content/author/author_id/57204102656</author-url><affiliation id="60027950" href="https://api.elsevier.com/content/affiliation/affiliation_id/60027950"/></author></authors></abstracts-retrieval-response>