<?xml version="1.0" encoding="UTF-8"?>

<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:wfw="http://wellformedweb.org/CommentAPI/"
     >
  <channel>
    <atom:link href="http://kitchingroup.cheme.cmu.edu/blog/feed/index.xml" rel="self" type="application/rss+xml" />
    <title>The Kitchin Research Group</title>
    <link>https://kitchingroup.cheme.cmu.edu/blog</link>
    <description>Chemical Engineering at Carnegie Mellon University</description>
    <pubDate>Tue, 28 Jan 2025 17:16:04 GMT</pubDate>
    <generator>Blogofile</generator>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    
    <item>
      <title>New publication - Structure Sensitive Reaction Kinetics of Chiral Molecules on Intrinsically Chiral Surfaces</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2025/01/27/New-publication-Structure-Sensitive-Reaction-Kinetics-of-Chiral-Molecules-on-Intrinsically-Chiral-Surfaces</link>
      <pubDate>Mon, 27 Jan 2025 20:42:00 EST</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">r8HkXBviG02EJdzRmvV58cLEJJc=</guid>
      <description>New publication - Structure Sensitive Reaction Kinetics of Chiral Molecules on Intrinsically Chiral Surfaces</description>
      <content:encoded><![CDATA[


&lt;p&gt;
We recently published this paper in The Journal of Physical Chemistry C exploring how the atomic structure of chiral copper surfaces influences the reaction kinetics of tartaric acid, a chiral molecule. Researchers developed two models—one using generalized coordination numbers (GCN) and another based on chiral cubic harmonic functions—to predict enantiospecificity, the ability of a surface to distinguish between two mirror-image molecules. Using curved copper surfaces, we measured reaction kinetics across hundreds of orientations and identified key surface structures that maximize enantiospecificity. The findings not only provide insights into the relationship between surface geometry and molecular interactions but also pave the way for designing highly selective catalysts, with potential applications in producing enantiopure pharmaceuticals and advancing green chemistry.
&lt;/p&gt;


&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;abdelmaqsoud-2024-struc-sensit&lt;/span&gt;,
  &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt; =       {Kareem Abdelmaqsoud and Michael Radetic and Carlos
                  Fern{\'a}ndez-Cab{\'a}n and Michael Widom and John R. Kitchin
                  and Andrew J. Gellman},
  &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt; =        {Structure Sensitive Reaction Kinetics of Chiral Molecules on
                  Intrinsically Chiral Surfaces},
  &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt; =      {The Journal of Physical Chemistry C},
  &lt;span style="color: #BA36A5;"&gt;volume&lt;/span&gt; =       {128},
  &lt;span style="color: #BA36A5;"&gt;number&lt;/span&gt; =       {33},
  &lt;span style="color: #BA36A5;"&gt;pages&lt;/span&gt; =        {13879-13887},
  &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt; =         2024,
  &lt;span style="color: #BA36A5;"&gt;doi&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;10.1021/acs.jpcc.4c04224&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;url&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;http://dx.doi.org/10.1021/acs.jpcc.4c04224&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;DATE_ADDED&lt;/span&gt; =   {Sat Aug 17 09:45:55 2024},
}
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1021/acs.jpcc.4c04224'&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/5MpBldx9WafwZO8movWxWS?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2025 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2025/01/27/New-publication---Structure-Sensitive-Reaction-Kinetics-of-Chiral-Molecules-on-Intrinsically-Chiral-Surfaces.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.8-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>10 years ago - org mode is awesome video</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/07/04/10-years-ago-org-mode-is-awesome-video</link>
      <pubDate>Thu, 04 Jul 2024 07:52:26 EDT</pubDate>
      <category><![CDATA[org-mode]]></category>
      <guid isPermaLink="false">satKzsj20KTdCZO_E3SMztghNgI=</guid>
      <description>10 years ago - org mode is awesome video</description>
      <content:encoded><![CDATA[


&lt;p&gt;
Ten years ago I posted a video on YouTube titled "org mode is awesome". This 18 minute video was a tour of features in org-mode that ranged included, outlining, task management, agendas, tables, code, exporting to different formats, and extendability. That video has been viewed 92.9K times!
&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/fgizHHd7nOo?si=YtXo7_4jyxQh90AG" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
A fair bit has changed since then, and a lot has stayed the same. org-mode is even more awesome! That video was made with what I called at the time &lt;code&gt;jmax&lt;/code&gt;, and that has evolved into &lt;code&gt;scimax&lt;/code&gt; today. I use &lt;code&gt;scimax&lt;/code&gt; on a daily basis in my research, teaching and other work. It is as important in my work today as it was 10 years ago, and has survived watching other editors come and go.
&lt;/p&gt;

&lt;p&gt;
I have had in mind to make an update of that video, but it has in my opinion really stood the test of time and is still highly relevant in its present form. The only thing that would really change is the background and font colors. 
&lt;/p&gt;

&lt;p&gt;
I have made over 200 other YouTube videos over that time, and many of them are on using Emacs and org-mode in a lot of different ways. These videos are organized in these playlists:
&lt;/p&gt;

&lt;dl class="org-dl"&gt;
&lt;dt&gt;&lt;a href="https://www.youtube.com/playlist?list=PL0sMmOaE_gs1Ox-wIIbHPLZ9O5uLJ_rQW"&gt;scimax-eln&lt;/a&gt;&lt;/dt&gt;&lt;dd&gt;Using scimax as an electronic lab notebook.&lt;/dd&gt;
&lt;dt&gt;&lt;a href="https://www.youtube.com/playlist?list=PL0sMmOaE_gs3E0OjExoI7vlCAVygj6S4I"&gt;scimax&lt;/a&gt;&lt;/dt&gt;&lt;dd&gt;Videos on libraries I developed in scimax, including org-ref&lt;/dd&gt;
&lt;dt&gt;&lt;a href="https://www.youtube.com/playlist?list=PL0sMmOaE_gs3GbuZV_sNjwMREw9rfElTV"&gt;org-mode&lt;/a&gt;&lt;/dt&gt;&lt;dd&gt;Videos exploring features in org-mode&lt;/dd&gt;
&lt;dt&gt;&lt;a href="https://www.youtube.com/playlist?list=PL0sMmOaE_gs2yzwy54kLZk5c1ZH-Nh-62"&gt;pycse&lt;/a&gt;&lt;/dt&gt;&lt;dd&gt;Videos on using Python in Emacs to solve engineering and science problems&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;
You can see how &lt;code&gt;scimax&lt;/code&gt; has evolved, and continues to evolve over this time through these videos, and of course through the &lt;code&gt;scimax&lt;/code&gt; repo at &lt;a href="https://github.com/jkitchin/scimax"&gt;https://github.com/jkitchin/scimax&lt;/a&gt;. There are still great things coming for &lt;code&gt;scimax&lt;/code&gt;, stay tuned!
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/07/04/10-years-ago---org-mode-is-awesome-video.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7.5&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>New publication - Pourbaix Machine Learning Framework Identifies Acidic Water Oxidation Catalysts Exhibiting Suppressed Ruthenium Dissolution</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/06/08/New-publication-Pourbaix-Machine-Learning-Framework-Identifies-Acidic-Water-Oxidation-Catalysts-Exhibiting-Suppressed-Ruthenium-Dissolution</link>
      <pubDate>Sat, 08 Jun 2024 13:43:06 EDT</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">wotgloASUt7mtV4EB6s_vNW6pno=</guid>
      <description>New publication - Pourbaix Machine Learning Framework Identifies Acidic Water Oxidation Catalysts Exhibiting Suppressed Ruthenium Dissolution</description>
      <content:encoded><![CDATA[


&lt;p&gt;
Water splitting is a crucial technology for renewable hydrogen generation. Under acid conditions most metals that would be used for the oxidation reaction tend to dissolve, limiting their utility. Iridium oxide is widely regarded as the most active and stable material, but it is very expensive. Ruthenium oxide is the next most active material, but it is less stable and tends to dissolve over time. In this work we studied 36,000 mixed metal oxides to identify potential compositions that would stabilize ruthenium from dissolution. We found a candidate Ru&lt;sub&gt;0.6&lt;/sub&gt;Cr&lt;sub&gt;0.2&lt;/sub&gt;Ti&lt;sub&gt;0.2&lt;/sub&gt;O&lt;sub&gt;2&lt;/sub&gt; with promise. We synthesized this material anf show that it has superior stability and improved activity compared to RuO&lt;sub&gt;2&lt;/sub&gt;.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;abed-2024-pourb-machin&lt;/span&gt;,
  &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt; =       {Jehad Abed and Javier Heras-Domingo and Rohan Yuri Sanspeur
                  and Mingchuan Luo and Wajdi Alnoush and Debora Motta Meira and
                  Hsiaotsu Wang and Jian Wang and Jigang Zhou and Daojin Zhou
                  and Khalid Fatih and John R. Kitchin and Drew Higgins and
                  Zachary W. Ulissi and Edward H. Sargent},
  &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt; =        {Pourbaix Machine Learning Framework Identifies Acidic Water
                  Oxidation Catalysts Exhibiting Suppressed Ruthenium
                  Dissolution},
  &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt; =      {Journal of the American Chemical Society},
  &lt;span style="color: #BA36A5;"&gt;volume&lt;/span&gt; =       {nil},
  &lt;span style="color: #BA36A5;"&gt;number&lt;/span&gt; =       {nil},
  &lt;span style="color: #BA36A5;"&gt;pages&lt;/span&gt; =        {nil},
  &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt; =         2024,
  &lt;span style="color: #BA36A5;"&gt;doi&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;10.1021/jacs.4c01353&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;url&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;http://dx.doi.org/10.1021/jacs.4c01353&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;DATE_ADDED&lt;/span&gt; =   {Sat Jun 8 13:12:31 2024},
}
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1021/jacs.4c01353'&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/8nlepsWOxl0?si=a_FR5vDxMkiLsmNk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/06/08/New-publication---Pourbaix-Machine-Learning-Framework-Identifies-Acidic-Water-Oxidation-Catalysts-Exhibiting-Suppressed-Ruthenium-Dissolution.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>New publication - Surface Segregation Studies in Ternary Noble Metal Alloys Comparing DFT and Machine Learning with Experimental Data</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/06/06/New-publication-Surface-Segregation-Studies-in-Ternary-Noble-Metal-Alloys-Comparing-DFT-and-Machine-Learning-with-Experimental-Data</link>
      <pubDate>Thu, 06 Jun 2024 09:17:13 EDT</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">7mY7Urlfm0a2xuAMg-Zb566RgGg=</guid>
      <description>New publication - Surface Segregation Studies in Ternary Noble Metal Alloys Comparing DFT and Machine Learning with Experimental Data</description>
      <content:encoded><![CDATA[


&lt;p&gt;
Alloy segregation is hard to model; you need large unit cells to get fine-grained compositions, and &lt;i&gt;a lot&lt;/i&gt; of DFT calculations to sample all the possible configurations. The challenge gets even bigger when you consider a ternary alloy, and want to model segregation over the entire ternary alloy composition space, and across multiple surfaces. We tackle this problem in this work using the Open Catalyst Project machine learned potentials (MLPs) that are fine-tuned on a few thousand DFT calculations. We use those MLPs with Monte Carlo simulations to predict segregation on three ternary alloy (111), (110), and (100) surfaces. We compare our predictions to experimental measurements on a polycrystalline CSAF. Similar to previous work of ours, we find qualitative and quantitative agreements in some composition ranges, and disagreement in others. We trace the limitations of quantitative accuracy to limitations in the DFT calculations.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;broderick-2024-surfac-segreg&lt;/span&gt;,
  &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt; =       {Kirby Broderick and Robert A. Burnley and Andrew J. Gellman
                  and John R. Kitchin},
  &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt; =        {Surface Segregation Studies in Ternary Noble Metal Alloys:
                  Comparing Dft and Machine Learning With Experimental Data},
  &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt; =      {ChemPhysChem},
  &lt;span style="color: #BA36A5;"&gt;volume&lt;/span&gt; =       {nil},
  &lt;span style="color: #BA36A5;"&gt;number&lt;/span&gt; =       {nil},
  &lt;span style="color: #BA36A5;"&gt;pages&lt;/span&gt; =        {nil},
  &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt; =         2024,
  &lt;span style="color: #BA36A5;"&gt;doi&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;10.1002/cphc.202400073&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;url&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;http://dx.doi.org/10.1002/cphc.202400073&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;DATE_ADDED&lt;/span&gt; =   {Thu Jun 6 08:37:37 2024},
}
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1002/cphc.202400073'&gt;&lt;/div&gt;
&lt;/p&gt;


&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/x-bCzsn_lmQ?si=oxTCVklbUgr8VwZt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/06/06/New-publication---Surface-Segregation-Studies-in-Ternary-Noble-Metal-Alloys-Comparing-DFT-and-Machine-Learning-with-Experimental-Data.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>New publication - Cyclic Steady-State Simulation and Waveform Design for Dynamic Programmable Catalysis</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/05/23/New-publication-Cyclic-Steady-State-Simulation-and-Waveform-Design-for-Dynamic-Programmable-Catalysis</link>
      <pubDate>Thu, 23 May 2024 16:51:46 EDT</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">1LIjMPewD2gXX9ORAMSS8SyzyAk=</guid>
      <description>New publication - Cyclic Steady-State Simulation and Waveform Design for Dynamic Programmable Catalysis</description>
      <content:encoded><![CDATA[


&lt;p&gt;
You can get higher rates of reaction on a catalyst by dynamically changing the adsorbate and reaction energetics. It has been an open challenge though to find ways to obtain the optimal waveform. In this work we present a problem formulation that is easy to solve and optimize waveforms in programmable catalysis.
&lt;/p&gt;

&lt;p&gt;
&lt;a href="https://doi.org/10.1021/acs.jpcc.4c01543"&gt;https://doi.org/10.1021/acs.jpcc.4c01543&lt;/a&gt;
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;tedesco-2024-cyclic-stead&lt;/span&gt;,
  &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt; =       {Carolina Colombo Tedesco and John R. Kitchin and Carl D.
                  Laird},
  &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt; =        {Cyclic Steady-State Simulation and Waveform Design for
                  Dynamic/programmable Catalysis},
  &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt; =      {The Journal of Physical Chemistry C},
  &lt;span style="color: #BA36A5;"&gt;volume&lt;/span&gt; =       {nil},
  &lt;span style="color: #BA36A5;"&gt;number&lt;/span&gt; =       {nil},
  &lt;span style="color: #BA36A5;"&gt;pages&lt;/span&gt; =        {nil},
  &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt; =         2024,
  &lt;span style="color: #BA36A5;"&gt;doi&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;10.1021/acs.jpcc.4c01543&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;url&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;http://dx.doi.org/10.1021/acs.jpcc.4c01543&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;DATE_ADDED&lt;/span&gt; =   {Thu May 23 16:35:52 2024},
}
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1021/acs.jpcc.4c01543'&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/33VyAgDmSNo?si=otdqN8p6X-yX_A2V" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/05/23/New-publication---Cyclic-Steady-State-Simulation-and-Waveform-Design-for-Dynamic-Programmable-Catalysis.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>Kolmogorov-Arnold Networks (KANs) and Lennard Jones</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/05/05/Kolmogorov-Arnold-Networks-KANs-and-Lennard-Jones</link>
      <pubDate>Sun, 05 May 2024 11:06:22 EDT</pubDate>
      <category><![CDATA[uncategorized]]></category>
      <guid isPermaLink="false">1zelkWojiUWoC3g4YT1TkwYFW18=</guid>
      <description>Kolmogorov-Arnold Networks (KANs) and Lennard Jones</description>
      <content:encoded><![CDATA[


&lt;div id="table-of-contents" role="doc-toc"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents" role="doc-toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#org6ed4d7a"&gt;1. Create a dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#orgca2cb78"&gt;2. Create and train the model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
KANs have been a hot topic of discussion recently (&lt;a href="https://arxiv.org/abs/2404.19756"&gt;https://arxiv.org/abs/2404.19756&lt;/a&gt;). Here I explore using them as an alternative to a neural network for a simple atomistic potential using Lennard Jones data. I adapted this code from  &lt;a href="https://github.com/KindXiaoming/pykan/blob/master/hellokan.ipynb"&gt;https://github.com/KindXiaoming/pykan/blob/master/hellokan.ipynb&lt;/a&gt;. 
&lt;/p&gt;

&lt;p&gt;
TL;DR It was easy to make the model, and it fit this simple data very well. It does not extrapolate in this example, and it is not obvious what the extrapolation behavior should be.
&lt;/p&gt;

&lt;div id="outline-container-org6ed4d7a" class="outline-2"&gt;
&lt;h2 id="org6ed4d7a"&gt;&lt;span class="section-number-2"&gt;1.&lt;/span&gt; Create a dataset&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;p&gt;
We leverage the &lt;code&gt;create_dataset&lt;/code&gt; function to generate the dataset here. I chose a range with some modest nonlinearity, and the minimum.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-jupyter-python"&gt;&lt;span style="color: #0000FF;"&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style="color: #0000FF;"&gt;as&lt;/span&gt; plt
&lt;span style="color: #0000FF;"&gt;import&lt;/span&gt; torch
&lt;span style="color: #0000FF;"&gt;from&lt;/span&gt; kan &lt;span style="color: #0000FF;"&gt;import&lt;/span&gt; create_dataset, KAN

&lt;span style="color: #0000FF;"&gt;def&lt;/span&gt; &lt;span style="color: #006699;"&gt;LJ&lt;/span&gt;(r):
    &lt;span style="color: #BA36A5;"&gt;r6&lt;/span&gt; = r**6
    &lt;span style="color: #0000FF;"&gt;return&lt;/span&gt; 1 / r6**2 - 1 / r6

&lt;span style="color: #BA36A5;"&gt;dataset&lt;/span&gt; = create_dataset(LJ, n_var=1, ranges=[0.95, 2.0],
                         train_num=50)

plt.plot(dataset[&lt;span style="color: #008000;"&gt;'train_input'&lt;/span&gt;], dataset[&lt;span style="color: #008000;"&gt;'train_label'&lt;/span&gt;], &lt;span style="color: #008000;"&gt;'b.'&lt;/span&gt;)
plt.xlabel(&lt;span style="color: #008000;"&gt;'r'&lt;/span&gt;)
plt.ylabel(&lt;span style="color: #008000;"&gt;'E'&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/0db7627856ef3cacbeb19cba9e64a53fb49bf422.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-orgca2cb78" class="outline-2"&gt;
&lt;h2 id="orgca2cb78"&gt;&lt;span class="section-number-2"&gt;2.&lt;/span&gt; Create and train the model&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
We start by making the model. We are going to model a Lennard-Jones potential with one input, the distance between two atoms, and one output. We start with a width of 2 "neurons".
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-jupyter-python"&gt;&lt;span style="color: #BA36A5;"&gt;model&lt;/span&gt; = KAN(width=[1, 2, 1])
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
Training is easy. You can even run this cell several times.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-jupyter-python"&gt;model.train(dataset, opt=&lt;span style="color: #008000;"&gt;"LBFGS"&lt;/span&gt;, steps=20);

model.plot()
&lt;/pre&gt;
&lt;/div&gt;

&lt;pre class="example"&gt;
train loss: 1.64e-04 | test loss: 1.46e-02 | reg: 6.72e+00 : 100%|██| 20/20 [00:03&amp;lt;00:00,  5.61it/s]

&lt;/pre&gt;

&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/0cea2b134045cc964f990ac28b524c32d441976b.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;


&lt;p&gt;
We can see here that the fit looks very good.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-jupyter-python"&gt;&lt;span style="color: #BA36A5;"&gt;X&lt;/span&gt; = torch.linspace(dataset[&lt;span style="color: #008000;"&gt;'train_input'&lt;/span&gt;].&lt;span style="color: #006FE0;"&gt;min&lt;/span&gt;(),
                   dataset[&lt;span style="color: #008000;"&gt;'train_input'&lt;/span&gt;].&lt;span style="color: #006FE0;"&gt;max&lt;/span&gt;(), 100)[:, &lt;span style="color: #D0372D;"&gt;None&lt;/span&gt;]

plt.plot(dataset[&lt;span style="color: #008000;"&gt;'train_input'&lt;/span&gt;], dataset[&lt;span style="color: #008000;"&gt;'train_label'&lt;/span&gt;], &lt;span style="color: #008000;"&gt;'b.'&lt;/span&gt;, label=&lt;span style="color: #008000;"&gt;'data'&lt;/span&gt;)

plt.plot(X, model(X).detach().numpy(), &lt;span style="color: #008000;"&gt;'r-'&lt;/span&gt;, label=&lt;span style="color: #008000;"&gt;'fit'&lt;/span&gt;)
plt.legend()
plt.xlabel(&lt;span style="color: #008000;"&gt;'r'&lt;/span&gt;)
plt.ylabel(&lt;span style="color: #008000;"&gt;'E'&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/24eddff0ce69063a1aaabc80060e78b56ecef0b5.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;

&lt;p&gt;
KANs do not save us from extrapolation issues though. I think a downside of KANs is it is not obvious what extrapolation behavior to expect. I guess it could be related to what happens in the spline representation of the functions. Eventually those have to extrapolate too.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-jupyter-python"&gt;&lt;span style="color: #BA36A5;"&gt;X&lt;/span&gt; = torch.linspace(0, 5, 1000)[:, &lt;span style="color: #D0372D;"&gt;None&lt;/span&gt;]
plt.plot(dataset[&lt;span style="color: #008000;"&gt;'train_input'&lt;/span&gt;], dataset[&lt;span style="color: #008000;"&gt;'train_label'&lt;/span&gt;], &lt;span style="color: #008000;"&gt;'b.'&lt;/span&gt;)
plt.plot(X, model(X).detach().numpy(), &lt;span style="color: #008000;"&gt;'r-'&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/a16818596b6a60ea026406808143fcddcfae54f9.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;


&lt;p&gt;
It is early days for KANs, so many things we know about MLPs are still unknown for KANs. For example, with MLPs we know they extrapolate like the activation functions. Probably there is some insight like that to be had here, but it needs to be uncovered. With MLPs there are a lot of ways to regularize them for desired behavior. Probably that is true here too, and will be discovered. Similarly, there are many ways people have approached uncertainty quantification in MLPs that probably have some analog in KANs. 
Still, the ease of use suggests it could be promising for some applications.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/05/05/Kolmogorov-Arnold-Networks-(KANs)-and-Lennard-Jones.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>Generalization of Graph-Based Active Learning Relaxation Strategies Across Materials</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/04/20/Generalization-of-Graph-Based-Active-Learning-Relaxation-Strategies-Across-Materials</link>
      <pubDate>Sat, 20 Apr 2024 09:20:07 EDT</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">BMxHanFWgWdXousv9pY3yE6eRo4=</guid>
      <description>Generalization of Graph-Based Active Learning Relaxation Strategies Across Materials</description>
      <content:encoded><![CDATA[


&lt;p&gt;
Geometry optimization is an expensive part of DFT; each step requires a DFT step. The Open Catalyst Project provides pre-trained machine learned potentials that provide cheap forces for a broad range of metallic, intermetallic materials. In this work we use models trained on the OC20 dataset to accelerate geometry optimization of materials outside that domain including larger adsorbates, oxides, and zeolites.  With fine-tuning, we are able to reduce the number of DFT calls required substantially for these systems.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;10.1088/2632-2153/ad37f0&lt;/span&gt;,
        &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt;={Wang, Xiaoxiao and Musielewicz, Joseph and Tran, Richard and Ethirajan, Sudheesh Kumar and Fu, Xiaoyan and Mera, Hilda and Kitchin, John R and Kurchin, Rachel and Ulissi, Zachary W},
        &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt;={Generalization of Graph-Based Active Learning Relaxation Strategies Across Materials},
        &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt;={Machine Learning: Science and Technology},
        &lt;span style="color: #BA36A5;"&gt;url&lt;/span&gt;={&lt;span style="color: #006DAF; text-decoration: underline;"&gt;http://iopscience.iop.org/article/10.1088/2632-2153/ad37f0&lt;/span&gt;},
        &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt;={2024}
}
&lt;/pre&gt;
&lt;/div&gt;


&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1088/2632-2153/ad37f0'&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/xQk59F2HTwQ?si=xLhbVO585CRa4YF_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/04/20/Generalization-of-Graph-Based-Active-Learning-Relaxation-Strategies-Across-Materials.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>A little more than a decade of the Kitchingroup blog</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/04/03/A-little-more-than-a-decade-of-the-Kitchingroup-blog</link>
      <pubDate>Wed, 03 Apr 2024 08:38:34 EDT</pubDate>
      <category><![CDATA[uncategorized]]></category>
      <guid isPermaLink="false">-ZV6r2to6H-DXZw9bvFEphIHmeU=</guid>
      <description>A little more than a decade of the Kitchingroup blog</description>
      <content:encoded><![CDATA[


&lt;p&gt;
There are a few early entries I backdated, but this blog got started in its present form in January 2013. This entry marks entry #594. I started this blog as part of an exercise in switching from Matlab to Python, and the first hundred entries or so are just me solving a problem in Python that I had previously solved in Matlab. It then expanded to include lots of entries on Emacs and org-mode, and other research related topics from my group. Many entries simply document something I spent time working out and that I wanted to be able to find by Google later.
&lt;/p&gt;


&lt;p&gt;
When I set the blog up, I enabled Google Analytics to see if anyone would look at. Recently Google announced they are shutting down the version of analytics I was using, and transitioning to a newer approach. They no longer collect data with the version this blog is using (since Oct last year), and they will delete the data this summer, so today I downloaded some of it to see what has happened over the past decade.
&lt;/p&gt;

&lt;p&gt;
Anecdotally many people from around the world have told me how useful the blog was for them. Now, I have data to see how many people have been impacted by this blog. This figure shows that a lot of people spent time in some part of the blog over the past decade! The data suggests over 1M people viewed these pages over 2M times. 
&lt;/p&gt;


&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/date-03-04-2024-time-08-26-10.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;


&lt;p&gt;
The peak usage was around 2020, and it has been trailing off since then. I have not been as active in posting since then. You can also see there is a very long build up to that peak.
&lt;/p&gt;

&lt;p&gt;
The user group for the blog is truly world wide, including almost every country in this map. That is amazing!
&lt;/p&gt;


&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/date-03-04-2024-time-08-33-54.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;

&lt;p&gt;
Finally, I found the pages that were most viewed. It is interesting most of them are the older pages, and all about Python. I guess that means I should write more posts on Python.
&lt;/p&gt;


&lt;p&gt;
&lt;figure&gt;&lt;img src="/media/date-03-04-2024-time-08-35-06.png"&gt;&lt;/figure&gt; 
&lt;/p&gt;


&lt;p&gt;
I don't know what the future of the blog is. It is in need of an overhaul. The packages that build it still work, but are not actively maintained. I have also spent more time writing with Jupyter Book lately than the way I wrote this blog. It isn't likely to disappear any time soon, it sits rent-free in GitHUB pages.
&lt;/p&gt;

&lt;p&gt;
To conclude, to everyone who has read these pages, thank you! It has been a lot of work to put together over the years, and I am glad to see many people have taken a look at it.
&lt;/p&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/04/03/A-little-more-than-a-decade-of-the-Kitchingroup-blog.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>New publication - Circumventing data imbalance in magnetic ground state data for magnetic moment predictions</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2024/02/17/New-publication-Circumventing-data-imbalance-in-magnetic-ground-state-data-for-magnetic-moment-predictions</link>
      <pubDate>Sat, 17 Feb 2024 09:59:30 EST</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">Ug-7-SHPykpwsIGejbv4Ww1_v2o=</guid>
      <description>New publication - Circumventing data imbalance in magnetic ground state data for magnetic moment predictions</description>
      <content:encoded><![CDATA[


&lt;p&gt;
Modeling magnetic materials with DFT is hard. In this work we develop a machine learning approach to predicting magnetic properties of materials based on their structure. Our two stage model first predicts if a material is magnetic, and then if it is, what the magnetic moments on each atom are. We show this can lead to faster and lower energy DFT solutions.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;sanspeur-2024-circum-data&lt;/span&gt;,
  &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt; =       {Rohan Yuri Sanspeur and John R Kitchin},
  &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt; =        {Circumventing Data Imbalance in Magnetic Ground State Data for
                  Magnetic Moment Predictions},
  &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt; =      {Machine Learning: Science and Technology},
  &lt;span style="color: #BA36A5;"&gt;volume&lt;/span&gt; =       {5},
  &lt;span style="color: #BA36A5;"&gt;number&lt;/span&gt; =       {1},
  &lt;span style="color: #BA36A5;"&gt;pages&lt;/span&gt; =        {015023},
  &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt; =         2024,
  &lt;span style="color: #BA36A5;"&gt;doi&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;10.1088/2632-2153/ad23fb&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;url&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;http://dx.doi.org/10.1088/2632-2153/ad23fb&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;DATE_ADDED&lt;/span&gt; =   {Tue Feb 6 20:13:47 2024},
}
&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1088/2632-2153/ad23fb'&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/FaOwCbkc3zc?si=77Bz5Xfmbz7FSZFq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2024 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2024/02/17/New-publication---Circumventing-data-imbalance-in-magnetic-ground-state-data-for-magnetic-moment-predictions.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
    <item>
      <title>New publication - Applying Large Graph Neural Networks to Predict Transition Metal Complex Energies Using the tmQM_wB97MV Data Set</title>
      <link>https://kitchingroup.cheme.cmu.edu/blog/2023/12/10/New-publication-Applying-Large-Graph-Neural-Networks-to-Predict-Transition-Metal-Complex-Energies-Using-the-tmQM-wB97MV-Data-Set</link>
      <pubDate>Sun, 10 Dec 2023 14:53:33 EST</pubDate>
      <category><![CDATA[news]]></category>
      <category><![CDATA[publication]]></category>
      <guid isPermaLink="false">u10QCWOhac20TRZ0y1xZy4QbKjc=</guid>
      <description>New publication - Applying Large Graph Neural Networks to Predict Transition Metal Complex Energies Using the tmQM_wB97MV Data Set</description>
      <content:encoded><![CDATA[


&lt;p&gt;
In this work, we show that we can use large graph neural networks to predict transition metal complex energies. We developed an improved dataset at a higher level of theory, and tested models ranging from GemNet-T (best) to SchNet (worst). The model performance saturates with the size of neutral structures, and improves with increasing size of charged structures. Finally, we showed that a pre-trained model from OC20 was even better than training from scratch. This indicates a degree of transferability from heterogeneous catalyst models to homogeneous molecular catalysts.
&lt;/p&gt;

&lt;div class="org-src-container"&gt;
&lt;pre class="src src-bibtex"&gt;&lt;span style="color: #006699;"&gt;@article&lt;/span&gt;{&lt;span style="color: #D0372D;"&gt;garrison-2023-apply-large&lt;/span&gt;,
  &lt;span style="color: #BA36A5;"&gt;author&lt;/span&gt; =       {Garrison, Aaron G. and Heras-Domingo, Javier and Kitchin, John
                  R. and dos Passos Gomes, Gabriel and Ulissi, Zachary W. and
                  Blau, Samuel M.},
  &lt;span style="color: #BA36A5;"&gt;title&lt;/span&gt; =        {Applying Large Graph Neural Networks To Predict Transition
                  Metal Complex Energies Using the tmQM\_wB97MV Data Set},
  &lt;span style="color: #BA36A5;"&gt;journal&lt;/span&gt; =      {Journal of Chemical Information and Modeling},
  &lt;span style="color: #BA36A5;"&gt;volume&lt;/span&gt; =       0,
  &lt;span style="color: #BA36A5;"&gt;number&lt;/span&gt; =       0,
  &lt;span style="color: #BA36A5;"&gt;pages&lt;/span&gt; =        {null},
  &lt;span style="color: #BA36A5;"&gt;year&lt;/span&gt; =         2023,
  &lt;span style="color: #BA36A5;"&gt;doi&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;10.1021/acs.jcim.3c01226&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;URL&lt;/span&gt; =          {&lt;span style="color: #006DAF; text-decoration: underline;"&gt;https://doi.org/10.1021/acs.jcim.3c01226&lt;/span&gt;},
  &lt;span style="color: #BA36A5;"&gt;eprint&lt;/span&gt; =       {https://doi.org/10.1021/acs.jcim.3c01226},
  &lt;span style="color: #BA36A5;"&gt;note&lt;/span&gt; =         {PMID: 38049389},
}

&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'&gt;&lt;/script&gt;
&lt;div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1021/acs.jcim.3c01226'&gt;&lt;/div&gt;
&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/p_DpuIdcelY?si=HaBtCUlByRjuJU7i" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Copyright (C) 2023 by John Kitchin. See the &lt;a href="/copying.html"&gt;License&lt;/a&gt; for information about copying.&lt;p&gt;
&lt;p&gt;&lt;a href="/org/2023/12/10/New-publication---Applying-Large-Graph-Neural-Networks-to-Predict-Transition-Metal-Complex-Energies-Using-the-tmQM_wB97MV-Data-Set.org"&gt;org-mode source&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Org-mode version = 9.7-pre&lt;/p&gt;]]></content:encoded>
    </item>
  </channel>
</rss>
