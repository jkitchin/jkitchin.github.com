

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Kitchin Research Group</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            
  





<article>
  <div class="blog_post">
    <header>
      <div id="A-Hy-macro-for-defining-functions-with-docstrings-on-each-argument"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/03/19/A-Hy-macro-for-defining-functions-with-docstrings-on-each-argument/" rel="bookmark" title="Permanent Link to A Hy macro for defining functions with docstrings on each argument">A Hy macro for defining functions with docstrings on each argument</a></h2>
      <p><small><span class="blog_post_date">Posted March 19, 2017 at 07:47 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/python/'>python</a>, <a href='/blog/category/hylang/'>hylang</a></span> | tags: 
      <p><small><span class="blog_post_date">Updated March 19, 2017 at 07:53 PM</span></small>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
For functions with a lot of arguments, python style docstrings leave something to be desired. For one, they are not that close to the arguments, so if you have a function with say 20 arguments, the docstring might take up a whole page! That means they are hard to keep synchronized too. Let's not argue now over the merits of a function with 20+ arguments, it is enough that they exist, and are a problem.
</p>

<p>
So what are typical documentation standards? Here is a Numpy style doc string:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">def</span> <span style="color: #006699;">func</span>(arg1, arg2):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #036A07;">"""multiply arg1 and arg2</span>

<span style="color: #9B9B9B; background-color: #EDEDED;"> </span><span style="color: #036A07;">   Parameters</span>
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span><span style="color: #036A07;">   ----------</span>
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span><span style="color: #036A07;">   arg1 : a number</span>
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span><span style="color: #036A07;">   arg2 : a number</span>

<span style="color: #9B9B9B; background-color: #EDEDED;"> </span><span style="color: #036A07;">   """</span>
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> arg1 * arg2
</pre>
</div>

<p>
It works well for a small number of arguments with limited descriptions. This is a proper docstring that is accessible by introspection and pydoc. With much longer argument lists, this falls apart. I will not pick on any code in particular here, but suffice it to say I was inspired today to think of a better way. There are some other documentation solutions at <a href="http://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters">http://stackoverflow.com/questions/9195455/how-to-document-a-method-with-parameters</a>, but None of them are better in my opinion. I want accessible docstrings by instrospection, and only if that is unavailable do I want to read the code! Finally, if I have to read the code, I want it to be easy to figure out, which means the documentation is close to the arguments.
</p>

<p>
There is bad news, I do not have one for vanilla python. Python does not even give you a way to deal with this. But, if we had a lisp, we could make a macro to help us out. In fact, we <i>have</i> a lisp with <a href="http://docs.hylang.org/en/latest/">hy</a>! And we can use a macro to make a  syntax that lets us keep the docstring close to the argument, <i>and</i> that constructs a real docstring so we get help later!
</p>

<p>
Here it is:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-hy">(<span style="color: #0000FF;">defmacro</span> <span style="color: #006699;">mydef</span> [func args <span style="color: #6434A3;">&amp;optional</span> docstring <span style="color: #6434A3;">&amp;rest</span> body]
  `(<span style="color: #0000FF;">defn</span> <span style="color: #006699;">~func</span> [~@(<span style="color: #006FE0;">map</span> (<span style="color: #0000FF;">lambda</span> [x] (<span style="color: #006FE0;">nth</span> x 0)) args)]
     ~(<span style="color: #006FE0;">+</span> (<span style="color: #0000FF;">if</span> docstring (<span style="color: #006FE0;">+</span> docstring <span style="color: #008000;">"\n\n"</span>) <span style="color: #008000;">""</span>)
         <span style="color: #008000;">"Parameters\n----------\n"</span>
         (.join <span style="color: #008000;">"\n"</span> (<span style="color: #006FE0;">map</span> (<span style="color: #0000FF;">lambda</span> [x]
                            (.format <span style="color: #008000;">"{} : {}"</span>
                                     (<span style="color: #006FE0;">nth</span> x 0)
                                     (<span style="color: #006FE0;">nth</span> x 1))) args)))
     ~@body))
</pre>
</div>

<p>
We can checkout how it expands like this:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-hy">(<span style="color: #006FE0;">print</span> (<span style="color: #006FE0;">macroexpand</span> '(mydef f [(a <span style="color: #008000;">"an int"</span>)
                               (b <span style="color: #008000;">"an int"</span>)]
                            <span style="color: #008000;">"some doc"</span>
                            (<span style="color: #006FE0;">*</span> a b))))
</pre>
</div>
<pre class="example">
('setv' 'f' ('fn' ['a' 'b'] 'some doc\n\nParameters\n----------\na : an int\nb : an int' ('*' 'a' 'b')))
</pre>

<p>
That looks ok. Now, for an example of using that. Here is the same function we defined before, but I put the documentation for each argument with the argument.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-hy">(mydef func ((arg1 <span style="color: #008000;">"a number"</span>)
             (arg2 <span style="color: #008000;">"a number"</span>))
  <span style="color: #008000;">"Multiply arg1 by arg2"</span>
  (<span style="color: #006FE0;">*</span> arg1 arg2))
</pre>
</div>

<p>
We can use the function now like a regular function.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-hy">(<span style="color: #006FE0;">print</span> (func 24 3))
</pre>
</div>

<pre class="example">
72
</pre>

<p>
And now for the help.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-hy">(help func)
</pre>
</div>

<pre class="example">
Help on function func in module __main__:

func(arg1, arg2)
    Multiply arg1 by arg2

    Parameters
    ----------
    arg1 : a number
    arg2 : a number
</pre>

<p>
Now, that should amaze and astonish you if you are a vanilla Pythonista! We have our cake, and we eat it too. You just can not make up your own syntax that way in Python. Imagine, we could add type information, validation code, etc&#x2026; into that macro. Maybe it could even be possible to store argument dependent documentation on the function, say in the function dictionary. That would require some conventions I guess,  but they could become introspectable then. For example, in this vanilla Python:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">def</span> <span style="color: #006699;">f</span>(x): <span style="color: #0000FF;">return</span> x*x
<span style="color: #BA36A5;">f.__dict__</span>[<span style="color: #008000;">'args'</span>] = {<span style="color: #008000;">'x'</span>: <span style="color: #008000;">'A number'</span>}
<span style="color: #0000FF;">print</span>(f.__dict__)
</pre>
</div>

<p>
{'args': {'x': 'A number'}}
</p>

<p>
In the end, this does not really solve all the problems I have with current docstrings in Python. It does solve a problem with writing and reading the code by keeping documentation close to the arguments, but ultimately the docstring from Python's point of view will basically look the same. It is pretty awesome that it is even possible. Hy lisp for the win here (again!).
</p>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/03/19/A-Hy-macro-for-defining-functions-with-docstrings-on-each-argument.org">org-mode source</a></p>
<p>Org-mode version = 9.0.5</p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Share on Twitter</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>


<a href="https://twitter.com/search?q=https://kitchingroup.cheme.cmu.edu/blog/2017/03/19/A-Hy-macro-for-defining-functions-with-docstrings-on-each-argument">Discuss on Twitter</a>

  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Modeling-a-Cu-dimer-by-EMT-nonlinear-regression-and-neural-networks"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/03/18/Modeling-a-Cu-dimer-by-EMT-nonlinear-regression-and-neural-networks/" rel="bookmark" title="Permanent Link to Modeling a Cu dimer by EMT, nonlinear regression and neural networks">Modeling a Cu dimer by EMT, nonlinear regression and neural networks</a></h2>
      <p><small><span class="blog_post_date">Posted March 18, 2017 at 03:47 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/neural-network/'>neural-network</a>, <a href='/blog/category/python/'>python</a>, <a href='/blog/category/machine-learning/'>machine-learning</a>, <a href='/blog/category/molecular-simulation/'>molecular-simulation</a></span> | tags: 
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
In this post we consider a Cu<sub>2</sub> dimer and how its energy varies with the separation of the atoms. We assume we have a way to calculate this, but that it is expensive, and that we want to create a simpler model that is as accurate, but cheaper to run. A simple way to do that is to regress a physical model, but we will illustrate some challenges with that. We then show a neural network can be used as an accurate regression function without needing to know more about the physics.
</p>

<p>
We will use an <a href="https://wiki.fysik.dtu.dk/ase/ase/calculators/emt.html">effective medium theory</a> calculator to demonstrate this. The calculations are not expected to be very accurate or relevant to any experimental data, but they are fast, and will illustrate several useful points that are independent of that. We will take as our energy zero the energy of two atoms at a large separation, in this case about 10 angstroms. Here we plot the energy as a function of the distance between the two atoms, which is the only degree of freedom that matters in this example.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
%matplotlib inline
<span style="color: #0000FF;">import</span> matplotlib.pyplot <span style="color: #0000FF;">as</span> plt

<span style="color: #0000FF;">from</span> ase.calculators.emt <span style="color: #0000FF;">import</span> EMT
<span style="color: #0000FF;">from</span> ase <span style="color: #0000FF;">import</span> Atoms

<span style="color: #BA36A5;">atoms</span> = Atoms(<span style="color: #008000;">'Cu2'</span>,[[0, 0, 0], [10, 0, 0]], pbc=[<span style="color: #D0372D;">False</span>, <span style="color: #D0372D;">False</span>, <span style="color: #D0372D;">False</span>])
atoms.set_calculator(EMT())

<span style="color: #BA36A5;">e0</span> = atoms.get_potential_energy()

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Array of bond lengths to get the energy for</span>
<span style="color: #BA36A5;">d</span> = np.linspace(1.7, 3, 30)

<span style="color: #0000FF;">def</span> <span style="color: #006699;">get_e</span>(distance):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">a</span> = atoms.copy()
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   a[1]<span style="color: #BA36A5;">.x</span> = distance
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   a.set_calculator(EMT())
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">e</span> = a.get_potential_energy()
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> e

<span style="color: #BA36A5;">e</span> = np.array([get_e(dist) <span style="color: #0000FF;">for</span> dist <span style="color: #0000FF;">in</span> d])
<span style="color: #BA36A5;">e</span> -=  e0  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">set the energy zero</span>

plt.plot(d, e, <span style="color: #008000;">'bo '</span>)
plt.xlabel(<span style="color: #008000;">'d (&#197;)'</span>)
plt.ylabel(<span style="color: #008000;">'energy (eV)'</span>)
</pre>
</div>

<p>
<img src="/media/ob-ipython-82aeda9421056689d5212f9033da900a.png"> 
</p>


<p>
We see there is a minimum, and the energy is asymmetric about the minimum. We have no functional form for the energy here, just the data in the plot. So to get another energy, we have to run another calculation. If that was expensive, we might prefer an analytical equation to evaluate instead.  We will get an analytical form by fitting a function to the data. A classic one is the <a href="https://en.wikipedia.org/wiki/Buckingham_potential">Buckingham potential</a>: \(E = A \exp(-B r) - \frac{C}{r^6}\). Here we perform the regression.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">def</span> <span style="color: #006699;">model</span>(r, A, B, C):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> A * np.exp(-B * r) - C / r**6

<span style="color: #0000FF;">from</span> pycse <span style="color: #0000FF;">import</span> nlinfit
<span style="color: #0000FF;">import</span> pprint

<span style="color: #BA36A5;">p0</span> = [-80, 1, 1]
<span style="color: #BA36A5;">p</span>, <span style="color: #BA36A5;">pint</span>, <span style="color: #BA36A5;">se</span> = nlinfit(model, d, e, p0, 0.05)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Parameters = '</span>, p)
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Confidence intervals = '</span>)
pprint.pprint(pint)
plt.plot(d, e, <span style="color: #008000;">'bo '</span>, label=<span style="color: #008000;">'calculations'</span>)

<span style="color: #BA36A5;">x</span> = np.linspace(<span style="color: #006FE0;">min</span>(d), <span style="color: #006FE0;">max</span>(d))
plt.plot(x, model(x, *p), label=<span style="color: #008000;">'fit'</span>)
plt.legend(loc=<span style="color: #008000;">'best'</span>)
plt.xlabel(<span style="color: #008000;">'d (&#197;)'</span>)
plt.ylabel(<span style="color: #008000;">'energy (eV)'</span>)
</pre>
</div>

<p>
Parameters =  [ -83.21072545    1.18663393 -266.15259507]
Confidence intervals =
array([[ -93.47624687,  -72.94520404],
       [   1.14158438,    1.23168348],
       [-280.92915682, -251.37603331]])
<img src="/media/ob-ipython-a05811588d06f090a2462ba9f48dccb3.png"> 
</p>

<p>
That fit is ok, but not great. We would be better off with a spline for this simple system! The trouble is how do we get anything better? If we had a better equation to fit to we might get better results.  While one might come up with one for this dimer, how would you extend it to more complex systems, even just a trimer? There have been decades of research dedicated to that, and we are not smarter than those researchers so, it is time for a new approach.
</p>

<p>
We will use a Neural Network regressor. The input will be \(d\) and we want to regress a function to predict the energy.
</p>

<p>
There are a couple of important points to make here.
</p>

<ol class="org-ol">
<li>This is just another kind of regression.</li>
<li>We need a lot more data to do the regression. Here we use 300 data points.</li>
<li>We need to specify a network architecture. Here we use one hidden layer with 10 neurons, and the tanh activation function on each neuron. The last layer is just the output layer. I do not claim this is any kind of optimal architecture. It is just one that works to illustrate the idea.</li>
</ol>

<p>
Here is the code that uses a neural network regressor, which is lightly adapted from <a href="http://scikit-neuralnetwork.readthedocs.io/en/latest/guide_model.html">http://scikit-neuralnetwork.readthedocs.io/en/latest/guide_model.html</a>.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">from</span> sknn.mlp <span style="color: #0000FF;">import</span> Regressor, Layer

<span style="color: #BA36A5;">D</span> = np.linspace(1.7, 3, 300)

<span style="color: #0000FF;">def</span> <span style="color: #006699;">get_e</span>(distance):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">a</span> = atoms.copy()
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   a[1]<span style="color: #BA36A5;">.x</span> = distance
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   a.set_calculator(EMT())
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">e</span> = a.get_potential_energy()
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> e

<span style="color: #BA36A5;">E</span> = np.array([get_e(dist) <span style="color: #0000FF;">for</span> dist <span style="color: #0000FF;">in</span> D])
<span style="color: #BA36A5;">E</span> -=  e0  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">set the energy zero</span>

<span style="color: #BA36A5;">X_train</span> = np.row_stack(np.array(D))

<span style="color: #BA36A5;">N</span> = 10
<span style="color: #BA36A5;">nn</span> = Regressor(layers=[Layer(<span style="color: #008000;">"Tanh"</span>, units=N),
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>  Layer(<span style="color: #008000;">'Linear'</span>)])
nn.fit(X_train, E)

<span style="color: #BA36A5;">dfit</span> = np.linspace(<span style="color: #006FE0;">min</span>(d), <span style="color: #006FE0;">max</span>(d))

<span style="color: #BA36A5;">efit</span> = nn.predict(np.row_stack(dfit))

plt.plot(d, e, <span style="color: #008000;">'bo '</span>)
plt.plot(dfit, efit)
plt.legend([<span style="color: #008000;">'calculations'</span>, <span style="color: #008000;">'neural network'</span>])
plt.xlabel(<span style="color: #008000;">'d (&#197;)'</span>)
plt.ylabel(<span style="color: #008000;">'energy (eV)'</span>)
</pre>
</div>

<p>
<img src="/media/ob-ipython-025c1b30f565c5806510804582e91242.png"> 
</p>

<p>
This fit looks pretty good, better than we got for the Buckingham potential. Well, it probably should look better, we have many more parameters that were fitted! It is not perfect, but it could be systematically improved by increasing the number of hidden layers, and neurons in each layer. I am being a little loose here by relying on a visual assessment of the fit. To systematically improve it you would need a quantitative analysis of the errors. I also note though, that if I run the block above several times in succession, I get different fits each time. I suppose that is due to some random numbers used to initialize the fit, but sometimes the fit is about as good as the result you see above, and sometimes it is terrible.
</p>

<p>
Ok, what is the point after all? We developed a neural network that pretty accurately captures the energy of a Cu dimer <i>with no knowledge</i> of the physics involved. Now, EMT is not that expensive, but suppose this required 300 DFT calculations at 1 minute or more a piece? That is five hours just to get the data! With this neural network, we can quickly compute energies. For example, this shows we get about 10000 energy calculations in just 287 ms.
</p>

<div class="org-src-container">
<pre class="src src-ipython">%%timeit

<span style="color: #BA36A5;">dfit</span> = np.linspace(<span style="color: #006FE0;">min</span>(d), <span style="color: #006FE0;">max</span>(d), 10000)
<span style="color: #BA36A5;">efit</span> = nn.predict(np.row_stack(dfit))
</pre>
</div>

<p>
1 loop, best of 3: 287 ms per loop
</p>

<p>
Compare that to the time it took to compute the 300 energies with EMT
</p>

<div class="org-src-container">
<pre class="src src-ipython">%%timeit
<span style="color: #BA36A5;">E</span> = np.array([get_e(dist) <span style="color: #0000FF;">for</span> dist <span style="color: #0000FF;">in</span> D])
</pre>
</div>

<p>
1 loop, best of 3: 230 ms per loop
</p>

<p>
The neural network is a lot faster than the way we get the EMT energies!
</p>

<p>
It is true in this case we could have used a spline, or interpolating function and it would likely be even better than this Neural Network. We are aiming to get more complicated soon though. For a trimer, we will have three dimensions to worry about, and that can still be worked out in a similar fashion I think. Past that, it becomes too hard to reduce the dimensions, and this approach breaks down. Then we have to try something else. We will get to that in another post.
</p>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/03/18/Modeling-a-Cu-dimer-by-EMT,-nonlinear-regression-and-neural-networks.org">org-mode source</a></p>
<p>Org-mode version = 9.0.5</p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Share on Twitter</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>


<a href="https://twitter.com/search?q=https://kitchingroup.cheme.cmu.edu/blog/2017/03/18/Modeling-a-Cu-dimer-by-EMT-nonlinear-regression-and-neural-networks">Discuss on Twitter</a>

  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="New-publication-in-Calphad"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/02/05/New-publication-in-Calphad/" rel="bookmark" title="Permanent Link to New publication in Calphad">New publication in Calphad</a></h2>
      <p><small><span class="blog_post_date">Posted February 05, 2017 at 12:28 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/publication/'>publication</a>, <a href='/blog/category/news/'>news</a></span> | tags: 
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
Alloys can have rich, complex phase behavior. Cu-Pd alloys for example show an unusual behavior where a BCC lattice forms for some compositions, even though the alloy is made from two metals that are exclusively FCC in structure! Being able to model and predict this kind of behavior is a major challenge. In this work, we use cluster expansions to model the configurational degrees of freedom in the FCC and BCC lattices and show qualitatively that we can predict the region where the B2 phase (the BCC one) forms. The agreement with experiment is not quantitative though, and we show that part this disagreement is due to the lack of vibrational entropy in the cluster expansion. When we include vibrational entropy, the qualitative agreement improves.
</p>

<div class="org-src-container">
<pre class="src src-bibtex"><span style="color: #006699;">@article</span>{<span style="color: #D0372D;">geng-2017-first-princ</span>,
  <span style="color: #BA36A5;">author</span> =       "Feiyang Geng and Jacob R. Boes and John R. Kitchin",
  <span style="color: #BA36A5;">title</span> =        {First-Principles Study of the Cu-Pd Phase Diagram},
  <span style="color: #BA36A5;">journal</span> =      "Calphad ",
  <span style="color: #BA36A5;">volume</span> =       56,
  <span style="color: #BA36A5;">pages</span> =        "224 - 229",
  <span style="color: #BA36A5;">year</span> =         2017,
  <span style="color: #BA36A5;">doi</span> =          {<span style="color: #006DAF; text-decoration: underline;">10.1016/j.calphad.2017.01.009</span>},
  <span style="color: #BA36A5;">url</span> =
                  {https://doi.org/https://doi.org/10.1016/j.calphad.2017.01.009},
  <span style="color: #BA36A5;">abstract</span> =     "Abstract The equilibrium phase diagram of a Cu-Pd alloy has
                  been computed using cluster expansion and Monte Carlo
                  simulation methods combined with density functional theory.
                  The computed phase boundaries show basic features that are
                  consistent with the experimentally reported phase diagram.
                  Without vibrational free energy contributions, the
                  order-disorder transition temperature is underestimated by 100
                  K and the critical point is inconsistent with experimental
                  result. The addition of vibrational free energy contributions
                  yields a more qualitatively correct Cu-Pd phase diagram in the
                  Cu rich region. ",
  <span style="color: #BA36A5;">issn</span> =         "0364-5916",
  <span style="color: #BA36A5;">keywords</span> =     "Density functional theory",
}
</pre>
</div>

<p>
<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
<div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1016/j.calphad.2017.01.009'></div>
</p>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/02/05/New-publication-in-Calphad.org">org-mode source</a></p>
<p>Org-mode version = 9.0.3</p>


    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Share on Twitter</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>


<a href="https://twitter.com/search?q=https://kitchingroup.cheme.cmu.edu/blog/2017/02/05/New-publication-in-Calphad">Discuss on Twitter</a>

  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="New-publication-in-Molecular-Simulation"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/02/01/New-publication-in-Molecular-Simulation/" rel="bookmark" title="Permanent Link to New publication in Molecular Simulation">New publication in Molecular Simulation</a></h2>
      <p><small><span class="blog_post_date">Posted February 01, 2017 at 07:22 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/publication/'>publication</a>, <a href='/blog/category/news/'>news</a></span> | tags: 
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
Molecules interact with each other when they adsorb on surfaces and these interactions are coverage dependent. Modeling these interactions is a challenge though, because there are many configurations of adsorbates on the surface, and the surface changes due to the interactions. To mitigate these challenges, one often simplifies the model, e.g. by using a cluster expansion or lattice gas Hamiltonian. These approaches have their own limitations though, and are not that useful for modeling dynamic processes like diffusion. Using molecular potentials enables the dynamic simulations, but not at the same level of accuracy as density functional theory. In this work we use density functional theory to train a neural network, and then use the neural network to model coverage-dependent adsorption isotherms and the dynamics of oxygen diffusion on a Pd(111) surface. We show the neural network can capture the onset of surface oxidation, and that the simulation results have comparable accuracy to the DFT calculations it was trained from.
</p>

<div class="org-src-container">
<pre class="src src-bibtex"><span style="color: #006699;">@article</span>{<span style="color: #D0372D;">boes-2017-neural-networ</span>,
  <span style="color: #BA36A5;">author</span> =       {Jacob R. Boes and John R. Kitchin},
  <span style="color: #BA36A5;">title</span> =        {Neural Network Predictions of Oxygen Interactions on a Dynamic
                  Pd Surface},
  <span style="color: #BA36A5;">journal</span> =      {Molecular Simulation},
  <span style="color: #BA36A5;">pages</span> =        {1-9},
  <span style="color: #BA36A5;">year</span> =         2017,
  <span style="color: #BA36A5;">doi</span> =          {<span style="color: #006DAF; text-decoration: underline;">10.1080/08927022.2016.1274984</span>},
  <span style="color: #BA36A5;">url</span> =          {<span style="color: #006DAF; text-decoration: underline;">https://doi.org/10.1080/08927022.2016.1274984</span>},
  <span style="color: #BA36A5;">keywords</span> =     {CBET-1506770},
}
</pre>
</div>

<p>
<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
<div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1080/08927022.2016.1274984'></div>
</p>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/02/01/New-publication-in-Molecular-Simulation.org">org-mode source</a></p>
<p>Org-mode version = 9.0.3</p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Share on Twitter</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>


<a href="https://twitter.com/search?q=https://kitchingroup.cheme.cmu.edu/blog/2017/02/01/New-publication-in-Molecular-Simulation">Discuss on Twitter</a>

  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="New-publication-in-J-Phys-Chem-C"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/01/31/New-publication-in-J-Phys-Chem-C/" rel="bookmark" title="Permanent Link to New publication in J. Phys. Chem. C">New publication in J. Phys. Chem. C</a></h2>
      <p><small><span class="blog_post_date">Posted January 31, 2017 at 09:30 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/publication/'>publication</a>, <a href='/blog/category/news/'>news</a></span> | tags: 
      <p><small><span class="blog_post_date">Updated June 28, 2021 at 01:31 PM</span></small>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
The surface composition of an alloy is rarely the same as the bulk composition due to segregation, and it changes with changing reaction conditions. Segregation is a ubiquitous issue in alloy catalysis, and makes modeling alloy surfaces a challenge, because we need to know the surface composition to model them! In this work, we take a first step in using density functional theory to build a neural network potential that we can use with Monte Carlo simulations to predict the temperature dependent surface composition of an Au-Pd bulk alloy in a vacuum. This approach yielded quantitative predictions in good agreement with experimental measurements over the entire bulk composition range.
</p>

<div class="org-src-container">
<pre class="src src-bibtex"><span style="color: #006699;">@article</span>{<span style="color: #D0372D;">boes-2017-model-segreg</span>,
  <span style="color: #BA36A5;">author</span> =       {Jacob R. Boes and John R. Kitchin},
  <span style="color: #BA36A5;">title</span> =        {Modeling Segregation on AuPd(111) Surfaces With Density
                  Functional Theory and Monte Carlo Simulations},
  <span style="color: #BA36A5;">journal</span> =      {The Journal of Physical Chemistry C},
  <span style="color: #BA36A5;">volume</span> =       121,
  <span style="color: #BA36A5;">number</span> =       6,
  <span style="color: #BA36A5;">pages</span> =        {3479-3487},
  <span style="color: #BA36A5;">year</span> =         2017,
  <span style="color: #BA36A5;">doi</span> =          {<span style="color: #006DAF; text-decoration: underline;">10.1021/acs.jpcc.6b12752</span>},
  <span style="color: #BA36A5;">url</span> =          {<span style="color: #006DAF; text-decoration: underline;">https://doi.org/10.1021/acs.jpcc.6b12752</span>},
  <span style="color: #BA36A5;">eprint</span> =       { https://doi.org/10.1021/acs.jpcc.6b12752 },
}

</pre>
</div>

<p>
<script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
<div data-badge-type='medium-donut' class='altmetric-embed' data-badge-details='right' data-doi='10.1021/acs.jpcc.6b12752'></div>
</p>
<p>Copyright (C) 2021 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/01/31/New-publication-in-J.-Phys.-Chem.-C.org">org-mode source</a></p>
<p>Org-mode version = 9.4.6</p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Share on Twitter</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>


<a href="https://twitter.com/search?q=https://kitchingroup.cheme.cmu.edu/blog/2017/01/31/New-publication-in-J-Phys-Chem-C">Discuss on Twitter</a>

  <hr class="interblog" />
 <a href="../24">« Previous Page</a>
  --  
 <a href="../26">Next Page »</a>

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2025/06/22/Lies-damn-lies-statistics-and-Bayesian-statistics/">Lies, damn lies, statistics and Bayesian statistics</a></li>
      <li><a href="/blog/2025/06/17/New-Publication-Solving-an-inverse-problem-with-generative-models/">New Publication - Solving an inverse problem with generative models</a></li>
      <li><a href="/blog/2025/05/07/New-publication-The-Evolving-Role-of-Programming-and-Llms-in-the-Development-of-Self-Driving-Laboratories/">New publication - The Evolving Role of Programming and Llms in the Development of Self-Driving Laboratories</a></li>
      <li><a href="/blog/2025/04/11/New-publication-A-Classification-based-Methodology-for-the-Estimation-of-Binary-Surfactant-Critical-Micelle-Concentrations/">New publication - A Classification-based Methodology for the Estimation of Binary Surfactant Critical Micelle Concentrations</a></li>
      <li><a href="/blog/2025/03/17/New-publication-CatTsunami-Accelerating-Transition-State-Energy-Calculations-With-Pretrained-Graph-Neural-Networks/">New publication - CatTsunami Accelerating Transition State Energy Calculations With Pretrained Graph Neural Networks</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2025
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
 
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PH8NF4F0RE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PH8NF4F0RE');
</script>


  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



