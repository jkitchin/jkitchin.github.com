

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Kitchin Research Group</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>
      <li><a href="/group.html">Group</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            
  





<article>
  <div class="blog_post">
    <header>
      <div id="Uncertainty-in-polynomial-roots-Part-II"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/07/06/Uncertainty-in-polynomial-roots-Part-II/" rel="bookmark" title="Permanent Link to Uncertainty in polynomial roots - Part II">Uncertainty in polynomial roots - Part II</a></h2>
      <p><small><span class="blog_post_date">Posted July 06, 2013 at 03:31 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/uncertainty/'>uncertainty</a>, <a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/07/06/Uncertainty-in-polynomial-roots-Part-II#disqus_thread">View Comments</a>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
We previously looked at uncertainty in polynomial roots where we had an analytical formula for the roots of the polynomial, and we knew the uncertainties in the polynomial parameters. It would be inconvenient to try this for a cubic polynomial, although there may be formulas for the roots. I do not know of there are general formulas for the roots of a 4<sup>th</sup> order polynomial or higher. 
</p>

<p>
Unfortunately, we cannot use the uncertainties package out of the box directly here.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

A = u.ufloat((a, sa))
B = u.ufloat((b, sb))
C = u.ufloat((c, sc))

<span style="color: #8b0000;">print</span> np.roots([A, B, C])
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "c:\Users\jkitchin\AppData\Local\Enthought\Canopy\User\lib\site-packages\numpy\lib\polynomial.py", line 218, in roots
    p = p.astype(float)
  File "c:\Users\jkitchin\AppData\Local\Enthought\Canopy\User\lib\site-packages\uncertainties\__init__.py", line 1257, in raise_error
    % (self.__class__, coercion_type))
TypeError: can't convert an affine function (&lt;class 'uncertainties.Variable'&gt;) to float; use x.nominal_value
</pre>

<p>
To make some progress, we have to understand how the <a href="https://github.com/numpy/numpy/blob/v1.7.0/numpy/lib/polynomial.py#L149">numpy.roots</a> function works. It constructs a <a href="http://en.wikipedia.org/wiki/Companion_matrix">Companion matrix</a>, and the eigenvalues of that matrix are the same as the roots of the polynomial.  
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

c0, c1, c2 = [-0.99526746, -0.011546,    1.00188999]

p = np.array([c2, c1, c0])
N = <span style="color: #8b0000;">len</span>(p)

<span style="color: #ff0000; font-weight: bold;"># we construct the companion matrix like this</span>
<span style="color: #ff0000; font-weight: bold;"># see https://github.com/numpy/numpy/blob/v1.7.0/numpy/lib/polynomial.py#L220</span>
<span style="color: #ff0000; font-weight: bold;"># for this code.</span>
<span style="color: #ff0000; font-weight: bold;"># build companion matrix and find its eigenvalues (the roots)</span>
A = np.diag(np.ones((N-2,), p.dtype), -1)
A[0, :] = -p[1:] / p[0]

<span style="color: #8b0000;">print</span> A

roots = np.linalg.eigvals(A)
<span style="color: #8b0000;">print</span> roots
</pre>
</div>

<pre class="example">
[[ 0.01152422  0.99338996]
 [ 1.          0.        ]]
[ 1.00246827 -0.99094405]
</pre>

<p>
This definition of the companion matrix is a little different than the one <a href="http://en.wikipedia.org/wiki/Companion_matrix">here</a>, but primarily in the scaling of the coefficients. That does not seem to change the eigenvalues, or the roots. 
</p>

<p>
Now, we have a path to estimate the uncertainty in the roots. Since we know the polynomial coefficients and their uncertainties from the fit, we can use Monte Carlo sampling to estimate the uncertainty in the roots. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u

c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

NSAMPLES = 100000
A = np.random.normal(a, sa, (NSAMPLES, ))
B = np.random.normal(b, sb, (NSAMPLES, ))
C = np.random.normal(c, sc, (NSAMPLES, ))

roots = [[] <span style="color: #8b0000;">for</span> i <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">range</span>(NSAMPLES)]

<span style="color: #8b0000;">for</span> i <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">range</span>(NSAMPLES):
    p = np.array([A[i], B[i], C[i]])
    N = <span style="color: #8b0000;">len</span>(p)
    
    M = np.diag(np.ones((N-2,), p.dtype), -1)
    M[0, :] = -p[1:] / p[0]
    r = np.linalg.eigvals(M)
    r.sort()  <span style="color: #ff0000; font-weight: bold;"># there is no telling what order the values come out in</span>
    roots[i] = r
    
avg = np.average(roots, axis=0)
std = np.std(roots, axis=0)

<span style="color: #8b0000;">for</span> r, s <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(avg, std):
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'{0: f} +/- {1: f}'</span>.format(r, s)
</pre>
</div>

<pre class="example">
-0.990949 +/-  0.013435
 1.002443 +/-  0.013462
</pre>

<p>
Compared to our previous approach with the uncertainties package where we got:
</p>

<pre class="example">
: -0.990944048037+/-0.0134208013339
:  1.00246826738 +/-0.0134477390832
</pre>

<p>
the agreement is quite good! The advantage of this approach is that we do not have to know the formula for the roots of higher order polynomials to estimate the uncertainty in the roots. The downside is we have to evaluate the eigenvalues of a matrix a large number of times to get good estimates of the uncertainty. For high power polynomials this could be problematic. I do not currently see a way around this, unless it becomes possible to get the uncertainties package to propagate through the numpy.eigvals function. It is possible to <a href="http://pythonhosted.org/uncertainties/user_guide.html#making-custom-functions-accept-numbers-with-uncertainties">wrap</a> some functions with uncertainties, but so far only functions that return a single number.
</p>

<p>
There are some other potential problems with this approach.  It is assumed that the accuracy of the eigenvalue solver is much better than the uncertainty in the polynomial parameters. You have to use some judgment in using these uncertainties. We are approximating the uncertainties of a nonlinear problem. In other words, the uncertainties of the roots are not linearly dependent on the uncertainties of the polynomial coefficients.  
</p>

<p>
It is possible to <a href="http://pythonhosted.org/uncertainties/user_guide.html#making-custom-functions-accept-numbers-with-uncertainties">wrap</a> some functions with uncertainties, but so far only functions that return a single number. Here is an example of getting the n<sup>th</sup> root and its uncertainty.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

@u.wrap
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(n=0, *P):
    <span style="color: #228b22;">''' compute the nth root of the polynomial P and the uncertainty of the root'''</span>
    p =  np.array(P)
    N = <span style="color: #8b0000;">len</span>(p)
    
    M = np.diag(np.ones((N-2,), p.dtype), -1)
    M[0, :] = -p[1:] / p[0]
    r = np.linalg.eigvals(M)
    r.sort()  <span style="color: #ff0000; font-weight: bold;"># there is no telling what order the values come out in</span>
    <span style="color: #8b0000;">return</span> r[n]

<span style="color: #ff0000; font-weight: bold;"># our polynomial coefficients and standard errors</span>
c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

A = u.ufloat((a, sa))
B = u.ufloat((b, sb))
C = u.ufloat((c, sc))

<span style="color: #8b0000;">for</span> result <span style="color: #8b0000;">in</span> [f(n, A, B, C) <span style="color: #8b0000;">for</span> n <span style="color: #8b0000;">in</span> [0, 1]]:
    <span style="color: #8b0000;">print</span> result
</pre>
</div>

<pre class="example">
-0.990944048037+/-0.013420800377
1.00246826738+/-0.0134477388218
</pre>

<p>
It is good to see this is the same result we got earlier, with <i>a lot less work</i> (although we do have to solve it for each root, which is a bit redundant)! It is a bit more abstract though, and requires a specific formulation of the function for the wrapper to work.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/07/06/Uncertainty-in-polynomial-roots---Part-II.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/07/06/Uncertainty-in-polynomial-roots-Part-II#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Uncertainty-in-polynomial-roots"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/07/05/Uncertainty-in-polynomial-roots/" rel="bookmark" title="Permanent Link to Uncertainty in polynomial roots">Uncertainty in polynomial roots</a></h2>
      <p><small><span class="blog_post_date">Posted July 05, 2013 at 09:10 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a>, <a href='/blog/category/uncertainty/'>uncertainty</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/07/05/Uncertainty-in-polynomial-roots#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated July 07, 2013 at 08:40 AM</span>
      </small></p>
    </header>
    <div class="post_prose">
      




<p>
Polynomials are convenient for fitting to data. Frequently we need to derive some properties of the data from the fit, e.g. the minimum value, or the slope, etc&#x2026; Since we are fitting data, there is uncertainty in the polynomial parameters, and corresponding uncertainty in any properties derived from those parameters. 
</p>

<p>
Here is our data.
</p>

<table id="data" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col class="right"/>

<col class="right"/>
</colgroup>
<tbody>
<tr>
<td class="right">-3.00</td>
<td class="right">8.10</td>
</tr>

<tr>
<td class="right">-2.33</td>
<td class="right">4.49</td>
</tr>

<tr>
<td class="right">-1.67</td>
<td class="right">1.73</td>
</tr>

<tr>
<td class="right">-1.00</td>
<td class="right">-0.02</td>
</tr>

<tr>
<td class="right">-0.33</td>
<td class="right">-0.90</td>
</tr>

<tr>
<td class="right">0.33</td>
<td class="right">-0.83</td>
</tr>

<tr>
<td class="right">1.00</td>
<td class="right">0.04</td>
</tr>

<tr>
<td class="right">1.67</td>
<td class="right">1.78</td>
</tr>

<tr>
<td class="right">2.33</td>
<td class="right">4.43</td>
</tr>

<tr>
<td class="right">3.00</td>
<td class="right">7.95</td>
</tr>
</tbody>
</table>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

x = [a[0] <span style="color: #8b0000;">for</span> a <span style="color: #8b0000;">in</span> data]
y = [a[1] <span style="color: #8b0000;">for</span> a <span style="color: #8b0000;">in</span> data]
plt.plot(x, y)
plt.savefig(<span style="color: #228b22;">'images/uncertain-roots.png'</span>)
</pre>
</div>

<p><img src="/img/./images/uncertain-roots.png"><p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">from</span> pycse <span style="color: #8b0000;">import</span> regress

x = np.array([a[0] <span style="color: #8b0000;">for</span> a <span style="color: #8b0000;">in</span> data])
y = [a[1] <span style="color: #8b0000;">for</span> a <span style="color: #8b0000;">in</span> data]

A = np.column_stack([x**0, x**1, x**2])

p, pint, se = regress(A, y, alpha=0.05)

<span style="color: #8b0000;">print</span> p

<span style="color: #8b0000;">print</span> pint

<span style="color: #8b0000;">print</span> se

plt.plot(x, y, <span style="color: #228b22;">'bo '</span>)

xfit = np.linspace(x.min(), x.max())
plt.plot(xfit, np.dot(np.column_stack([xfit**0, xfit**1, xfit**2]), p), <span style="color: #228b22;">'b-'</span>)
plt.savefig(<span style="color: #228b22;">'images/uncertain-roots-1.png'</span>)
</pre>
</div>

<pre class="example">
[-0.99526746 -0.011546    1.00188999]
[[-1.05418017 -0.93635474]
 [-0.03188236  0.00879037]
 [ 0.98982737  1.01395261]]
[ 0.0249142   0.00860025  0.00510128]
</pre>

<p><img src="/img/./images/uncertain-roots-1.png"><p>

<p>
Since this is a quadratic equation, we know the roots analytically: \(x = \frac{-b \pm \sqrt{b^2 - 4 a c}{2 a}\). So, we can use the uncertainties package to directly compute the uncertainties in the roots. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u

c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

A = u.ufloat((a, sa))
B = u.ufloat((b, sb))
C = u.ufloat((c, sc))

<span style="color: #ff0000; font-weight: bold;"># np.sqrt does not work with uncertainity</span>
r1 = (-B + (B**2 - 4 * A * C)**0.5) / (2 * A)
r2 = (-B - (B**2 - 4 * A * C)**0.5) / (2 * A)

<span style="color: #8b0000;">print</span> r1
<span style="color: #8b0000;">print</span> r2
</pre>
</div>

<pre class="example">
1.00246826738+/-0.0134477390832
-0.990944048037+/-0.0134208013339
</pre>

<p>
The minimum is also straightforward to analyze here. The derivative of the polynomial is \(2 a x + b\) and it is equal to zero at \(x = -b / (2 a)\).
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u

c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

A = u.ufloat((a, sa))
B = u.ufloat((b, sb))

zero = -B / (2 * A)
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'The minimum is at {0}.'</span>.format(zero)
</pre>
</div>

<pre class="example">
The minimum is at 0.00576210967034+/-0.00429211341136.
</pre>

<p>
You can see there is uncertainty in both the roots of the original polynomial, as well as the minimum of the data. The approach here worked well because the polynomials were low order (quadratic or linear) where we know the formulas for the roots. Consequently, we can take advantage of the uncertainties module with little effort to propagate the errors. For higher order polynomials, we would probably have to do some wrapping of functions to propagate uncertainties.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/07/05/Uncertainty-in-polynomial-roots.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/07/05/Uncertainty-in-polynomial-roots#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Estimating-uncertainties-in-equations-of-state"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/07/04/Estimating-uncertainties-in-equations-of-state/" rel="bookmark" title="Permanent Link to Estimating uncertainties in equations of state">Estimating uncertainties in equations of state</a></h2>
      <p><small><span class="blog_post_date">Posted July 04, 2013 at 03:21 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/uncategorized/'>uncategorized</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/07/04/Estimating-uncertainties-in-equations-of-state#disqus_thread">View Comments</a>
      </small></p>
    </header>
    <div class="post_prose">
      




<p>
We often use DFT to calculate the energy of a unit cell as a function of volume. Then, we fit an equation of state to the data to estimate the volume that minimizes the total energy, and the bulk modulus of the material. 
<a href="10.1016/j.comphys.2003.12.001">10.1016/j.comphys.2003.12.001</a>
</p>



<table id="raw-data" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col class="right"/>

<col class="right"/>
</colgroup>
<thead>
<tr>
<th scope="col" class="right">volume</th>
<th scope="col" class="right">energy</th>
</tr>
</thead>
<tbody>
<tr>
<td class="right">324.85990899</td>
<td class="right">-399.9731688470</td>
</tr>

<tr>
<td class="right">253.43999457</td>
<td class="right">-400.0172393178</td>
</tr>

<tr>
<td class="right">234.03826687</td>
<td class="right">-400.0256270548</td>
</tr>

<tr>
<td class="right">231.12159387</td>
<td class="right">-400.0265690700</td>
</tr>

<tr>
<td class="right">228.40609504</td>
<td class="right">-400.0273551120</td>
</tr>

<tr>
<td class="right">225.86490337</td>
<td class="right">-400.0280030862</td>
</tr>

<tr>
<td class="right">223.47556626</td>
<td class="right">-400.0285313450</td>
</tr>

<tr>
<td class="right">221.21992353</td>
<td class="right">-400.0289534593</td>
</tr>

<tr>
<td class="right">219.08319566</td>
<td class="right">-400.0292800709</td>
</tr>

<tr>
<td class="right">217.05369547</td>
<td class="right">-400.0295224970</td>
</tr>

<tr>
<td class="right">215.12089909</td>
<td class="right">-400.0296863867</td>
</tr>

<tr>
<td class="right">213.27525144</td>
<td class="right">-400.0297809256</td>
</tr>

<tr>
<td class="right">211.51060823</td>
<td class="right">-400.0298110000</td>
</tr>

<tr>
<td class="right">203.66743321</td>
<td class="right">-400.0291665573</td>
</tr>

<tr>
<td class="right">197.07888649</td>
<td class="right">-400.0275017142</td>
</tr>

<tr>
<td class="right">191.39717952</td>
<td class="right">-400.0250998136</td>
</tr>

<tr>
<td class="right">186.40163591</td>
<td class="right">-400.0221371852</td>
</tr>

<tr>
<td class="right">181.94435510</td>
<td class="right">-400.0187369863</td>
</tr>

<tr>
<td class="right">177.92077043</td>
<td class="right">-400.0149820198</td>
</tr>

<tr>
<td class="right">174.25380090</td>
<td class="right">-400.0109367042</td>
</tr>

<tr>
<td class="right">170.88582166</td>
<td class="right">-400.0066495100</td>
</tr>

<tr>
<td class="right">167.76711189</td>
<td class="right">-400.0021478258</td>
</tr>

<tr>
<td class="right">164.87096104</td>
<td class="right">-399.9974753449</td>
</tr>

<tr>
<td class="right">159.62553397</td>
<td class="right">-399.9876885136</td>
</tr>

<tr>
<td class="right">154.97005460</td>
<td class="right">-399.9774175487</td>
</tr>

<tr>
<td class="right">150.78475335</td>
<td class="right">-399.9667603369</td>
</tr>

<tr>
<td class="right">146.97722201</td>
<td class="right">-399.9557686286</td>
</tr>

<tr>
<td class="right">143.49380641</td>
<td class="right">-399.9445262604</td>
</tr>
</tbody>
</table>


<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
<span style="color: #8b0000;">from</span> pycse <span style="color: #8b0000;">import</span> nlinfit

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">data</span>
V = np.array([row[0] <span style="color: #8b0000;">for</span> row <span style="color: #8b0000;">in</span> data]) 
E = np.array([row[1] <span style="color: #8b0000;">for</span> row <span style="color: #8b0000;">in</span> data])

plt.plot(V, E, <span style="color: #228b22;">'.'</span>)
plt.xlabel(<span style="color: #228b22;">'Volume ($\AA^3$)'</span>)
plt.ylabel(<span style="color: #228b22;">'Energy (Ha)'</span>)

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">Murnaghan</span>(vol, E0, B0, BP, V0):
    <span style="color: #228b22;">'''</span>
<span style="color: #228b22;">    given a vector of parameters and volumes, return a vector of energies.</span>
<span style="color: #228b22;">    equation From PRB 28,5480 (1983)</span>
<span style="color: #228b22;">    '''</span>
    
    E = E0 + B0*vol/BP*(((V0/vol)**BP)/(BP-1)+1) - V0*B0/(BP-1.)

    <span style="color: #8b0000;">return</span> E

guess = [-400, 0.5, 2, 210]
pars, pint, SE = nlinfit(Murnaghan, V, E, guess, alpha=0.05)
E0, B0, BP, V0 = pint

Vfit = np.linspace(V.min(), V.max())
plt.plot(Vfit, Murnaghan(Vfit, *pars))
plt.savefig(<span style="color: #228b22;">'images/eos-uncertainty.png'</span>)

<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'95% confidence intervals'</span>
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'V0 = {0} bohr**3'</span>.format(V0)
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'E0 = {0} Ha'</span>.format(E0)
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'B0 = {0} GPA'</span>.format([x * 29421.010901602753 <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> B0])
</pre>
</div>

<pre class="example">
95% confidence intervals
V0 = [212.27788154532402, 213.27897592511891] bohr**3
E0 = [-400.0297027767362, -400.02922937100408] Ha
B0 = [108.62283904402159, 111.20447706313001] GPA
</pre>

<p><img src="/img/./images/eos-uncertainty.png"><p>

<p>
You can see the fit is not perfect, and there is corresponding uncertainty in the estimated parameters. A nice feature of the Murnaghan equation of state is that the parameters are directly the quantities of interest, so the uncertainties are directly calculated here. For other models, e.g. a polynomial fit, you would have to propagate the errors in the parameters to the properties.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/07/04/Estimating-uncertainties-in-equations-of-state.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/07/04/Estimating-uncertainties-in-equations-of-state#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Estimating-where-two-functions-intersect-using-data"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/07/04/Estimating-where-two-functions-intersect-using-data/" rel="bookmark" title="Permanent Link to Estimating where two functions intersect using data">Estimating where two functions intersect using data</a></h2>
      <p><small><span class="blog_post_date">Posted July 04, 2013 at 02:38 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/07/04/Estimating-where-two-functions-intersect-using-data#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated July 07, 2013 at 09:01 AM</span>
      </small></p>
    </header>
    <div class="post_prose">
      




<p>
Suppose we have two functions described by this data:
</p>

<table id="data" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col class="right"/>

<col class="right"/>

<col class="right"/>
</colgroup>
<thead>
<tr>
<th scope="col" class="right">T(K)</th>
<th scope="col" class="right">E1</th>
<th scope="col" class="right">E2</th>
</tr>
</thead>
<tbody>
<tr>
<td class="right">300</td>
<td class="right">-208</td>
<td class="right">-218</td>
</tr>

<tr>
<td class="right">400</td>
<td class="right">-212</td>
<td class="right">-221</td>
</tr>

<tr>
<td class="right">500</td>
<td class="right">-215</td>
<td class="right">-220</td>
</tr>

<tr>
<td class="right">600</td>
<td class="right">-218</td>
<td class="right">-222</td>
</tr>

<tr>
<td class="right">700</td>
<td class="right">-220</td>
<td class="right">-222</td>
</tr>

<tr>
<td class="right">800</td>
<td class="right">-223</td>
<td class="right">-224</td>
</tr>

<tr>
<td class="right">900</td>
<td class="right">-227</td>
<td class="right">-225</td>
</tr>

<tr>
<td class="right">1000</td>
<td class="right">-229</td>
<td class="right">-227</td>
</tr>

<tr>
<td class="right">1100</td>
<td class="right">-233</td>
<td class="right">-228</td>
</tr>

<tr>
<td class="right">1200</td>
<td class="right">-235</td>
<td class="right">-227</td>
</tr>

<tr>
<td class="right">1300</td>
<td class="right">-240</td>
<td class="right">-229</td>
</tr>
</tbody>
</table>

<p>
We want to determine the temperature at which they intersect, and more importantly what the uncertainty on the intersection is. There is noise in the data, which means there is uncertainty in any function that could be fit to it, and that uncertainty would propagate to the intersection. Let us examine the data.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

T = [x[0] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data]
E1 = [x[1] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data]
E2 = [x[2] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data]

plt.plot(T, E1, T, E2)
plt.legend([<span style="color: #228b22;">'E1'</span>, <span style="color: #228b22;">'E2'</span>])
plt.savefig(<span style="color: #228b22;">'images/intersection-0.png'</span>)
</pre>
</div>

<p><img src="/img/./images/intersection-0.png"><p>

<p>
Our strategy is going to be to fit functions to each data set, and get the confidence intervals on the parameters of the fit. Then, we will solve the equations to find where they are equal to each other and propagate the uncertainties in the parameters to the answer.
</p>

<p>
These functions look approximately linear, so we will fit lines to each function. We use the regress function in pycse to get the uncertainties on the fits. Then, we use the uncertainties package to propagate the uncertainties in the analytical solution to the intersection of two lines.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">from</span> pycse <span style="color: #8b0000;">import</span> regress
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
<span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u

T = np.array([x[0] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data])
E1 = np.array([x[1] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data])
E2 = np.array([x[2] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data])

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">columns of the x-values for a line: constant, T</span>
A = np.column_stack([T**0, T])

p1, pint1, se1 = regress(A, E1, alpha=0.05)

p2, pint2, se2 = regress(A, E2, alpha=0.05)

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">Now we have two lines: y1 = m1*T + b1 and y2 = m2*T + b2</span>
<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">they intersect at m1*T + b1 = m2*T + b2</span>
<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">or at T = (b2 - b1) / (m1 - m2)</span>
b1 = u.ufloat((p1[0], se1[0]))
m1 = u.ufloat((p1[1], se1[1]))

b2 = u.ufloat((p2[0], se2[0]))
m2 = u.ufloat((p2[1], se2[1]))

T_intersection = (b2 - b1) / (m1 - m2)
<span style="color: #8b0000;">print</span> T_intersection

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">plot the data, the fits and the intersection and \pm 2 \sigma.</span>
plt.plot(T, E1, <span style="color: #228b22;">'bo '</span>, label=<span style="color: #228b22;">'E1'</span>)
plt.plot(T, np.dot(A,p1), <span style="color: #228b22;">'b-'</span>)
plt.plot(T, E2, <span style="color: #228b22;">'ro '</span>, label=<span style="color: #228b22;">'E2'</span>)
plt.plot(T, np.dot(A,p2), <span style="color: #228b22;">'r-'</span>)

plt.plot(T_intersection.nominal_value,
        (b1 + m1*T_intersection).nominal_value, <span style="color: #228b22;">'go'</span>,
        ms=13, alpha=0.2, label=<span style="color: #228b22;">'Intersection'</span>)
plt.plot([T_intersection.nominal_value - 2*T_intersection.std_dev(),
          T_intersection.nominal_value + 2*T_intersection.std_dev()],
         [(b1 + m1*T_intersection).nominal_value, 
          (b1 + m1*T_intersection).nominal_value],
         <span style="color: #228b22;">'g-'</span>, lw=3, label=<span style="color: #228b22;">'$\pm 2 \sigma$'</span>)
       
plt.legend(loc=<span style="color: #228b22;">'best'</span>)
plt.savefig(<span style="color: #228b22;">'images/intersection-1.png'</span>)
</pre>
</div>

<pre class="example">
813.698630137+/-62.407180552
</pre>

<p><img src="/img/./images/intersection-1.png"><p>

<p>
You can see there is a substantial uncertainty in the temperature at approximately the 90% confidence level (&plusmn; 2 &sigma;).
</p>


<p>
<span class="underline">Update 7-7-2013</span>
</p>

<p>
After a suggestion from Prateek, here we subtract the two data sets, fit a line to that data, and then use fsolve to find the zero. We <a href="http://pythonhosted.org/uncertainties/user_guide.html#making-custom-functions-accept-numbers-with-uncertainties">wrap</a> fsolve in the uncertainties package to directly get the uncertainty on the root. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">from</span> pycse <span style="color: #8b0000;">import</span> regress
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
<span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u
<span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> fsolve


T = np.array([x[0] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data])
E1 = np.array([x[1] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data])
E2 = np.array([x[2] <span style="color: #8b0000;">for</span> x <span style="color: #8b0000;">in</span> data])

E = E1 - E2

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">columns of the x-values for a line: constant, T</span>
A = np.column_stack([T**0, T])

p, pint, se = regress(A, E, alpha=0.05)

b = u.ufloat((p[0], se[0]))
m = u.ufloat((p[1], se[1]))

@u.wrap
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(b, m):
    X, = fsolve(<span style="color: #8b0000;">lambda</span> x: b + m * x, 800)
    <span style="color: #8b0000;">return</span> X

<span style="color: #8b0000;">print</span> f(b, m)
</pre>
</div>

<pre class="example">
813.698630137+/-54.0386903923
</pre>

<p>
Interesting that this uncertainty is a little smaller than the previously computed uncertainty. Here you can see we have to wrap the function in a peculiar way. The function must return a single float number, and take arguments with uncertainty. We define the polynomial fit (a line in this case) in a lambda function inside the function. It works ok.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/07/04/Estimating-where-two-functions-intersect-using-data.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/07/04/Estimating-where-two-functions-intersect-using-data#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Memoizing-instance-methods-in-a-class"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/06/26/Memoizing-instance-methods-in-a-class/" rel="bookmark" title="Permanent Link to Memoizing instance methods in a class">Memoizing instance methods in a class</a></h2>
      <p><small><span class="blog_post_date">Posted June 26, 2013 at 06:32 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/programming/'>programming</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/06/26/Memoizing-instance-methods-in-a-class#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated June 28, 2013 at 07:10 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
Suppose you have a module that you import a class from, and the class defines some methods that you want to memoize. You do not want to modify the source code, maybe because it is not your code, or because you do not want to maintain it, etc&#x2026; Here is one way to modify the class functions at runtime. We will use the memoize decorator and replace the class function definition with the wrapped function that caches the results. We also allow arbitrary arguments and keyword arguments. A subtle wrinkle here is that you cannot use a dictionary as a key to a dictionary because dictionaries are not hashable. We use the pickle module to created a string that should uniquely represent the args and keyword args, and we use that string as the key.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">class</span> <span style="color: #4682b4;">Calculator</span>:
    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">__init__</span>(<span style="color: #8b0000;">self</span>):
        <span style="color: #8b0000;">pass</span>

    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">calculate</span>(<span style="color: #8b0000;">self</span>, a):
        <span style="color: #228b22;">'returns the answer to everything'</span>
        <span style="color: #8b0000;">return</span> 42

    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">method_2</span>(<span style="color: #8b0000;">self</span>, *args, **kwargs):
        <span style="color: #8b0000;">return</span> (args, kwargs)


<span style="color: #8b0000;">import</span> pickle

<span style="color: #8b0000;">from</span> functools <span style="color: #8b0000;">import</span> wraps
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">memoize</span>(func):
    cache = {}
    <span style="color: #8b0000;">@wraps</span>(func)
    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">wrap</span>(*args,**kwargs):
        key = pickle.dumps((args, kwargs))
        <span style="color: #8b0000;">if</span> key <span style="color: #8b0000;">not</span> <span style="color: #8b0000;">in</span> cache:
            <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'Running func with '</span>, args
            cache[key] = func(*args, **kwargs)
        <span style="color: #8b0000;">else:</span>
            <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'result in cache'</span>
        <span style="color: #8b0000;">return</span> cache[key]
    <span style="color: #8b0000;">return</span> wrap

<span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">now monkey patch/decorate the class function</span>
Calculator.calculate = memoize(Calculator.calculate)
Calculator.method_2 = memoize(Calculator.method_2)

calc = Calculator()
<span style="color: #8b0000;">print</span> calc.calculate(3)
<span style="color: #8b0000;">print</span> calc.calculate(3)
<span style="color: #8b0000;">print</span> calc.calculate(4)
<span style="color: #8b0000;">print</span> calc.calculate(3)


<span style="color: #8b0000;">print</span> calc.method_2()
<span style="color: #8b0000;">print</span> calc.method_2()

<span style="color: #8b0000;">print</span> calc.method_2(1,2)
<span style="color: #8b0000;">print</span> calc.method_2(1,2)

<span style="color: #8b0000;">print</span> calc.method_2(1,2,a=5)
<span style="color: #8b0000;">print</span> calc.method_2(1,2,a=5)
</pre>
</div>

<pre class="example">
Running func with  (&lt;__main__.Calculator instance at 0x0000000001E9B3C8&gt;, 3)
42
result in cache
42
Running func with  (&lt;__main__.Calculator instance at 0x0000000001E9B3C8&gt;, 4)
42
result in cache
42
Running func with  (&lt;__main__.Calculator instance at 0x0000000001E9B3C8&gt;,)
((), {})
result in cache
((), {})
Running func with  (&lt;__main__.Calculator instance at 0x0000000001E9B3C8&gt;, 1, 2)
((1, 2), {})
result in cache
((1, 2), {})
Running func with  (&lt;__main__.Calculator instance at 0x0000000001E9B3C8&gt;, 1, 2)
((1, 2), {'a': 5})
result in cache
((1, 2), {'a': 5})
</pre>

<p>
This particular memoize decorator is not persistent; the data is only stored in memory. You would have to write the data out to a file and reread the file to make it persistent.
</p>

<p>
It is not obvious this practice is good; you have in essence changed the behavior of the original function in a way that may be hard to debug, and could conceivably be incompatible with the documentation of the function.
</p>

<p>
An alternative approach is writing another function that wraps the code you want, and memoize that function.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">class</span> <span style="color: #4682b4;">Calculator</span>:
    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">__init__</span>(<span style="color: #8b0000;">self</span>):
        <span style="color: #8b0000;">pass</span>

    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">calculate</span>(<span style="color: #8b0000;">self</span>, a):
        <span style="color: #228b22;">'returns the answer to everything'</span>
        <span style="color: #8b0000;">return</span> 42



<span style="color: #8b0000;">from</span> functools <span style="color: #8b0000;">import</span> wraps
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">memoize</span>(func):
    cache = {}
    <span style="color: #8b0000;">@wraps</span>(func)
    <span style="color: #8b0000;">def</span> <span style="color: #8b2323;">wrap</span>(*args):
        <span style="color: #8b0000;">if</span> args <span style="color: #8b0000;">not</span> <span style="color: #8b0000;">in</span> cache:
            <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'Running func with '</span>, args
            cache[args] = func(*args)
        <span style="color: #8b0000;">else:</span>
            <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'result in cache'</span>
        <span style="color: #8b0000;">return</span> cache[args]
    <span style="color: #8b0000;">return</span> wrap

calc = Calculator()

<span style="color: #8b0000;">@memoize</span>
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">my_calculate</span>(a):
    <span style="color: #8b0000;">return</span> calc.calculate(a)

<span style="color: #8b0000;">print</span> my_calculate(3)
<span style="color: #8b0000;">print</span> my_calculate(3)
<span style="color: #8b0000;">print</span> my_calculate(4)
<span style="color: #8b0000;">print</span> my_calculate(3)
</pre>
</div>

<pre class="example">
Running func with  (3,)
42
result in cache
42
Running func with  (4,)
42
result in cache
42
</pre>

<p>
It is debatable whether this is cleaner. One argument for this is that it does not monkey with the original code at all.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/06/26/Memoizing-instance-methods-in-a-class.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/06/26/Memoizing-instance-methods-in-a-class#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="../75">« Previous Page</a>
  --  
 <a href="../77">Next Page »</a>

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2018/10/11/A-differentiable-ODE-integrator-for-sensitivity-analysis/">A differentiable ODE integrator for sensitivity analysis</a></li>
      <li><a href="/blog/2018/10/10/Autograd-and-the-derivative-of-an-integral-function/">Autograd and the derivative of an integral function</a></li>
      <li><a href="/blog/2018/10/09/Compressibility-variation-from-an-implicit-equation-of-state/">Compressibility variation from an implicit equation of state</a></li>
      <li><a href="/blog/2018/10/08/Getting-derivatives-from-implicit-functions-with-autograd/">Getting derivatives from implicit functions with autograd</a></li>
      <li><a href="/blog/2018/10/07/Compressibility-factor-variation-from-the-van-der-Waals-equation-by-three-different-approaches/">Compressibility factor variation from the van der Waals equation by three different approaches</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
        <a href="http://kitchinresearchgroup.disqus.com/latest.rss">Comments RSS Feed</a>.
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2018
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>
  <script>
  (function() {
      var links = document.getElementsByTagName('a');
      var query = '?';
      for(var i = 0; i < links.length; i++) {
          if(links[i].href.indexOf('#disqus_thread') >= 0) {
              query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
          }
      }
      document.write('<script charset="utf-8" type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/get_num_replies.js' + query + '"></' + 'script>');
  })();
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



