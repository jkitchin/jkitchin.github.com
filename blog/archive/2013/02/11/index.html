

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Kitchin Research Group</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>
      <li><a href="/group.html">Group</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            
  





<article>
  <div class="blog_post">
    <header>
      <div id="Graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression/" rel="bookmark" title="Permanent Link to Graphical methods to help get initial guesses for multivariate nonlinear regression">Graphical methods to help get initial guesses for multivariate nonlinear regression</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a>, <a href='/blog/category/plotting/'>plotting</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:40 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
<a href="http://matlab.cheme.cmu.edu/2011/10/09/graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression/" >Matlab post</a>
</p>

<p>
Fit the model f(x1,x2; a,b) = a*x1 + x2^b to the data given below. This model has two independent variables, and two parameters.
</p>

<p>
We want to do a nonlinear fit to find a and b that minimize the summed squared errors between the model predictions and the data. With only two variables, we can graph how the summed squared error varies with the parameters, which may help us get initial guesses. Let us assume the parameters lie in a range, here we choose 0 to 5. In other problems you would adjust this as needed.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">from</span> mpl_toolkits.mplot3d <span style="color: #8b0000;">import</span> Axes3D
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

x1 = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
x2 = [0.2, 0.4, 0.8, 0.9, 1.1, 2.1]
X = np.column_stack([x1, x2]) <span style="color: #ff0000; font-weight: bold;"># independent variables</span>

f = [ 3.3079,    6.6358,   10.3143,   13.6492,   17.2755,   23.6271]

fig = plt.figure()
ax = fig.gca(projection = <span style="color: #228b22;">'3d'</span>)

ax.plot(x1, x2, f)
ax.set_xlabel(<span style="color: #228b22;">'x1'</span>)
ax.set_ylabel(<span style="color: #228b22;">'x2'</span>)
ax.set_zlabel(<span style="color: #228b22;">'f(x1,x2)'</span>)

plt.savefig(<span style="color: #228b22;">'images/graphical-mulvar-1.png'</span>)


arange = np.linspace(0,5);
brange = np.linspace(0,5);

A,B = np.meshgrid(arange, brange)

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">model</span>(X, a, b):
    <span style="color: #228b22;">'Nested function for the model'</span>
    x1 = X[:, 0]
    x2 = X[:, 1]
    
    f = a * x1 + x2**b
    <span style="color: #8b0000;">return</span> f

<span style="color: #8b0000;">@np</span>.vectorize
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">errfunc</span>(a, b):
    <span style="color: #ff0000; font-weight: bold;"># function for the summed squared error</span>
    fit = model(X, a, b)
    sse = np.sum((fit - f)**2)
    <span style="color: #8b0000;">return</span> sse

SSE = errfunc(A, B)

plt.clf()
plt.contourf(A, B, SSE, 50)
plt.plot([3.2], [2.1], <span style="color: #228b22;">'ro'</span>)
plt.figtext( 3.4, 2.2, <span style="color: #228b22;">'Minimum near here'</span>, color=<span style="color: #228b22;">'r'</span>)

plt.savefig(<span style="color: #228b22;">'images/graphical-mulvar-2.png'</span>)

guesses = [3.18, 2.02]

<span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> curve_fit

popt, pcov = curve_fit(model, X, f, guesses)
<span style="color: #8b0000;">print</span> popt

plt.plot([popt[0]], [popt[1]], <span style="color: #228b22;">'r*'</span>)
plt.savefig(<span style="color: #228b22;">'images/graphical-mulvar-3.png'</span>)

<span style="color: #8b0000;">print</span> model(X, *popt)

fig = plt.figure()
ax = fig.gca(projection = <span style="color: #228b22;">'3d'</span>)

ax.plot(x1, x2, f, <span style="color: #228b22;">'ko'</span>, label=<span style="color: #228b22;">'data'</span>)
ax.plot(x1, x2, model(X, *popt), <span style="color: #228b22;">'r-'</span>, label=<span style="color: #228b22;">'fit'</span>)
ax.set_xlabel(<span style="color: #228b22;">'x1'</span>)
ax.set_ylabel(<span style="color: #228b22;">'x2'</span>)
ax.set_zlabel(<span style="color: #228b22;">'f(x1,x2)'</span>)

plt.savefig(<span style="color: #228b22;">'images/graphical-mulvar-4.png'</span>)
</pre>
</div>

<pre class="example">
[ 3.21694798  1.9728254 ]
[  3.25873623   6.59792994  10.29473657  13.68011436  17.29161001
  23.62366445]
</pre>

<p><img src="/img/./images/graphical-mulvar-1.png"><p>

<p><img src="/img/./images/graphical-mulvar-2.png"><p>

<p><img src="/img/./images/graphical-mulvar-3.png"><p>

<p><img src="/img/./images/graphical-mulvar-4.png"><p>

<p>
It can be difficult to figure out initial guesses for nonlinear fitting problems. For one and two dimensional systems, graphical techniques may be useful to visualize how the summed squared error between the model and data depends on the parameters.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Graphical-methods-to-help-get-initial-guesses-for-multivariate-nonlinear-regression#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Integrating-the-batch-reactor-mole-balance"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Integrating-the-batch-reactor-mole-balance/" rel="bookmark" title="Permanent Link to Integrating the batch reactor mole balance">Integrating the batch reactor mole balance</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/ode/'>ode</a></span> | tags: <a href='/blog/tag/reaction-engineering/'>reaction engineering</a>
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Integrating-the-batch-reactor-mole-balance#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated March 03, 2013 at 10:36 AM</span>
      </small></p>
    </header>
    <div class="post_prose">
      




<p>
An alternative approach of evaluating an integral is to integrate a differential equation. For the batch reactor, the differential equation that describes conversion as a function of time is:
</p>

<p>
\(\frac{dX}{dt} = -r_A V/N_{A0}\).
</p>

<p>
Given a value of initial concentration, or volume and initial number of moles of A, we can integrate this ODE to find the conversion at some later time. We assume that \(X(t=0)=0\). We will integrate the ODE over a time span of 0 to 10,000 seconds.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">from</span> scipy.integrate <span style="color: #8b0000;">import</span> odeint
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

k = 1.0e-3
Ca0 = 1.0  <span style="color: #ff0000; font-weight: bold;"># </span><span style="color: #ff0000; font-weight: bold;">mol/L</span>

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">func</span>(X, t):
    ra = -k * (Ca0 * (1 - X))**2
    <span style="color: #8b0000;">return</span> -ra / Ca0

X0 = 0
tspan = np.linspace(0,10000)

sol = odeint(func, X0, tspan)
plt.plot(tspan,sol)
plt.xlabel(<span style="color: #228b22;">'Time (sec)'</span>)
plt.ylabel(<span style="color: #228b22;">'Conversion'</span>)
plt.savefig(<span style="color: #228b22;">'images/2013-01-06-batch-conversion.png'</span>)
</pre>
</div>

<p><img src="/img/./images/2013-01-06-batch-conversion.png"><p>

<p>
You can read off of this figure to find the time required to achieve a particular conversion.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Integrating-the-batch-reactor-mole-balance.org">org-mode source</a><p>


    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Integrating-the-batch-reactor-mole-balance#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Introduction-to-statistical-data-analysis"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Introduction-to-statistical-data-analysis/" rel="bookmark" title="Permanent Link to Introduction to statistical data analysis">Introduction to statistical data analysis</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/statistics/'>statistics</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Introduction-to-statistical-data-analysis#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:34 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
<a href="http://matlab.cheme.cmu.edu/2011/08/27/introduction-to-statistical-data-analysis/" >Matlab post</a>
</p>

<p>
Given several measurements of a single quantity, determine the average value of the measurements, the standard deviation of the measurements and the 95% confidence interval for the average.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

y = [8.1, 8.0, 8.1]

ybar = np.mean(y)
s = np.std(y, ddof=1)

<span style="color: #8b0000;">print</span> ybar, s
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; 8.06666666667 0.057735026919
</pre>

<p>
Interesting, we have to specify the divisor in numpy.std by the ddof argument. The default for this in Matlab is 1, the default for this function is 0.
</p>

<p>
Here is the principle of computing a confidence interval.
</p>

<ol>
<li>compute the average
</li>
<li>Compute the standard deviation of your data
</li>
<li>Define the confidence interval, e.g. 95% = 0.95
</li>
<li>compute the student-t multiplier. This is a function of the
confidence interval you specify, and the number of data points
you have minus 1. You subtract 1 because one degree of freedom
is lost from calculating the average.
</li>
</ol>

<p>
The confidence interval is defined as ybar +- T_multiplier*std/sqrt(n).
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">from</span> scipy.stats.distributions <span style="color: #8b0000;">import</span>  t
ci = 0.95
alpha = 1.0 - ci

n = <span style="color: #8b0000;">len</span>(y)
T_multiplier = t.ppf(1.0 - alpha / 2.0, n - 1)

ci95 = T_multiplier * s / np.sqrt(n)

<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'T_multiplier = {0}'</span>.format(T_multiplier)
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'ci95 = {0}'</span>.format(ci95)
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'The true average is between {0} and {1} at a 95% confidence level'</span>.format(ybar - ci95, ybar + ci95)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; T_multiplier = 4.30265272991
ci95 = 0.143421757664
The true average is between 7.923244909 and 8.21008842433 at a 95% confidence level
</pre>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Introduction-to-statistical-data-analysis.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Introduction-to-statistical-data-analysis#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Linear-least-squares-fitting-with-linear-algebra"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Linear-least-squares-fitting-with-linear-algebra/" rel="bookmark" title="Permanent Link to Linear least squares fitting with linear algebra">Linear least squares fitting with linear algebra</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/linear-algebra/'>linear algebra</a>, <a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Linear-least-squares-fitting-with-linear-algebra#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:38 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
<a href="http://matlab.cheme.cmu.edu/2011/09/24/linear-least-squares-fitting-with-linear-algebra/" >Matlab post</a>
</p>

<p>
The idea here is to formulate a set of linear equations that is easy to solve. We  can express the equations in terms of our unknown fitting parameters \(p_i\) as:
</p>

<pre class="example">
x1^0*p0 + x1*p1 = y1
x2^0*p0 + x2*p1 = y2
x3^0*p0 + x3*p1 = y3
etc...
</pre>

<p>
Which we write in matrix form as \(A p = y\) where \(A\) is a matrix of column vectors, e.g. [1, x_i]. \(A\) is not a square matrix, so we cannot solve it as written. Instead, we form \(A^T A p = A^T y\) and solve that set of equations.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
x = np.array([0, 0.5, 1, 1.5, 2.0, 3.0, 4.0, 6.0, 10])
y = np.array([0, -0.157, -0.315, -0.472, -0.629, -0.942, -1.255, -1.884, -3.147])

A = np.column_stack([x**0, x])

M = np.dot(A.T, A)
b = np.dot(A.T, y)

i1, slope1 = np.dot(np.linalg.inv(M), b)
i2, slope2 = np.linalg.solve(M, b) <span style="color: #ff0000; font-weight: bold;"># an alternative approach.</span>

<span style="color: #8b0000;">print</span> i1, slope1
<span style="color: #8b0000;">print</span> i2, slope2

<span style="color: #ff0000; font-weight: bold;"># plot data and fit</span>
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

plt.plot(x, y, <span style="color: #228b22;">'bo'</span>)
plt.plot(x, np.dot(A, [i1, slope1]), <span style="color: #228b22;">'r--'</span>)
plt.xlabel(<span style="color: #228b22;">'x'</span>)
plt.ylabel(<span style="color: #228b22;">'y'</span>)
plt.savefig(<span style="color: #228b22;">'images/la-line-fit.png'</span>)
</pre>
</div>

<pre class="example">
0.00062457337884 -0.3145221843
0.00062457337884 -0.3145221843
</pre>

<p><img src="/img/./images/la-line-fit.png"><p>

<p>
This method can be readily extended to fitting any polynomial model, or other linear model that is fit in a least squares sense. This method does not provide confidence intervals.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Linear-least-squares-fitting-with-linear-algebra.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Linear-least-squares-fitting-with-linear-algebra#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Linear-regression-with-confidence-intervals"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Linear-regression-with-confidence-intervals/" rel="bookmark" title="Permanent Link to Linear regression with confidence intervals.">Linear regression with confidence intervals.</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a>, <a href='/blog/category/linear-regression/'>linear regression</a>, <a href='/blog/category/confidence-interval/'>confidence interval</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Linear-regression-with-confidence-intervals#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:39 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
<a href="http://matlab.cheme.cmu.edu/2011/08/28/linear-regression-with-confidence-intervals/" >Matlab post</a>
Fit a fourth order polynomial to this data and determine the confidence interval for each parameter. Data from example 5-1 in Fogler, Elements of Chemical Reaction Engineering.
</p>

<p>
We want the equation \(Ca(t) = b0 + b1*t + b2*t^2 + b3*t^3 + b4*t^4\) fit to the data in the least squares sense. We can write this in a linear algebra form as: T*p = Ca where T is a matrix of columns [1 t t^2 t^3 t^4], and p is a column vector of the fitting parameters. We want to solve for the p vector and estimate the confidence intervals.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">from</span> scipy.stats.distributions <span style="color: #8b0000;">import</span>  t

time = np.array([0.0, 50.0, 100.0, 150.0, 200.0, 250.0, 300.0])
Ca = np.array([50.0, 38.0, 30.6, 25.6, 22.2, 19.5, 17.4])*1e-3

T = np.column_stack([time**0, time, time**2, time**3, time**4])

p, res, rank, s = np.linalg.lstsq(T, Ca)
<span style="color: #ff0000; font-weight: bold;"># the parameters are now in p</span>

<span style="color: #ff0000; font-weight: bold;"># compute the confidence intervals</span>
n = <span style="color: #8b0000;">len</span>(Ca)
k = <span style="color: #8b0000;">len</span>(p)

sigma2 = np.sum((Ca - np.dot(T, p))**2) / (n - k)  <span style="color: #ff0000; font-weight: bold;"># RMSE</span>

C = sigma2 * np.linalg.inv(np.dot(T.T, T)) <span style="color: #ff0000; font-weight: bold;"># covariance matrix</span>
se = np.sqrt(np.diag(C)) <span style="color: #ff0000; font-weight: bold;"># standard error</span>

alpha = 0.05 <span style="color: #ff0000; font-weight: bold;"># 100*(1 - alpha) confidence level</span>

sT = t.ppf(1.0 - alpha/2.0, n - k) <span style="color: #ff0000; font-weight: bold;"># student T multiplier</span>
CI = sT * se

<span style="color: #8b0000;">for</span> beta, ci <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(p, CI):
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'{2: 1.2e} [{0: 1.4e} {1: 1.4e}]'</span>.format(beta - ci, beta + ci, beta)

SS_tot = np.sum((Ca - np.mean(Ca))**2)
SS_err = np.sum((np.dot(T, p) - Ca)**2)

<span style="color: #ff0000; font-weight: bold;">#  http://en.wikipedia.org/wiki/Coefficient_of_determination</span>
Rsq = 1 - SS_err/SS_tot
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'R^2 = {0}'</span>.format(Rsq)

<span style="color: #ff0000; font-weight: bold;"># plot fit</span>
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
plt.plot(time, Ca, <span style="color: #228b22;">'bo'</span>, label=<span style="color: #228b22;">'raw data'</span>)
plt.plot(time, np.dot(T, p), <span style="color: #228b22;">'r-'</span>, label=<span style="color: #228b22;">'fit'</span>)
plt.xlabel(<span style="color: #228b22;">'Time'</span>)
plt.ylabel(<span style="color: #228b22;">'Ca (mol/L)'</span>)
plt.legend(loc=<span style="color: #228b22;">'best'</span>)
plt.savefig(<span style="color: #228b22;">'images/linregress-conf.png'</span>)
</pre>
</div>

<pre class="example">
 5.00e-02 [ 4.9680e-02  5.0300e-02]
-2.98e-04 [-3.1546e-04 -2.8023e-04]
 1.34e-06 [ 1.0715e-06  1.6155e-06]
-3.48e-09 [-4.9032e-09 -2.0665e-09]
 3.70e-12 [ 1.3501e-12  6.0439e-12]
R^2 = 0.999986967246
</pre>

<p><img src="/img/./images/linregress-conf.png"><p>

<p>
A fourth order polynomial fits the data well, with a good R^2 value. All of the parameters appear to be significant, i.e. zero is not included in any of the parameter confidence intervals. This does not mean this is the best model for the data, just that the model fits well.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Linear-regression-with-confidence-intervals..org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Linear-regression-with-confidence-intervals#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="../10">« Previous Page</a>
  --  
 <a href="../12">Next Page »</a>

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2019/02/12/Using-results-from-one-code-block-in-another-org-mode/">Using results from one code block in another org-mode</a></li>
      <li><a href="/blog/2018/12/31/2018-in-a-nutshell-for-the-Kitchin-Research-Group/">2018 in a nutshell for the Kitchin Research Group</a></li>
      <li><a href="/blog/2018/11/16/Line-integrals-in-Python-with-autograd/">Line integrals in Python with autograd</a></li>
      <li><a href="/blog/2018/11/05/Using-autograd-for-error-propagation/">Using autograd for error propagation</a></li>
      <li><a href="/blog/2018/11/03/Constrained-optimization-with-Lagrange-multipliers-and-autograd/">Constrained optimization with Lagrange multipliers and autograd</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
        <a href="http://kitchinresearchgroup.disqus.com/latest.rss">Comments RSS Feed</a>.
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2019
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>
  <script>
  (function() {
      var links = document.getElementsByTagName('a');
      var query = '?';
      for(var i = 0; i < links.length; i++) {
          if(links[i].href.indexOf('#disqus_thread') >= 0) {
              query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
          }
      }
      document.write('<script charset="utf-8" type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/get_num_replies.js' + query + '"></' + 'script>');
  })();
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



