

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Kitchin Research Group</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>
      <li><a href="/group.html">Group</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            
  





<article>
  <div class="blog_post">
    <header>
      <div id="Model-selection"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Model-selection/" rel="bookmark" title="Permanent Link to Model selection">Model selection</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a>, <a href='/blog/category/statistics/'>statistics</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Model-selection#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated March 06, 2013 at 04:36 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
<a href="http://matlab.cheme.cmu.edu/2011/10/01/model-selection/" >Matlab post</a>
</p>

<p>
adapted from <a href="http://www.itl.nist.gov/div898/handbook/pmd/section4/pmd44.htm" >http://www.itl.nist.gov/div898/handbook/pmd/section4/pmd44.htm</a>
</p>

<p>
In this example, we show some ways to choose which of several models fit data the best. We have data for the total pressure and temperature of a fixed amount of a gas in a tank that was measured over the course of several days. We want to select a model that relates the pressure to the gas temperature.
</p>

<p>
The data is stored in a text file download PT.txt , with the following structure:
</p>

<pre class="example">
Run          Ambient                            Fitted
 Order  Day  Temperature  Temperature  Pressure    Value    Residual
  1      1      23.820      54.749      225.066   222.920     2.146
...
</pre>

<p>
We need to read the data in, and perform a regression analysis on P vs. T. In python we start counting at 0, so we actually want columns 3 and 4.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

data = np.loadtxt(<span style="color: #228b22;">'data/PT.txt'</span>, skiprows=2)
T = data[:, 3]
P = data[:, 4]

plt.plot(T, P, <span style="color: #228b22;">'k.'</span>)
plt.xlabel(<span style="color: #228b22;">'Temperature'</span>)
plt.ylabel(<span style="color: #228b22;">'Pressure'</span>)
plt.savefig(<span style="color: #228b22;">'images/model-selection-1.png'</span>)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; [&lt;matplotlib.lines.Line2D object at 0x00000000084398D0&gt;]
&lt;matplotlib.text.Text object at 0x000000000841F6A0&gt;
&lt;matplotlib.text.Text object at 0x0000000008423DD8&gt;
</pre>

<p><img src="/img/./images/model-selection-1.png"><p>

<p>
It appears the data is roughly linear, and we know from the ideal gas law that PV = nRT, or P = nR/V*T, which says P should be linearly correlated with V. Note that the temperature data is in degC, not in K, so it is not expected that P=0 at T = 0. We will use linear algebra to compute the line coefficients. 
</p>

<div class="org-src-container">

<pre class="src src-python">A = np.vstack([T**0, T]).T
b = P

x, res, rank, s = np.linalg.lstsq(A, b)
intercept, slope = x
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'b, m ='</span>, intercept, slope

n = <span style="color: #8b0000;">len</span>(b)
k = <span style="color: #8b0000;">len</span>(x)

sigma2 = np.sum((b - np.dot(A,x))**2) / (n - k)

C = sigma2 * np.linalg.inv(np.dot(A.T, A))
se = np.sqrt(np.diag(C))

<span style="color: #8b0000;">from</span> scipy.stats.distributions <span style="color: #8b0000;">import</span>  t
alpha = 0.05

sT = t.ppf(1-alpha/2., n - k) <span style="color: #ff0000; font-weight: bold;"># student T multiplier</span>
CI = sT * se

<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'CI = '</span>,CI
<span style="color: #8b0000;">for</span> beta, ci <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(x, CI):
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'[{0} {1}]'</span>.format(beta - ci, beta + ci)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; b, m = 7.74899739238 3.93014043824
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; CI =  [ 4.76511545  0.1026405 ]
... ... [2.98388194638 12.5141128384]
[3.82749994079 4.03278093569]
</pre>

<p>
The confidence interval on the intercept is large, but it does not contain zero at the 95% confidence level.
</p>

<p>
The R^2 value accounts roughly for the fraction of variation in the data that can be described by the model. Hence, a value close to one means nearly all the variations are described by the model, except for random variations.
</p>

<div class="org-src-container">

<pre class="src src-python">ybar = np.mean(P)
SStot = np.sum((P - ybar)**2)
SSerr = np.sum((P - np.dot(A, x))**2)
R2 = 1 - SSerr/SStot
<span style="color: #8b0000;">print</span> R2
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; 0.993715411798
</pre>

<div class="org-src-container">

<pre class="src src-python">plt.figure(); plt.clf()
plt.plot(T, P, <span style="color: #228b22;">'k.'</span>, T, np.dot(A, x), <span style="color: #228b22;">'b-'</span>)
plt.xlabel(<span style="color: #228b22;">'Temperature'</span>)
plt.ylabel(<span style="color: #228b22;">'Pressure'</span>)
plt.title(<span style="color: #228b22;">'R^2 = {0:1.3f}'</span>.format(R2))
plt.savefig(<span style="color: #228b22;">'images/model-selection-2.png'</span>)
</pre>
</div>

<pre class="example">
&lt;matplotlib.figure.Figure object at 0x0000000008423860&gt;
[&lt;matplotlib.lines.Line2D object at 0x00000000085BE780&gt;, &lt;matplotlib.lines.Line2D object at 0x00000000085BE940&gt;]
&lt;matplotlib.text.Text object at 0x0000000008449898&gt;
&lt;matplotlib.text.Text object at 0x000000000844CCF8&gt;
&lt;matplotlib.text.Text object at 0x000000000844ED30&gt;
</pre>

<p><img src="/img/./images/model-selection-2.png"><p>

<p>
The fit looks good, and R^2 is near one, but is it a good model? There are a few ways to examine this. We want to make sure that there are no systematic trends in the errors between the fit and the data, and we want to make sure there are not hidden correlations with other variables. The residuals are the error between the fit and the data. The residuals should not show any patterns when plotted against any variables, and they do not in this case.
</p>

<div class="org-src-container">

<pre class="src src-python">residuals = P - np.dot(A, x)

plt.figure()

f, (ax1, ax2, ax3) = plt.subplots(3)

ax1.plot(T,residuals,<span style="color: #228b22;">'ko'</span>)
ax1.set_xlabel(<span style="color: #228b22;">'Temperature'</span>)


run_order = data[:, 0]
ax2.plot(run_order, residuals,<span style="color: #228b22;">'ko '</span>)
ax2.set_xlabel(<span style="color: #228b22;">'run order'</span>)

ambientT = data[:, 2]
ax3.plot(ambientT, residuals,<span style="color: #228b22;">'ko'</span>)
ax3.set_xlabel(<span style="color: #228b22;">'ambient temperature'</span>)

plt.tight_layout() <span style="color: #ff0000; font-weight: bold;"># make sure plots do not overlap</span>

plt.savefig(<span style="color: #228b22;">'images/model-selection-3.png'</span>)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &lt;matplotlib.figure.Figure object at 0x00000000085C21D0&gt;
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; [&lt;matplotlib.lines.Line2D object at 0x0000000008861CC0&gt;]
&lt;matplotlib.text.Text object at 0x00000000085D3A58&gt;
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; [&lt;matplotlib.lines.Line2D object at 0x0000000008861E80&gt;]
&lt;matplotlib.text.Text object at 0x00000000085EC5F8&gt;
&gt;&gt;&gt; &gt;&gt;&gt; [&lt;matplotlib.lines.Line2D object at 0x0000000008861C88&gt;]
&lt;matplotlib.text.Text object at 0x0000000008846828&gt;
</pre>

<p><img src="/img/./images/model-selection-3.png"><p>

<p>
There may be some correlations in the residuals with the run order. That could indicate an experimental source of error.
</p>

<p>
We assume all the errors are uncorrelated with each other. We can use a lag plot to assess this, where we plot residual[i] vs residual[i-1], i.e. we look for correlations between adjacent residuals. This plot should look random, with no correlations if the model is good.
</p>

<div class="org-src-container">

<pre class="src src-python">plt.figure(); plt.clf()
plt.plot(residuals[1:-1], residuals[0:-2],<span style="color: #228b22;">'ko'</span>)
plt.xlabel(<span style="color: #228b22;">'residual[i]'</span>)
plt.ylabel(<span style="color: #228b22;">'residual[i-1]'</span>)
plt.savefig(<span style="color: #228b22;">'images/model-selection-correlated-residuals.png'</span>)
</pre>
</div>

<pre class="example">
&lt;matplotlib.figure.Figure object at 0x000000000886EB00&gt;
[&lt;matplotlib.lines.Line2D object at 0x0000000008A02908&gt;]
&lt;matplotlib.text.Text object at 0x00000000089E8198&gt;
&lt;matplotlib.text.Text object at 0x00000000089EB908&gt;
</pre>

<p><img src="/img/./images/model-selection-correlated-residuals.png"><p>

<p>
It is hard to argue there is any correlation here. 
</p>

<p>
Lets consider a quadratic model instead.
</p>

<div class="org-src-container">

<pre class="src src-python">A = np.vstack([T**0, T, T**2]).T
b = P;

x, res, rank, s = np.linalg.lstsq(A, b)
<span style="color: #8b0000;">print</span> x

n = <span style="color: #8b0000;">len</span>(b)
k = <span style="color: #8b0000;">len</span>(x)

sigma2 = np.sum((b - np.dot(A,x))**2) / (n - k)

C = sigma2 * np.linalg.inv(np.dot(A.T, A))
se = np.sqrt(np.diag(C))

<span style="color: #8b0000;">from</span> scipy.stats.distributions <span style="color: #8b0000;">import</span>  t
alpha = 0.05

sT = t.ppf(1-alpha/2., n - k) <span style="color: #ff0000; font-weight: bold;"># student T multiplier</span>
CI = sT * se

<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'CI = '</span>,CI
<span style="color: #8b0000;">for</span> beta, ci <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(x, CI):
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'[{0} {1}]'</span>.format(beta - ci, beta + ci)


ybar = np.mean(P)
SStot = np.sum((P - ybar)**2)
SSerr = np.sum((P - np.dot(A,x))**2)
R2 = 1 - SSerr/SStot
<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'R^2 = {0}'</span>.format(R2)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; [  9.00353031e+00   3.86669879e+00   7.26244301e-04]
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; CI =  [  1.38030344e+01   6.62100654e-01   7.48516727e-03]
... ... [-4.79950412123 22.8065647329]
[3.20459813681 4.52879944409]
[-0.00675892296907 0.00821141157035]
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; R^2 = 0.993721969407
</pre>

<p>
You can see that the confidence interval on the constant and T^2 term includes zero. That is a good indication this additional parameter is not significant. You can see also that the R^2 value is not better than the one from a linear fit,  so adding a parameter does not increase the goodness of fit. This is an example of overfitting the data. Since the constant in this model is apparently not significant, let us consider the simplest model with a fixed intercept of zero.
</p>

<p>
Let us consider a model with intercept = 0, P = alpha*T. 
</p>

<div class="org-src-container">

<pre class="src src-python">A = np.vstack([T]).T
b = P;

x, res, rank, s = np.linalg.lstsq(A, b)

n = <span style="color: #8b0000;">len</span>(b)
k = <span style="color: #8b0000;">len</span>(x)

sigma2 = np.sum((b - np.dot(A,x))**2) / (n - k)

C = sigma2 * np.linalg.inv(np.dot(A.T, A))
se = np.sqrt(np.diag(C))

<span style="color: #8b0000;">from</span> scipy.stats.distributions <span style="color: #8b0000;">import</span>  t
alpha = 0.05

sT = t.ppf(1-alpha/2.0, n - k) <span style="color: #ff0000; font-weight: bold;"># student T multiplier</span>
CI = sT * se

<span style="color: #8b0000;">for</span> beta, ci <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(x, CI):
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'[{0} {1}]'</span>.format(beta - ci, beta + ci)

plt.figure()
plt.plot(T, P, <span style="color: #228b22;">'k. '</span>, T, np.dot(A, x))
plt.xlabel(<span style="color: #228b22;">'Temperature'</span>)
plt.ylabel(<span style="color: #228b22;">'Pressure'</span>)
plt.legend([<span style="color: #228b22;">'data'</span>, <span style="color: #228b22;">'fit'</span>])

ybar = np.mean(P)
SStot = np.sum((P - ybar)**2)
SSerr = np.sum((P - np.dot(A,x))**2)
R2 = 1 - SSerr/SStot
plt.title(<span style="color: #228b22;">'R^2 = {0:1.3f}'</span>.format(R2))
plt.savefig(<span style="color: #228b22;">'images/model-selection-no-intercept.png'</span>)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; ... ... [4.05680124495 4.12308349899]
&lt;matplotlib.figure.Figure object at 0x0000000008870BE0&gt;
[&lt;matplotlib.lines.Line2D object at 0x00000000089F4550&gt;, &lt;matplotlib.lines.Line2D object at 0x00000000089F4208&gt;]
&lt;matplotlib.text.Text object at 0x0000000008A13630&gt;
&lt;matplotlib.text.Text object at 0x0000000008A16DA0&gt;
&lt;matplotlib.legend.Legend object at 0x00000000089EFD30&gt;
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &lt;matplotlib.text.Text object at 0x000000000B26C0B8&gt;
</pre>

<p>
<p><img src="/img/./images/model-selection-no-intercept.png"><p>
The fit is visually still pretty good, and the R^2 value is only slightly worse. Let us examine the residuals again. 
</p>


<div class="org-src-container">

<pre class="src src-python">residuals = P - np.dot(A,x)

plt.figure()
plt.plot(T,residuals,<span style="color: #228b22;">'ko'</span>)
plt.xlabel(<span style="color: #228b22;">'Temperature'</span>)
plt.ylabel(<span style="color: #228b22;">'residuals'</span>)
plt.savefig(<span style="color: #228b22;">'images/model-selection-no-incpt-resid.png'</span>)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &lt;matplotlib.figure.Figure object at 0x0000000008A0F5C0&gt;
[&lt;matplotlib.lines.Line2D object at 0x000000000B29B0F0&gt;]
&lt;matplotlib.text.Text object at 0x000000000B276FD0&gt;
&lt;matplotlib.text.Text object at 0x000000000B283780&gt;
</pre>

<p><img src="/img/./images/model-selection-no-incpt-resid.png"><p>

<p>
You can see a slight trend of decreasing value of the residuals as the Temperature increases. This may indicate a deficiency in the model with no intercept. For the ideal gas law in degC: \(PV = nR(T+273)\) or \(P = nR/V*T + 273*nR/V\), so the intercept is expected to be non-zero in this case. Specifically, we expect the intercept to be 273*R*n/V. Since the molar density of a gas is pretty small, the intercept may be close to, but not equal to zero. That is why the fit still looks ok, but is not as good as letting the intercept be a fitting parameter. That is an example of the deficiency in our model.
</p>

<p>
In the end, it is hard to justify a model more complex than a line in this case. 
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Model-selection.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Model-selection#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Nonlinear-curve-fitting-by-direct-least-squares-minimization"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Nonlinear-curve-fitting-by-direct-least-squares-minimization/" rel="bookmark" title="Permanent Link to Nonlinear curve fitting by direct least squares minimization">Nonlinear curve fitting by direct least squares minimization</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting-by-direct-least-squares-minimization#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:40 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
Here is an example of fitting a nonlinear function to data by direct minimization of the summed squared error. 
</p>
<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> fmin
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

volumes = np.array([13.71, 14.82, 16.0, 17.23, 18.52])

energies = np.array([-56.29, -56.41, -56.46, -56.463,-56.41])

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">Murnaghan</span>(parameters,vol):
    <span style="color: #228b22;">'From PRB 28,5480 (1983'</span>
    E0 = parameters[0]
    B0 = parameters[1]
    BP = parameters[2]
    V0 = parameters[3]

    E = E0 + B0*vol/BP*(((V0/vol)**BP)/(BP-1)+1) - V0*B0/(BP-1.)

    <span style="color: #8b0000;">return</span> E

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">objective</span>(pars,vol):
    <span style="color: #ff0000; font-weight: bold;">#we will minimize this function</span>
    err =  energies - Murnaghan(pars,vol)
    <span style="color: #8b0000;">return</span> np.sum(err**2) <span style="color: #ff0000; font-weight: bold;">#we return the summed squared error directly</span>

x0 = [ -56., 0.54, 2., 16.5] <span style="color: #ff0000; font-weight: bold;">#initial guess of parameters</span>

plsq = fmin(objective,x0,args=(volumes,)) <span style="color: #ff0000; font-weight: bold;">#note args is a tuple</span>

<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'parameters = {0}'</span>.format(plsq)

<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
plt.plot(volumes,energies,<span style="color: #228b22;">'ro'</span>)

<span style="color: #ff0000; font-weight: bold;">#plot the fitted curve on top</span>
x = np.linspace(<span style="color: #8b0000;">min</span>(volumes),<span style="color: #8b0000;">max</span>(volumes),50)
y = Murnaghan(plsq,x)
plt.plot(x,y,<span style="color: #228b22;">'k-'</span>)
plt.xlabel(<span style="color: #228b22;">'Volume ($\AA^3$)'</span>)
plt.ylabel(<span style="color: #228b22;">'Total energy (eV)'</span>)
plt.savefig(<span style="color: #228b22;">'images/nonlinear-fitting-lsq.png'</span>)
</pre>
</div>

<pre class="example">
Optimization terminated successfully.
         Current function value: 0.000020
         Iterations: 137
         Function evaluations: 240
parameters = [-56.46932645   0.59141447   1.9044796   16.59341303]
</pre>

<p><img src="/img/./images/nonlinear-fitting-lsq.png"><p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Nonlinear-curve-fitting-by-direct-least-squares-minimization.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting-by-direct-least-squares-minimization#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Nonlinear-curve-fitting-with-confidence-intervals"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Nonlinear-curve-fitting-with-confidence-intervals/" rel="bookmark" title="Permanent Link to Nonlinear curve fitting with confidence intervals">Nonlinear curve fitting with confidence intervals</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting-with-confidence-intervals#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:41 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      




<p>
Our goal is to fit this equation to data \(y = c1 exp(-x) + c2*x\) and compute the confidence intervals on the parameters.
</p>

<p>
This is actually could be a linear regression problem, but it is convenient to illustrate the  use the nonlinear fitting routine because it makes it easy to get
confidence intervals for comparison. The basic idea is to use the covariance matrix returned from the nonlinear fitting routine to estimate the student-t corrected confidence interval. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #ff0000; font-weight: bold;"># Nonlinear curve fit with confidence interval</span>
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> curve_fit
<span style="color: #8b0000;">from</span> scipy.stats.distributions <span style="color: #8b0000;">import</span>  t

x = np.array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])
y = np.array([ 4.70192769,  4.46826356,  4.57021389,  4.29240134,  3.88155125,
               3.78382253,  3.65454727,  3.86379487,  4.16428541,  4.06079909])

<span style="color: #ff0000; font-weight: bold;"># this is the function we want to fit to our data</span>
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">func</span>(x,c0, c1):
    <span style="color: #8b0000;">return</span> c0 * np.exp(-x) + c1*x

pars, pcov = curve_fit(func, x, y, p0=[4.96, 2.11])

alpha = 0.05 <span style="color: #ff0000; font-weight: bold;"># 95% confidence interval</span>

n = <span style="color: #8b0000;">len</span>(y)    <span style="color: #ff0000; font-weight: bold;"># number of data points</span>
p = <span style="color: #8b0000;">len</span>(pars) <span style="color: #ff0000; font-weight: bold;"># number of parameters</span>

dof = <span style="color: #8b0000;">max</span>(0, n-p) <span style="color: #ff0000; font-weight: bold;"># number of degrees of freedom</span>

tval = t.ppf(1.0 - alpha / 2.0, dof) <span style="color: #ff0000; font-weight: bold;"># student-t value for the dof and confidence level</span>

<span style="color: #8b0000;">for</span> i, p,var <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(range(n), pars, np.diag(pcov)):
    sigma = var**0.5
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'c{0}: {1} [{2}  {3}]'</span>.format(i, p,
                                  p - sigma*tval,
                                  p + sigma*tval)

<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
plt.plot(x,y,<span style="color: #228b22;">'bo '</span>)
xfit = np.linspace(0,1)
yfit = func(xfit, pars[0], pars[1])
plt.plot(xfit,yfit,<span style="color: #228b22;">'b-'</span>)
plt.legend([<span style="color: #228b22;">'data'</span>,<span style="color: #228b22;">'fit'</span>],loc=<span style="color: #228b22;">'best'</span>)
plt.savefig(<span style="color: #228b22;">'images/nonlin-fit-ci.png'</span>)
</pre>
</div>

<pre class="example">
c0: 4.96713966439 [4.62674476567  5.30753456311]
c1: 2.10995112628 [1.76711622427  2.45278602828]
</pre>

<p><img src="/img/./images/nonlin-fit-ci.png"><p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Nonlinear-curve-fitting-with-confidence-intervals.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting-with-confidence-intervals#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Nonlinear-curve-fitting"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Nonlinear-curve-fitting/" rel="bookmark" title="Permanent Link to Nonlinear curve fitting">Nonlinear curve fitting</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/nonlinear-regression/'>nonlinear regression</a>, <a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:40 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
Here is a typical nonlinear function fit to data. you need to provide an initial guess. In this example we fit the Birch-Murnaghan equation of state to energy vs. volume data from density functional theory calculations.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> leastsq
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

vols = np.array([13.71, 14.82, 16.0, 17.23, 18.52])

energies = np.array([-56.29, -56.41, -56.46, -56.463, -56.41])

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">Murnaghan</span>(parameters, vol):
    <span style="color: #228b22;">'From Phys. Rev. B 28, 5480 (1983)'</span>
    E0, B0, BP, V0 = parameters

    E = E0 + B0 * vol / BP * (((V0 / vol)**BP) / (BP - 1) + 1) - V0 * B0 / (BP - 1.0)

    <span style="color: #8b0000;">return</span> E

<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">objective</span>(pars, y, x):
    <span style="color: #ff0000; font-weight: bold;">#we will minimize this function</span>
    err =  y - Murnaghan(pars, x)
    <span style="color: #8b0000;">return</span> err

x0 = [ -56.0, 0.54, 2.0, 16.5] <span style="color: #ff0000; font-weight: bold;">#initial guess of parameters</span>

plsq = leastsq(objective, x0, args=(energies, vols))

<span style="color: #8b0000;">print</span> <span style="color: #228b22;">'Fitted parameters = {0}'</span>.format(plsq[0])

<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt
plt.plot(vols,energies, <span style="color: #228b22;">'ro'</span>)

<span style="color: #ff0000; font-weight: bold;">#plot the fitted curve on top</span>
x = np.linspace(<span style="color: #8b0000;">min</span>(vols), <span style="color: #8b0000;">max</span>(vols), 50)
y = Murnaghan(plsq[0], x)
plt.plot(x, y, <span style="color: #228b22;">'k-'</span>)
plt.xlabel(<span style="color: #228b22;">'Volume'</span>)
plt.ylabel(<span style="color: #228b22;">'Energy'</span>)
plt.savefig(<span style="color: #228b22;">'images/nonlinear-curve-fitting.png'</span>)
</pre>
</div>

<pre class="example">
Fitted parameters = [-56.46839641   0.57233217   2.7407944   16.55905648]
</pre>

<p><img src="/img/./images/nonlinear-curve-fitting.png"><p>

<p>
See additional examples at \url{http://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html}.</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Nonlinear-curve-fitting.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
  





<article>
  <div class="blog_post">
    <header>
      <div id="Parameter-estimation-by-directly-minimizing-summed-squared-errors"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/02/18/Parameter-estimation-by-directly-minimizing-summed-squared-errors/" rel="bookmark" title="Permanent Link to Parameter estimation by directly minimizing summed squared errors">Parameter estimation by directly minimizing summed squared errors</a></h2>
      <p><small><span class="blog_post_date">Posted February 18, 2013 at 09:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/02/18/Parameter-estimation-by-directly-minimizing-summed-squared-errors#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated February 27, 2013 at 02:41 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
<a href="http://matlab.cheme.cmu.edu/2011/10/10/nonlinearfit_minsse-m/" >Matlab post</a>
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> matplotlib.pyplot <span style="color: #8b0000;">as</span> plt

x = np.array([0.0,       1.1,       2.3,      3.1,       4.05,      6.0])
y = np.array([0.0039,    1.2270,    5.7035,   10.6472,   18.6032,   42.3024])

plt.plot(x, y)
plt.xlabel(<span style="color: #228b22;">'x'</span>)
plt.ylabel(<span style="color: #228b22;">'y'</span>)
plt.savefig(<span style="color: #228b22;">'images/nonlin-minsse-1.png'</span>)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; [&lt;matplotlib.lines.Line2D object at 0x000000000733D898&gt;]
&lt;matplotlib.text.Text object at 0x00000000071EC5C0&gt;
&lt;matplotlib.text.Text object at 0x00000000071EED30&gt;
</pre>

<p><img src="/img/./images/nonlin-minsse-1.png"><p>

<p>
We are going to fit the function \(y = x^a\) to the data. The best \(a\) will minimize the summed squared error between the model and the fit. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">def</span> <span style="color: #8b2323;">errfunc_</span>(a):
    <span style="color: #8b0000;">return</span> np.sum((y - x**a)**2)

errfunc = np.vectorize(errfunc_)

arange = np.linspace(1, 3)
sse = errfunc(arange)

plt.figure()
plt.plot(arange, sse)
plt.xlabel(<span style="color: #228b22;">'a'</span>)
plt.ylabel(<span style="color: #228b22;">'$\Sigma (y - y_{pred})^2$'</span>)
plt.savefig(<span style="color: #228b22;">'images/nonlin-minsse-2.png'</span>)
</pre>
</div>

<pre class="example">
... &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &lt;matplotlib.figure.Figure object at 0x000000000736DBA8&gt;
[&lt;matplotlib.lines.Line2D object at 0x00000000075CBEF0&gt;]
&lt;matplotlib.text.Text object at 0x00000000076B8C18&gt;
&lt;matplotlib.text.Text object at 0x0000000007698BE0&gt;
</pre>

<p><img src="/img/./images/nonlin-minsse-2.png"><p>

<p>
Based on the graph above, you can see a minimum in the summed squared error near \(a = 2.1\). We use that as our initial guess. Since we know the answer is bounded, we use scipy.optimize.fminbound
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">from</span> scipy.optimize <span style="color: #8b0000;">import</span> fminbound

amin = fminbound(errfunc, 1.0, 3.0)

<span style="color: #8b0000;">print</span> amin

plt.figure()
plt.plot(x, y, <span style="color: #228b22;">'bo'</span>, label=<span style="color: #228b22;">'data'</span>)
plt.plot(x, x**amin, <span style="color: #228b22;">'r-'</span>, label=<span style="color: #228b22;">'fit'</span>)
plt.xlabel(<span style="color: #228b22;">'x'</span>)
plt.ylabel(<span style="color: #228b22;">'y'</span>)
plt.legend(loc=<span style="color: #228b22;">'best'</span>)
plt.savefig(<span style="color: #228b22;">'images/nonlin-minsse-3.png'</span>)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; 2.09004838933
&gt;&gt;&gt; &lt;matplotlib.figure.Figure object at 0x00000000075D8470&gt;
[&lt;matplotlib.lines.Line2D object at 0x0000000007BDFA20&gt;]
[&lt;matplotlib.lines.Line2D object at 0x0000000007BDFC18&gt;]
&lt;matplotlib.text.Text object at 0x0000000007BC6828&gt;
&lt;matplotlib.text.Text object at 0x0000000007BCAF98&gt;
&lt;matplotlib.legend.Legend object at 0x0000000007BE3128&gt;
</pre>

<p><img src="/img/./images/nonlin-minsse-3.png"><p>

<p>
We can do nonlinear fitting by directly minimizing the summed squared error between a model and data. This method lacks some of the features of other methods, notably the simple ability to get the confidence interval. However, this method is flexible and may offer more insight into how the solution depends on the parameters. </p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/02/18/Parameter-estimation-by-directly-minimizing-summed-squared-errors.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2013/02/18/Parameter-estimation-by-directly-minimizing-summed-squared-errors#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />
 <a href="../11">« Previous Page</a>
  --  
 <a href="../13">Next Page »</a>

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2018/01/27/New-publication-in-Topics-in-Catalysis/">New publication in Topics in Catalysis</a></li>
      <li><a href="/blog/2018/01/03/New-publication-in-Molecular-Simulation/">New publication in Molecular Simulation</a></li>
      <li><a href="/blog/2017/12/31/2017-in-a-nutshell-for-the-Kitchin-Research-group/">2017 in a nutshell for the Kitchin Research group</a></li>
      <li><a href="/blog/2017/11/29/Solving-an-eigenvalue-differential-equation-with-a-neural-network/">Solving an eigenvalue differential equation with a neural network</a></li>
      <li><a href="/blog/2017/11/28/Solving-ODEs-with-a-neural-network-and-autograd/">Solving ODEs with a neural network and autograd</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
        <a href="http://kitchinresearchgroup.disqus.com/latest.rss">Comments RSS Feed</a>.
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2018
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>
  <script>
  (function() {
      var links = document.getElementsByTagName('a');
      var query = '?';
      for(var i = 0; i < links.length; i++) {
          if(links[i].href.indexOf('#disqus_thread') >= 0) {
              query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
          }
      }
      document.write('<script charset="utf-8" type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/get_num_replies.js' + query + '"></' + 'script>');
  })();
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



