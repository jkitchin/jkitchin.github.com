

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Kitchin Research Group: lennardjones</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>
      <li><a href="/group.html">Group</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            
  





<article>
  <div class="blog_post">
    <header>
      <div id="Timing-Lennard-Jones-implementations-ASE-vs-autograd"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/11/20/Timing-Lennard-Jones-implementations-ASE-vs-autograd/" rel="bookmark" title="Permanent Link to Timing Lennard-Jones implementations - ASE vs autograd">Timing Lennard-Jones implementations - ASE vs autograd</a></h2>
      <p><small><span class="blog_post_date">Posted November 20, 2017 at 09:19 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/autograd/'>autograd</a>, <a href='/blog/category/lennardjones/'>lennardjones</a>, <a href='/blog/category/python/'>python</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2017/11/20/Timing-Lennard-Jones-implementations-ASE-vs-autograd#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated November 21, 2017 at 07:42 AM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgb9c2faf">1. Timing on the forces</a></li>
</ul>
</div>
</div>
<p>
In a comment on this <a href="http://kitchingroup.cheme.cmu.edu/blog/2017/11/14/Forces-by-automatic-differentiation-in-molecular-simulation/">post</a> Konrad Hinsen asked if the autograd forces on a Lennard-Jones potential would be useable in production. I wasn't sure, and was suspicious that analytical force functions would be faster. It turns out to not be so simple. In this post, I attempt to do some timing experiments for comparison. These are tricky to do right, and in a meaningful way, so I will start by explaining what is tricky and why I think the results are meaningful. 
</p>

<p>
The ASE calculators cache their results, and return the cached results after the first run. We will do these on a 13-atom icosahedron cluster.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgb9b1952"><span style="color: #0000FF;">from</span> ase.calculators.lj <span style="color: #0000FF;">import</span> LennardJones
<span style="color: #0000FF;">from</span> ase.cluster.icosahedron <span style="color: #0000FF;">import</span> Icosahedron

<span style="color: #BA36A5;">atoms</span> = Icosahedron(<span style="color: #008000;">'Ar'</span>, noshells=2, latticeconstant=3)
atoms.set_calculator(LennardJones())

<span style="color: #0000FF;">import</span> time
<span style="color: #BA36A5;">t0</span> = time.time()
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'energy: '</span>, atoms.get_potential_energy())
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">' time: '</span>, time.time() - t0)
<span style="color: #0000FF;">print</span>()

<span style="color: #BA36A5;">t0</span> = time.time()
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'energy: '</span>, atoms.get_potential_energy())
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">' time: '</span>, time.time() - t0)
<span style="color: #0000FF;">print</span>()

<span style="color: #BA36A5;">atoms.calc.results</span> = {}
<span style="color: #BA36A5;">t0</span> = time.time()
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'energy: '</span>, atoms.get_potential_energy())
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'time: '</span>, time.time() - t0)
</pre>
</div>

<pre class="example">
energy:  -1.25741774649
 time:  0.0028629302978515625

energy:  -1.25741774649
 time:  0.00078582763671875

energy:  -1.25741774649
time:  0.0031850337982177734

</pre>

<p>
Note the approximate order of magnitude reduction in elapsed time for the second call. After that, we reset the calculator results, and the time goes back up. So, we have to incorporate that into our timing. Also, in the ASE calculator, the forces are simultaneously calculated. There isn't a way to separate the calls. I am going to use the timeit feature in Ipython for the timing. I don't have a lot of control over what else is running on my machine, so I have observed some variability in the timing results. Finally, I am running these on a MacBook Air.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org23d2e9b">%%timeit
atoms.get_potential_energy()
<span style="color: #BA36A5;">atoms.calc.results</span> = {} <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">this resets it so it runs each time. Otherwise, we get cached results</span>
</pre>
</div>

<p>
1.46 ms ± 107 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</p>

<p>
That seems like a surprisingly long time. If you neglect the calculator reset, it looks about 10 times faster because the cache lookup is fast!
</p>

<p>
Let's compare that to an implementation of the Lennard-Jones potential similar to the last time. This implementation differs from <a href="http://kitchingroup.cheme.cmu.edu/blog/2017/11/14/Forces-by-automatic-differentiation-in-molecular-simulation/">the first one I blogged about</a>. This one is fully vectorized. It still does not support periodic boundary conditions though. This version may be up to 10 times faster than the previous version. I haven't tested this very well, I only assured it gives the same energy as ASE for the example in this post.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org2d00a75"><span style="color: #0000FF;">import</span> autograd.numpy <span style="color: #0000FF;">as</span> np

<span style="color: #0000FF;">def</span> <span style="color: #006699;">energy</span>(positions):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #036A07;">"Compute the energy of a Lennard-Jones system."</span>
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">sigma</span> = 1.0
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">epsilon</span> = 1.0
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">rc</span> = 3 * sigma

<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">e0</span> = 4 * epsilon * ((sigma / rc)**12 - (sigma / rc)**6)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">natoms</span> = <span style="color: #006FE0;">len</span>(positions)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">These are the pairs of indices we need to compute distances for.</span>
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">a</span>, <span style="color: #BA36A5;">b</span> = np.triu_indices(natoms, 1)

<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">d</span> = positions[a] - positions[b]
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">r2</span> = np.<span style="color: #006FE0;">sum</span>(d**2, axis=1)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">c6</span> = np.where(r2 &lt;= rc**2, (sigma**2 / r2)**3, np.zeros_like(r2))
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">energy</span> = -e0 * (c6 != 0.0).<span style="color: #006FE0;">sum</span>()
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">c12</span> = c6**2
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">energy</span> += np.<span style="color: #006FE0;">sum</span>(4 * epsilon * (c12 - c6))
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> energy

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Just to check we get the same answer</span>
<span style="color: #0000FF;">print</span>(energy(atoms.positions))
</pre>
</div>

<p>
-1.25741774649
</p>

<p>
The energy looks good. For timing, we store the positions in a variable, in case there is any lookup time, since this function only needs an array.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org7312f34"><span style="color: #BA36A5;">pos</span> = atoms.positions
</pre>
</div>

<p>

</p>

<p>
There is no caching to worry about here, we can just get the timing.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org38e167b">%%timeit
energy(pos)
</pre>
</div>

<p>
82.2 µs ± 2.85 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</p>

<p>
Wow, that is a lot faster than the ASE implementation. Score one for vectorization.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org9087076"><span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Vectorized is {0:1.1f} times faster than ASE at energy.'</span>.<span style="color: #006FE0;">format</span>(1.46e-3 / 82.5e-6))
</pre>
</div>

<pre class="example">
Vectorized is 17.7 times faster than ASE at energy.

</pre>

<p>
Yep, a fully vectorized implementation is a lot faster than the ASE version which uses loops. So far the difference has nothing to do with autograd.
</p>

<div id="outline-container-orgb9c2faf" class="outline-2">
<h2 id="orgb9c2faf"><span class="section-number-2">1</span> Timing on the forces</h2>
<div class="outline-text-2" id="text-1">
<p>
The forces are where derivatives are important, and it is a reasonable question of whether hand-coded derivatives are faster or slower than autograd derivatives. We first look at the forces from ASE. The analytical forces take about the same time as the energy, which is not surprising. The same work is done for both of them.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org689833d">np.set_printoptions(precision=3, suppress=<span style="color: #D0372D;">True</span>)
<span style="color: #0000FF;">print</span>(atoms.get_forces())
</pre>
</div>

<pre class="example">
[[-0.    -0.    -0.   ]
 [-0.296 -0.     0.183]
 [-0.296 -0.    -0.183]
 [ 0.296 -0.     0.183]
 [ 0.296 -0.    -0.183]
 [ 0.183 -0.296 -0.   ]
 [-0.183 -0.296  0.   ]
 [ 0.183  0.296 -0.   ]
 [-0.183  0.296  0.   ]
 [-0.     0.183 -0.296]
 [ 0.    -0.183 -0.296]
 [-0.     0.183  0.296]
 [ 0.    -0.183  0.296]]

</pre>

<div class="org-src-container">
<pre class="src src-ipython" id="orgcaaa884">%%timeit
atoms.get_forces()
<span style="color: #BA36A5;">atoms.calc.results</span> = {}
</pre>
</div>

<pre class="example">
1.22 ms ± 38.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)

</pre>

<p>
Here is our auto-differentiated force function.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org767b1e9"><span style="color: #0000FF;">from</span> autograd <span style="color: #0000FF;">import</span> elementwise_grad

<span style="color: #0000FF;">def</span> <span style="color: #006699;">forces</span>(pos):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">dEdR</span> = elementwise_grad(energy)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> -dEdR(pos)
</pre>
</div>

<p>
Let's just check the forces for consistency.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org777df8d"><span style="color: #0000FF;">print</span>(forces(atoms.positions))

<span style="color: #0000FF;">print</span>(np.allclose(forces(atoms.positions), atoms.get_forces()))
</pre>
</div>

<pre class="example">
[[-0.    -0.    -0.   ]
 [-0.296 -0.     0.183]
 [-0.296 -0.    -0.183]
 [ 0.296 -0.     0.183]
 [ 0.296 -0.    -0.183]
 [ 0.183 -0.296 -0.   ]
 [-0.183 -0.296  0.   ]
 [ 0.183  0.296 -0.   ]
 [-0.183  0.296  0.   ]
 [-0.     0.183 -0.296]
 [ 0.    -0.183 -0.296]
 [-0.     0.183  0.296]
 [ 0.    -0.183  0.296]]
True

</pre>

<p>
Those all look the same, so now performance for that:
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org90b4b07">%%timeit 

forces(pos)
</pre>
</div>

<pre class="example">
727 µs ± 47.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)

</pre>

<p>
This is faster than the ASE version. I suspect that it is largely because of the faster, vectorized algorithm overall. 
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org7de1cf3"><span style="color: #0000FF;">print</span>(<span style="color: #008000;">'autograd is {0:1.1f} times faster than ASE on forces.'</span>.<span style="color: #006FE0;">format</span>(1.22e-3 / 727e-6))
</pre>
</div>

<pre class="example">
autograd is 1.7 times faster than ASE on forces.

</pre>

<p>
autograd forces are consistently 2-6 times faster than the ASE implementation. It could be possible to hand-code a faster function for the forces, if it was fully vectorized. I spent a while seeing what would be required for that, and it is not obvious how to do that. Any solution that uses loops will be slower I think.
</p>

<p>
This doesn't directly answer the question of whether this can work in production. Everything is still written in Python here, which might limit the size and length of calculations you can practically do. With the right implementation though, it looks promising.
</p>
</div>
</div>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/11/20/Timing-Lennard-Jones-implementations---ASE-vs-autograd.org">org-mode source</a></p>
<p>Org-mode version = 9.1.2</p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

  <div class="after_post"><a href="http://jkitchin.github.io/blog/2017/11/20/Timing-Lennard-Jones-implementations-ASE-vs-autograd#disqus_thread">Read and Post Comments</a></div>
  <hr class="interblog" />

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2018/01/27/New-publication-in-Topics-in-Catalysis/">New publication in Topics in Catalysis</a></li>
      <li><a href="/blog/2018/01/03/New-publication-in-Molecular-Simulation/">New publication in Molecular Simulation</a></li>
      <li><a href="/blog/2017/12/31/2017-in-a-nutshell-for-the-Kitchin-Research-group/">2017 in a nutshell for the Kitchin Research group</a></li>
      <li><a href="/blog/2017/11/29/Solving-an-eigenvalue-differential-equation-with-a-neural-network/">Solving an eigenvalue differential equation with a neural network</a></li>
      <li><a href="/blog/2017/11/28/Solving-ODEs-with-a-neural-network-and-autograd/">Solving ODEs with a neural network and autograd</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
        <a href="http://kitchinresearchgroup.disqus.com/latest.rss">Comments RSS Feed</a>.
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2018
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>
  <script>
  (function() {
      var links = document.getElementsByTagName('a');
      var query = '?';
      for(var i = 0; i < links.length; i++) {
          if(links[i].href.indexOf('#disqus_thread') >= 0) {
              query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
          }
      }
      document.write('<script charset="utf-8" type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/get_num_replies.js' + query + '"></' + 'script>');
  })();
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



