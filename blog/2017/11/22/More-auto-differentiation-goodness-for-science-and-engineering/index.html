

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>More auto-differentiation goodness for science and engineering</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>
      <li><a href="/group.html">Group</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            






<article>
  <div class="blog_post">
    <header>
      <div id="More-auto-differentiation-goodness-for-science-and-engineering"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/11/22/More-auto-differentiation-goodness-for-science-and-engineering/" rel="bookmark" title="Permanent Link to More auto-differentiation goodness for science and engineering">More auto-differentiation goodness for science and engineering</a></h2>
      <p><small><span class="blog_post_date">Posted November 22, 2017 at 03:52 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/python/'>python</a>, <a href='/blog/category/autograd/'>autograd</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2017/11/22/More-auto-differentiation-goodness-for-science-and-engineering#disqus_thread">View Comments</a>
      <p><small><span class="blog_post_date">Updated November 22, 2017 at 03:55 PM</span>
      </small></p>
    </header>
    <div class="post_prose">
      



<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org8469481">1. Showing mixed partial derivatives are equal</a></li>
<li><a href="#org04c0323">2. Root finding with jacobians</a></li>
<li><a href="#org579e18e">3. Getting the pressure from a solid equation of state</a></li>
<li><a href="#org43b361c">4. Deriving activity coefficients and demonstration of the Gibbs-Duhem relation</a></li>
<li><a href="#org1626a54">5. Summary</a></li>
</ul>
</div>
</div>
<p>
In this post I continue my investigations in the use of auto-differentiation via autograd in scientific and mathematical programming. The main focus of today is using autograd to get derivatives that either have mathematical value, eg. accelerating root finding, or demonstrating mathematical rules, or scientific value, e.g. the derivative is related to a property, or illustrates some constraint.
</p>

<p>
All the code in this post relies on these imports:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">import</span> autograd.numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">from</span> autograd <span style="color: #0000FF;">import</span> grad, jacobian
</pre>
</div>

<p>

</p>

<p>
In the following sections I explore some applications in calculus, root-finding, materials and thermodynamics.
</p>

<div id="outline-container-org8469481" class="outline-2">
<h2 id="org8469481"><span class="section-number-2">1</span> Showing mixed partial derivatives are equal</h2>
<div class="outline-text-2" id="text-1">
<p>
In calculus, we know that if we have a well-behaved function \(f(x, y)\), then it should be true that \(\frac{\partial^2f}{\partial x \partial y} = \frac{\partial^2f}{\partial y \partial y}\).
</p>

<p>
Here we use autograd to compute the mixed partial derivatives and show for 10 random points that this statement is true. This doesnt' prove it for all points, of course, but it is easy to prove for any point of interest.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org8aad9b9"><span style="color: #0000FF;">def</span> <span style="color: #006699;">f</span>(x, y):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> x * y**2

<span style="color: #BA36A5;">dfdx</span> = grad(f)
<span style="color: #BA36A5;">d2fdxdy</span> = grad(dfdx, 1)

<span style="color: #BA36A5;">dfdy</span> = grad(f, 1)
<span style="color: #BA36A5;">d2fdydx</span> = grad(dfdy)

<span style="color: #BA36A5;">x</span> = np.random.rand(10)
<span style="color: #BA36A5;">y</span> = np.random.rand(10)

<span style="color: #BA36A5;">T</span> = [d2fdxdy(x1, y1) == d2fdydx(x1, y1) <span style="color: #0000FF;">for</span> x1, y1 <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">zip</span>(x, y)]

<span style="color: #0000FF;">print</span>(np.<span style="color: #006FE0;">all</span>(T))
</pre>
</div>

<p>
True
</p>
</div>
</div>

<div id="outline-container-org04c0323" class="outline-2">
<h2 id="org04c0323"><span class="section-number-2">2</span> Root finding with jacobians</h2>
<div class="outline-text-2" id="text-2">
<p>
fsolve often works fine without access to derivatives. In this example from <a href="http://people.duke.edu/~ccc14/sta-663-2016/13_Optimization.html">here</a>, we solve a set of equations with two variables, and it takes 21 iterations to reach the solution.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org37121e8"><span style="color: #0000FF;">from</span> scipy.optimize <span style="color: #0000FF;">import</span> fsolve

<span style="color: #0000FF;">def</span> <span style="color: #006699;">f</span>(x):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> np.array([x[1] - 3*x[0]*(x[0]+1)*(x[0]-1),
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span>.25*x[0]**2 + x[1]**2 - 1])


<span style="color: #BA36A5;">ans</span>, <span style="color: #BA36A5;">info</span>, <span style="color: #BA36A5;">flag</span>, <span style="color: #BA36A5;">msg</span> = fsolve(f, (0.5, 0.5), full_output=1)
<span style="color: #0000FF;">print</span>(ans)
<span style="color: #0000FF;">print</span>(info[<span style="color: #008000;">'nfev'</span>])
</pre>
</div>

<p>
[ 1.117  0.83 ]
21
</p>

<p>
If we add the jacobian, we get the same result with only 15 iterations, about 1/3 fewer iterations. If the iterations are expensive, this might save a lot of time. 
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgaa52a5d"><span style="color: #BA36A5;">df</span> = jacobian(f)
<span style="color: #BA36A5;">x0</span> = np.array([0.5, 0.5])

<span style="color: #BA36A5;">ans</span>, <span style="color: #BA36A5;">info</span>, <span style="color: #BA36A5;">flag</span>, <span style="color: #BA36A5;">msg</span>  = fsolve(f, x0, fprime=df, full_output=1)
<span style="color: #0000FF;">print</span>(ans)
<span style="color: #0000FF;">print</span>(info[<span style="color: #008000;">'nfev'</span>])
</pre>
</div>

<p>
[ 1.117  0.83 ]
15
</p>

<p>
There is a similar <a href="https://github.com/HIPS/autograd/blob/master/examples/rosenbrock.py">example</a> provided by autograd.
</p>
</div>
</div>

<div id="outline-container-org579e18e" class="outline-2">
<h2 id="org579e18e"><span class="section-number-2">3</span> Getting the pressure from a solid equation of state</h2>
<div class="outline-text-2" id="text-3">
<p>
In this <a href="http://kitchingroup.cheme.cmu.edu/blog/2013/02/18/Nonlinear-curve-fitting/">post</a> we described how to fit a solid equation of state to describe the energy of a solid under isotropic strain. Now, we can readily compute the pressure at a particular volume from the equation:
</p>

<p>
\(P = -\frac{dE}{dV}\)
</p>

<p>
We just need the derivative of this equation:
</p>

<p>
\(E = E_0+\frac{B_0 V}{B'_0}\left[\frac{(V_0/V)^{B'_0}}{B'_0-1}+1\right]-\frac{V_0 B_0}{B'_0-1}\)
</p>

<p>
or we use autograd to get it for us.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org3308535"><span style="color: #BA36A5;">E0</span>, <span style="color: #BA36A5;">B0</span>, <span style="color: #BA36A5;">BP</span>, <span style="color: #BA36A5;">V0</span> = -56.466,   0.49,    4.753,  16.573

<span style="color: #0000FF;">def</span> <span style="color: #006699;">Murnaghan</span>(vol):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">E</span> = E0 + B0 * vol / BP * (((V0 / vol)**BP) / (BP - 1.0) + 1.0) - V0 * B0 / (BP - 1.)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> E

<span style="color: #0000FF;">def</span> <span style="color: #006699;">P</span>(vol):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">dEdV</span> = grad(Murnaghan)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> -dEdV(vol) * 160.21773  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">in Gpa</span>

<span style="color: #0000FF;">print</span>(P(V0)) <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Pressure at the minimum</span>
<span style="color: #0000FF;">print</span>(P(0.99 * V0))  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Compressed</span>
</pre>
</div>

<pre class="example">
4.44693531998e-15
0.808167684691

</pre>

<p>
So it takes positive pressure to compress the system, as expected, and at the minimum the pressure is equal to zero. Seems pretty clear autograd is better than deriving the required pressure derivative.
</p>
</div>
</div>

<div id="outline-container-org43b361c" class="outline-2">
<h2 id="org43b361c"><span class="section-number-2">4</span> Deriving activity coefficients and demonstration of the Gibbs-Duhem relation</h2>
<div class="outline-text-2" id="text-4">
<p>
Thermodynamics tells us that in a binary mixture the following is true:
</p>

<p>
\(0 = x_1 \frac{d \ln \gamma_1}{dx_1} + (1 - x_1) \frac{d \ln \gamma_2}{dx_1}\)
</p>

<p>
In other words, the activity coefficients of the two species can't be independent. 
</p>

<p>
Suppose we have the <a href="https://en.wikipedia.org/wiki/Margules_activity_model">Margules model</a> for the excess free energy:
</p>

<p>
\(G^{ex}/RT = n x_1 (1 - x_1) (A_{21} x_1 + A_{12} (1 - x_1))\)
</p>

<p>
where \(n = n_1 + n_2\), and \(x_1 = n1 / n\), and \(x_2 = n_2 / n\). 
</p>

<p>
From this expression, we know:
</p>

<p>
\(\ln \gamma_1 = \frac{\partial G_{ex}/RT}{\partial n_1}\)
</p>

<p>
and
</p>

<p>
\(\ln \gamma_2 = \frac{\partial G_{ex}/RT}{\partial n_2}\)
</p>

<p>
It is also true that (the Gibbs-Duhem equation):
</p>

<p>
\(0 = x_1 \frac{d \ln \gamma_1}{d n_1} + x_2 \frac{d \ln \gamma_2}{d n_1}\)
</p>

<p>
Here we will use autograd to get these derivatives, and demonstrate the Gibbs-Duhem eqn holds for this excess Gibbs energy model.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgd986da2"><span style="color: #BA36A5;">A12</span>, <span style="color: #BA36A5;">A21</span> = 2.04, 1.5461  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Acetone/water https://en.wikipedia.org/wiki/Margules_activity_model</span>

<span style="color: #0000FF;">def</span> <span style="color: #006699;">GexRT</span>(n1, n2):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">n</span> = n1 + n2
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">x1</span> = n1 / n
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">x2</span> = n2 / n
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">return</span> n * x1 * x2 * (A21 * x1 + A12 * x2)

<span style="color: #BA36A5;">lngamma1</span> = grad(GexRT)     <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">dGex/dn1</span>
<span style="color: #BA36A5;">lngamma2</span> = grad(GexRT, 1)  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">dGex/dn2</span>

<span style="color: #BA36A5;">n1</span>, <span style="color: #BA36A5;">n2</span> = 1.0, 2.0
<span style="color: #BA36A5;">n</span> = n1 + n2
<span style="color: #BA36A5;">x1</span> = n1 / n
<span style="color: #BA36A5;">x2</span> = n2 / n

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Evaluate the activity coefficients</span>
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'AD:         '</span>,lngamma1(n1, n2), lngamma2(n1, n2))

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Compare that to these analytically derived activity coefficients</span>
<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'Analytical: '</span>, (A12 + 2 * (A21 - A12) * x1) * x2**2, (A21 + 2 * (A12 - A21) * x2) * x1**2)

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Demonstration of the Gibbs-Duhem rule</span>
<span style="color: #BA36A5;">dg1</span> = grad(lngamma1)
<span style="color: #BA36A5;">dg2</span> = grad(lngamma2)

<span style="color: #BA36A5;">n</span> = 1.0 <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Choose a basis number of moles</span>
<span style="color: #BA36A5;">x1</span> = np.linspace(0, 1)
<span style="color: #BA36A5;">x2</span> = 1 - x1
<span style="color: #BA36A5;">n1</span> = n * x1
<span style="color: #BA36A5;">n2</span> = n - n1

<span style="color: #BA36A5;">GD</span> = [_x1 * dg1(_n1, _n2) + _x2 * dg2(_n1, _n2)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #9B9B9B; background-color: #EDEDED;"> </span> <span style="color: #0000FF;">for</span> _x1, _x2, _n1, _n2 <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">zip</span>(x1, x2, n1, n2)]

<span style="color: #0000FF;">print</span>(np.allclose(GD, np.zeros(<span style="color: #006FE0;">len</span>(GD))))
</pre>
</div>

<pre class="example">
('AD:         ', 0.76032592592592585, 0.24495925925925932)
('Analytical: ', 0.760325925925926, 0.24495925925925924)
True

</pre>

<p>
That is pretty compelling. The autograd derivatives are much easier to code than the analytical solutions (which also had to be derived). You can also see that the Gibbs-Duhem equation is satisfied for this model, at least with a reasonable tolerance for the points we evaluated it at. 
</p>
</div>
</div>

<div id="outline-container-org1626a54" class="outline-2">
<h2 id="org1626a54"><span class="section-number-2">5</span> Summary</h2>
<div class="outline-text-2" id="text-5">
<p>
Today we examined four ways to use autograd in scientific or mathematical programs to replace the need to derive derivatives by hand. The main requirements for this to work are that you use the autograd.numpy module, and only the functions in it that are supported. It is possible to add your own functions (described in the <a href="https://github.com/HIPS/autograd/blob/master/docs/tutorial.md#extend-autograd-by-defining-your-own-primitives">tutorial</a>) if needed. It seems like there are a lot of opportunities for scientific programming for autograd.
</p>
</div>
</div>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/11/22/More-auto-differentiation-goodness-for-science-and-engineering.org">org-mode source</a></p>
<p>Org-mode version = 9.1.2</p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_url = "http://jkitchin.github.io/blog/2017/11/22/More-auto-differentiation-goodness-for-science-and-engineering";
</script>
<script type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/embed.js"></script>
<noscript><a href="http://kitchinresearchgroup.disqus.com/?url=ref">View the discussion thread.</a></noscript><a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2018/01/27/New-publication-in-Topics-in-Catalysis/">New publication in Topics in Catalysis</a></li>
      <li><a href="/blog/2018/01/03/New-publication-in-Molecular-Simulation/">New publication in Molecular Simulation</a></li>
      <li><a href="/blog/2017/12/31/2017-in-a-nutshell-for-the-Kitchin-Research-group/">2017 in a nutshell for the Kitchin Research group</a></li>
      <li><a href="/blog/2017/11/29/Solving-an-eigenvalue-differential-equation-with-a-neural-network/">Solving an eigenvalue differential equation with a neural network</a></li>
      <li><a href="/blog/2017/11/28/Solving-ODEs-with-a-neural-network-and-autograd/">Solving ODEs with a neural network and autograd</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
        <a href="http://kitchinresearchgroup.disqus.com/latest.rss">Comments RSS Feed</a>.
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2018
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>
  <script>
  (function() {
      var links = document.getElementsByTagName('a');
      var query = '?';
      for(var i = 0; i < links.length; i++) {
          if(links[i].href.indexOf('#disqus_thread') >= 0) {
              query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
          }
      }
      document.write('<script charset="utf-8" type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/get_num_replies.js' + query + '"></' + 'script>');
  })();
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



