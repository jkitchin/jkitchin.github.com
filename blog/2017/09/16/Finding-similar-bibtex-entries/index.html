

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Finding similar bibtex entries</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            






<article>
  <div class="blog_post">
    <header>
      <div id="Finding-similar-bibtex-entries"></div>
      <h2 class="blog_post_title"><a href="/blog/2017/09/16/Finding-similar-bibtex-entries/" rel="bookmark" title="Permanent Link to Finding similar bibtex entries">Finding similar bibtex entries</a></h2>
      <p><small><span class="blog_post_date">Posted September 16, 2017 at 10:00 AM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/similarity/'>similarity</a>, <a href='/blog/category/bibtex/'>bibtex</a></span> | tags: 
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
A common task while writing scientific papers is citing previous research. I use org-ref extensively for that, and it makes it pretty easy to find similar references, e.g. that have common authors, or common keywords. It also lets me find similar articles in Web of Science or Scopus. Suppose that I have cited a particular paper, e.g. e <a class='org-ref-reference' href="#boes-2016-neural-networ">boes-2016-neural-networ</a>, and I want to find similar references to it that are <i>already</i> in my bibtex file, and similar by <i>my definition</i>. With org-ref I can easily search by keyword or author to find similar entries, but these are limited by what I search for, and they are not sorted. Today, I will explore the first step in a recommender system that calculates similarity, and provides a sorted list of candidates with the most relevant ones first.
</p>

<p>
The idea is to calculate some measure of similarity between the title of that reference, and the titles of other references in my bibtex file, and then sort them by similarity. This is the reference I want to find similar entries for:
</p>

<p>
Boes, J. R., Groenenboom, M. C., Keith, J. A., &amp; Kitchin, J. R., Neural network and Reaxff comparison for Au properties, Int. J. Quantum Chem., 116(13), 979–987 (2016).  <a href="https://doi.org/10.1002/qua.25115">https://doi.org/10.1002/qua.25115</a>
</p>

<p>
The first thing we do is read in our bibtex file, and print a representative entry.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">import</span> bibtexparser
<span style="color: #0000FF;">from</span> bibtexparser.bparser <span style="color: #0000FF;">import</span> BibTexParser

<span style="color: #0000FF;">with</span> <span style="color: #006FE0;">open</span>(<span style="color: #008000;">'/Users/jkitchin/Dropbox/bibliography/references.bib'</span>) <span style="color: #0000FF;">as</span> bibtex_file:
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">parser</span> = BibTexParser()
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">bib_database</span> = bibtexparser.load(bibtex_file, parser=parser)
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #BA36A5;">entries</span> = bib_database.entries

<span style="color: #0000FF;">print</span>(entries[10])
</pre>
</div>

<p>
{'author': 'Jaan Aarik and Aleks Aidla and V{\\"a}ino Sammelselg and Teet\nUustare', 'title': 'Effect of Growth Conditions on Formation of \\ce{TiO_2}-{II}\nThin Films in Atomic Layer Deposition Process', 'journal': 'Journal of Crystal Growth', 'volume': '181', 'number': '3', 'pages': '259 - 264', 'year': '1997', 'doi': '10.1016/S0022-0248(97)00279-0', 'link': 'http://www.sciencedirect.com/science/article/pii/S0022024897002790', 'issn': '0022-0248', 'ENTRYTYPE': 'article', 'ID': 'aarik-1997-effec-growt'}
</p>

<p>
Each entry is a dictionary containing the fields and their values. For this exploration, I will only consider similarities between titles. The next step is we find which entry corresponds to the reference we want to find similarities to.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #BA36A5;">ids</span> = [e[<span style="color: #008000;">'ID'</span>] <span style="color: #0000FF;">for</span> e <span style="color: #0000FF;">in</span> entries]
<span style="color: #BA36A5;">i</span> = ids.index(<span style="color: #008000;">'boes-2016-neural-networ'</span>)
<span style="color: #0000FF;">print</span>(entries[i])
</pre>
</div>

<p>
{'author': 'Jacob R. Boes and Mitchell C. Groenenboom and John A. Keith\nand John R. Kitchin', 'title': 'Neural Network and {Reaxff} Comparison for {Au} Properties', 'journal': 'Int. J. Quantum Chem.', 'volume': '116', 'number': '13', 'pages': '979-987', 'year': '2016', 'doi': '10.1002/qua.25115', 'link': 'https://doi.org/10.1002/qua.25115', 'issn': '1097-461X', 'keyword': 'Kohn-Sham density functional theory, neural networks, reactive\nforce fields, potential energy surfaces, machine learning', 'ENTRYTYPE': 'article', 'ID': 'boes-2016-neural-networ'}
</p>

<p>
It is best if we make the entry we want to find similarities to the first one, so here we swap the first and i<sup>th</sup> entries.
</p>

<div class="org-src-container">
<pre class="src src-ipython">entries[0], <span style="color: #BA36A5;">entries</span>[i] = entries[i], entries[0]
</pre>
</div>

<p>
Now, we prepare the list of strings to get similarities for.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #BA36A5;">titles</span> = [e.get(<span style="color: #008000;">'title'</span>, <span style="color: #008000;">''</span>) <span style="color: #0000FF;">for</span> e <span style="color: #0000FF;">in</span> entries]
</pre>
</div>


<p>
We will use <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">term frequency–inverse document frequency</a> to get a vector that represents each title, and then use <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> as a measure of similarity. Here is the place to note that <i>I chose</i> these, and could choose other ones too. Also, it is worth noting that in this measure of similarity I did <i>not</i> choose which keywords to measure similarity on.
</p>

<p>
The functionality for this is provided by <a href="http://scikit-learn.org/stable/">sklearn</a>. It has implemented functions for the algorithms above, and in just a few lines of code you get an array of tf-idf features to analyze. The array we get from our vectorizer contains normalized vectors, so we can get the cosine similarity just from a dot product of the vectors. The first row corresponds to the similarity of the first string to all the others. I want them sorted in descending order. The argsort function returns ascending order, so we use a trick to sort the negative of the similarity score which achieves that. There are certainly more advanced treatments of the text we could use by <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes">customizing the vectorizer</a>, e.g. word stemming, but for now we neglect that.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">from</span> sklearn.feature_extraction.text <span style="color: #0000FF;">import</span> TfidfVectorizer

<span style="color: #BA36A5;">vectorizer</span> = TfidfVectorizer(stop_words=<span style="color: #008000;">'english'</span>)
<span style="color: #BA36A5;">X</span> = vectorizer.fit_transform(titles)

<span style="color: #BA36A5;">cosine_similarities</span> = (X * X.T).A[0]

<span style="color: #BA36A5;">related_docs_indices</span> = (-cosine_similarities).argsort()

<span style="color: #0000FF;">print</span>(<span style="color: #008000;">'The top 10 recommendations for {} are:\n'</span>.<span style="color: #006FE0;">format</span>(S[0]))
<span style="color: #0000FF;">for</span> i, j <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">enumerate</span>(related_docs_indices[1:11]):
<span style="color: #9B9B9B; background-color: #EDEDED;"> </span>   <span style="color: #0000FF;">print</span>(<span style="color: #008000;">'{i}. {ID}: {title}, {author}\n'</span>.<span style="color: #006FE0;">format</span>(i=i + 1, **entries[j]))
</pre>
</div>

<p>
The top 10 recommendations for Neural Network and {Reaxff} Comparison for {Au} Properties are:
</p>

<ol class="org-ol">
<li>behler-2010-neural: Neural network potential-energy surfaces for atomistic</li>
</ol>
<p>
simulations, J{\"o}rg Behler
</p>

<ol class="org-ol">
<li>boes-2017-neural-networ: Neural Network Predictions of Oxygen Interactions on a Dynamic</li>
</ol>
<p>
{Pd} Surface, Jacob R. Boes and John R. Kitchin
</p>

<ol class="org-ol">
<li>eshet-2010-ab: Ab Initio Quality Neural-Network Potential for Sodium, Hagai Eshet and Rustam Z. Khaliullin and Thomas D. K{\"u}hne</li>
</ol>
<p>
and J{\"o}rg Behler and Michele Parrinello
</p>

<ol class="org-ol">
<li>behler-2014-repres-poten: Representing Potential Energy Surfaces By High-Dimensional</li>
</ol>
<p>
Neural Network Potentials, J Behler
</p>

<ol class="org-ol">
<li>behler-2007-gener-neural: Generalized Neural-Network Representation of High-Dimensional</li>
</ol>
<p>
Potential-Energy Surfaces, J{\"o}rg Behler and Michele Parrinello
</p>

<ol class="org-ol">
<li>artrith-2012-high: High-Dimensional Neural Network Potentials for Metal Surfaces:</li>
</ol>
<p>
A Prototype Study for Copper, Nongnuch Artrith and J{\"o}rg Behler
</p>

<ol class="org-ol">
<li>behler-2015-const: Constructing High-Dimensional Neural Network Potentials: A</li>
</ol>
<p>
Tutorial Review, J{\"o}rg Behler
</p>

<ol class="org-ol">
<li>artrith-2011-high: High-Dimensional Neural-Network Potentials for Multicomponent</li>
</ol>
<p>
Systems: Applications To Zinc Oxide, Nongnuch Artrith and Tobias Morawietz and J{\"o}rg Behler
</p>

<ol class="org-ol">
<li>sosso-2012-neural-gete: Neural Network Interatomic Potential for the Phase Change</li>
</ol>
<p>
Material \ce{GeTe}, Gabriele C. Sosso and Giacomo Miceli and Sebastiano Caravati
and J{\"o}rg Behler and Marco Bernasconi
</p>

<ol class="org-ol">
<li>lorenz-2006-descr: Descriptions of Surface Chemical Reactions Using a Neural</li>
</ol>
<p>
Network Representation of the Potential-Energy Surface, S{\"o}nke Lorenz and Matthias Scheffler and Axel Gross
</p>

<p>
It is evident that this is showing other references containing the words "neural network"! I guess that is a little disappointing, since these would just as easily been narrowed down in org-ref. On the other hand, they are sorted and grouped, which would not happen in org-ref. This is a comparison of pretty short strings (just the titles), so maybe this would be much more interesting if abstracts were also included. Including authors would give a different set as well (I tried it, and got a bunch of my own references!).
</p>

<p>
I don't think it would be very difficult to get this into an Emacs selection tool, e.g. helm/ivy. Check this out:
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #0000FF;">import</span> pycse.lisp

related_docs_indices[1:6].lisp
</pre>
</div>

<p>

</p>

<p>
'(1592 1650 299 1751 103)'
</p>


<p>
That is a result that can be read directly by lisp, so we could simply write the code above as a shell script that takes an argument, and returns a list of indices to sort the candidates on. The alternative is to implement this in elisp, perhaps via a dynamic module if there is already a good C library for this. My sense is the Python libraries are more advanced in functionality.
</p>

<p>
This could have a number of other applications. Given some reference content, you could imagine finding emails that are similar to it, finding RSS entries that are similar to it, finding org headlines that are related, similar files, or similarity with any other set of strings that can be gathered, e.g. from Crossref or some other search, etc. I predict there will be more on these topics in the future!
</p>
<p>Copyright (C) 2017 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p>
<p><a href="/org/2017/09/16/Finding-similar-bibtex-entries.org">org-mode source</a></p>
<p>Org-mode version = 9.0.7</p>


    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Share on Twitter</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>


<a href="https://twitter.com/search?q=https://kitchingroup.cheme.cmu.edu/blog/2017/09/16/Finding-similar-bibtex-entries">Discuss on Twitter</a>


          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2023/12/03/New-publication-Chemical-Properties-from-Graph-Neural-Network-Predicted-Electron-Densities/">New publication - Chemical Properties from Graph Neural Network-Predicted Electron Densities</a></li>
      <li><a href="/blog/2023/09/24/New-publication-Beyond-Independent-Error-Assumptions-in-Large-GNN-Atomistic-Models/">New publication - Beyond Independent Error Assumptions in Large GNN Atomistic Models</a></li>
      <li><a href="/blog/2023/09/24/Adding-new-backends-to-hashcache/">Adding new backends to hashcache</a></li>
      <li><a href="/blog/2023/09/21/A-better-manager-for-supervising-Python-functions/">A better manager for supervising Python functions</a></li>
      <li><a href="/blog/2023/09/20/Supervising-Python-functions/">Supervising Python functions</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2023
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



