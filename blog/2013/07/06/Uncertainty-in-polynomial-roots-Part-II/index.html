

<!doctype html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Uncertainty in polynomial roots - Part II</title>
  <meta name="google-site-verification" content="CGcacJdHc2YoZyI0Vey9XRA5qwhhFDzThKJezbRFcJ4" />
  <meta name="description" content="Chemical Engineering at Carnegie Mellon University">
  <meta name="author" content="John Kitchin">
  <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
  <link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="/blog/feed/atom" />
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">

  <link rel="stylesheet" href="/css/base.css?v=1">
  <link rel="stylesheet" href="/css/grid.css?v=1">
  <link rel="stylesheet" media="handheld" href="/css/handheld.css?v=1">
  <link rel="stylesheet" href="/css/pygments_murphy.css" type="text/css" />

  <script src="/js/libs/modernizr-1.7.min.js"></script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <link rel="stylesheet" href="/themes/theme1/style.css?v=1">
<link href='http://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>

</head>
  <body>
    <div id="container" class="container container_12">
      <div id="main" role="main">
        <div id="main_block">
          <header>
<div id="header" class="header_gradient theme_font">
<table><tr><td>
    <h1><a href="/">The Kitchin Research Group</a></h1>
    <h2>Chemical Engineering at Carnegie Mellon University</h2>
</td>
<td colspan=100%><div style="float:right;width:100%;text-align:right;"> <span id='badgeCont737515' style='width:126px'><script src='http://labs.researcherid.com/mashlets?el=badgeCont737515&mashlet=badge&showTitle=false&className=a&rid=A-2363-2010'></script></span></div>
</td></tr>
</table>
</div>
  <div id="navigation" class="grid_12">

    <ul class="theme_font">
      <li><a href="/blog"
             class="">Blog</a></li>

      <li><a href="/blog/archive"
             class="">Archives</a></li>

      <li><a href="/publications.html">Publications</a></li>
      <li><a href="/group.html">Group</a></li>

      <li><a href="/research.html"
             class="">Research</a></li>

      <li><a href="/categories.html"
             class="">Categories</a></li>

      <li><a href="/about.html"
             class="">About us</a></li>

      <li><a href="/subscribe.html">Subscribe</a></li>

    </ul>
  </div>
</header>

          <div id="prose_block" class="grid_8">
            






<article>
  <div class="blog_post">
    <header>
      <div id="Uncertainty-in-polynomial-roots-Part-II"></div>
      <h2 class="blog_post_title"><a href="/blog/2013/07/06/Uncertainty-in-polynomial-roots-Part-II/" rel="bookmark" title="Permanent Link to Uncertainty in polynomial roots - Part II">Uncertainty in polynomial roots - Part II</a></h2>
      <p><small><span class="blog_post_date">Posted July 06, 2013 at 03:31 PM</span> | categories:
        <span class="blog_post_categories"><a href='/blog/category/data-analysis/'>data analysis</a>, <a href='/blog/category/uncertainty/'>uncertainty</a></span> | tags: 
        | <a href="http://jkitchin.github.io/blog/2013/07/06/Uncertainty-in-polynomial-roots-Part-II#disqus_thread">View Comments</a>
      </small></p>
    </header>
    <div class="post_prose">
      



<p>
We previously looked at uncertainty in polynomial roots where we had an analytical formula for the roots of the polynomial, and we knew the uncertainties in the polynomial parameters. It would be inconvenient to try this for a cubic polynomial, although there may be formulas for the roots. I do not know of there are general formulas for the roots of a 4<sup>th</sup> order polynomial or higher. 
</p>

<p>
Unfortunately, we cannot use the uncertainties package out of the box directly here.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

A = u.ufloat((a, sa))
B = u.ufloat((b, sb))
C = u.ufloat((c, sc))

<span style="color: #8b0000;">print</span> np.roots([A, B, C])
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "c:\Users\jkitchin\AppData\Local\Enthought\Canopy\User\lib\site-packages\numpy\lib\polynomial.py", line 218, in roots
    p = p.astype(float)
  File "c:\Users\jkitchin\AppData\Local\Enthought\Canopy\User\lib\site-packages\uncertainties\__init__.py", line 1257, in raise_error
    % (self.__class__, coercion_type))
TypeError: can't convert an affine function (&lt;class 'uncertainties.Variable'&gt;) to float; use x.nominal_value
</pre>

<p>
To make some progress, we have to understand how the <a href="https://github.com/numpy/numpy/blob/v1.7.0/numpy/lib/polynomial.py#L149">numpy.roots</a> function works. It constructs a <a href="http://en.wikipedia.org/wiki/Companion_matrix">Companion matrix</a>, and the eigenvalues of that matrix are the same as the roots of the polynomial.  
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

c0, c1, c2 = [-0.99526746, -0.011546,    1.00188999]

p = np.array([c2, c1, c0])
N = <span style="color: #8b0000;">len</span>(p)

<span style="color: #ff0000; font-weight: bold;"># we construct the companion matrix like this</span>
<span style="color: #ff0000; font-weight: bold;"># see https://github.com/numpy/numpy/blob/v1.7.0/numpy/lib/polynomial.py#L220</span>
<span style="color: #ff0000; font-weight: bold;"># for this code.</span>
<span style="color: #ff0000; font-weight: bold;"># build companion matrix and find its eigenvalues (the roots)</span>
A = np.diag(np.ones((N-2,), p.dtype), -1)
A[0, :] = -p[1:] / p[0]

<span style="color: #8b0000;">print</span> A

roots = np.linalg.eigvals(A)
<span style="color: #8b0000;">print</span> roots
</pre>
</div>

<pre class="example">
[[ 0.01152422  0.99338996]
 [ 1.          0.        ]]
[ 1.00246827 -0.99094405]
</pre>

<p>
This definition of the companion matrix is a little different than the one <a href="http://en.wikipedia.org/wiki/Companion_matrix">here</a>, but primarily in the scaling of the coefficients. That does not seem to change the eigenvalues, or the roots. 
</p>

<p>
Now, we have a path to estimate the uncertainty in the roots. Since we know the polynomial coefficients and their uncertainties from the fit, we can use Monte Carlo sampling to estimate the uncertainty in the roots. 
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np
<span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u

c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

NSAMPLES = 100000
A = np.random.normal(a, sa, (NSAMPLES, ))
B = np.random.normal(b, sb, (NSAMPLES, ))
C = np.random.normal(c, sc, (NSAMPLES, ))

roots = [[] <span style="color: #8b0000;">for</span> i <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">range</span>(NSAMPLES)]

<span style="color: #8b0000;">for</span> i <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">range</span>(NSAMPLES):
    p = np.array([A[i], B[i], C[i]])
    N = <span style="color: #8b0000;">len</span>(p)
    
    M = np.diag(np.ones((N-2,), p.dtype), -1)
    M[0, :] = -p[1:] / p[0]
    r = np.linalg.eigvals(M)
    r.sort()  <span style="color: #ff0000; font-weight: bold;"># there is no telling what order the values come out in</span>
    roots[i] = r
    
avg = np.average(roots, axis=0)
std = np.std(roots, axis=0)

<span style="color: #8b0000;">for</span> r, s <span style="color: #8b0000;">in</span> <span style="color: #8b0000;">zip</span>(avg, std):
    <span style="color: #8b0000;">print</span> <span style="color: #228b22;">'{0: f} +/- {1: f}'</span>.format(r, s)
</pre>
</div>

<pre class="example">
-0.990949 +/-  0.013435
 1.002443 +/-  0.013462
</pre>

<p>
Compared to our previous approach with the uncertainties package where we got:
</p>

<pre class="example">
: -0.990944048037+/-0.0134208013339
:  1.00246826738 +/-0.0134477390832
</pre>

<p>
the agreement is quite good! The advantage of this approach is that we do not have to know the formula for the roots of higher order polynomials to estimate the uncertainty in the roots. The downside is we have to evaluate the eigenvalues of a matrix a large number of times to get good estimates of the uncertainty. For high power polynomials this could be problematic. I do not currently see a way around this, unless it becomes possible to get the uncertainties package to propagate through the numpy.eigvals function. It is possible to <a href="http://pythonhosted.org/uncertainties/user_guide.html#making-custom-functions-accept-numbers-with-uncertainties">wrap</a> some functions with uncertainties, but so far only functions that return a single number.
</p>

<p>
There are some other potential problems with this approach.  It is assumed that the accuracy of the eigenvalue solver is much better than the uncertainty in the polynomial parameters. You have to use some judgment in using these uncertainties. We are approximating the uncertainties of a nonlinear problem. In other words, the uncertainties of the roots are not linearly dependent on the uncertainties of the polynomial coefficients.  
</p>

<p>
It is possible to <a href="http://pythonhosted.org/uncertainties/user_guide.html#making-custom-functions-accept-numbers-with-uncertainties">wrap</a> some functions with uncertainties, but so far only functions that return a single number. Here is an example of getting the n<sup>th</sup> root and its uncertainty.
</p>

<div class="org-src-container">

<pre class="src src-python"><span style="color: #8b0000;">import</span> uncertainties <span style="color: #8b0000;">as</span> u
<span style="color: #8b0000;">import</span> numpy <span style="color: #8b0000;">as</span> np

@u.wrap
<span style="color: #8b0000;">def</span> <span style="color: #8b2323;">f</span>(n=0, *P):
    <span style="color: #228b22;">''' compute the nth root of the polynomial P and the uncertainty of the root'''</span>
    p =  np.array(P)
    N = <span style="color: #8b0000;">len</span>(p)
    
    M = np.diag(np.ones((N-2,), p.dtype), -1)
    M[0, :] = -p[1:] / p[0]
    r = np.linalg.eigvals(M)
    r.sort()  <span style="color: #ff0000; font-weight: bold;"># there is no telling what order the values come out in</span>
    <span style="color: #8b0000;">return</span> r[n]

<span style="color: #ff0000; font-weight: bold;"># our polynomial coefficients and standard errors</span>
c, b, a = [-0.99526746, -0.011546,    1.00188999]
sc, sb, sa = [ 0.0249142,   0.00860025,  0.00510128]

A = u.ufloat((a, sa))
B = u.ufloat((b, sb))
C = u.ufloat((c, sc))

<span style="color: #8b0000;">for</span> result <span style="color: #8b0000;">in</span> [f(n, A, B, C) <span style="color: #8b0000;">for</span> n <span style="color: #8b0000;">in</span> [0, 1]]:
    <span style="color: #8b0000;">print</span> result
</pre>
</div>

<pre class="example">
-0.990944048037+/-0.013420800377
1.00246826738+/-0.0134477388218
</pre>

<p>
It is good to see this is the same result we got earlier, with <i>a lot less work</i> (although we do have to solve it for each root, which is a bit redundant)! It is a bit more abstract though, and requires a specific formulation of the function for the wrapper to work.
</p>
<p>Copyright (C) 2013 by John Kitchin. See the <a href="/copying.html">License</a> for information about copying.<p><p><a href="/org/2013/07/06/Uncertainty-in-polynomial-roots---Part-II.org">org-mode source</a><p>

    </div>
  </div>
</article>



<a href="https://twitter.com/share" class="twitter-share-button" data-via="johnkitchin">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_url = "http://jkitchin.github.io/blog/2013/07/06/Uncertainty-in-polynomial-roots-Part-II";
</script>
<script type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/embed.js"></script>
<noscript><a href="http://kitchinresearchgroup.disqus.com/?url=ref">View the discussion thread.</a></noscript><a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>

          </div>
          <div id="sidebar" class="grid_4">
            <aside>
<section>
<script>
  (function() {
    var cx = '002533177287215655227:l7uvu35ssbc';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</section>

<section>
    <h1 class="post_header_gradient theme_font">Twitter</h1>
    <a class="twitter-timeline" href="https://twitter.com/johnkitchin" data-widget-id="545217643582881792">Tweets by @johnkitchin</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>


  <section>
    <h1 class="post_header_gradient theme_font">Links</h1>
    <ul>
      <li><a href="https://www.continuum.io">Anaconda Python</a></li>
      <li><a href="/pycse">Pycse</a></li>
      <li><a href="/dft-book">DFT-book</a></li>
    </ul>
  </section>

  <section>
    <h1 class="post_header_gradient theme_font">Latest Posts</h1>
    <ul>
      <li><a href="/blog/2018/01/27/New-publication-in-Topics-in-Catalysis/">New publication in Topics in Catalysis</a></li>
      <li><a href="/blog/2018/01/03/New-publication-in-Molecular-Simulation/">New publication in Molecular Simulation</a></li>
      <li><a href="/blog/2017/12/31/2017-in-a-nutshell-for-the-Kitchin-Research-group/">2017 in a nutshell for the Kitchin Research group</a></li>
      <li><a href="/blog/2017/11/29/Solving-an-eigenvalue-differential-equation-with-a-neural-network/">Solving an eigenvalue differential equation with a neural network</a></li>
      <li><a href="/blog/2017/11/28/Solving-ODEs-with-a-neural-network-and-autograd/">Solving ODEs with a neural network and autograd</a></li>
    </ul>
  </section>

<section>
<h1 class="post_header_gradient theme_font">Latest GitHub Repos</h1>
  <a href="https://github.com/jkitchin">@jkitchin</a> on GitHub.
  <ul id="my-github-projects">
        <li class="loading">Status updating&#8230;</li>
  </ul>

</section>
</aside>

          </div>
          <div class="clear"></div>
        </div>
      </div>
      
<footer>
  <div id="footer" class="grid_12">
    <div class="grid_8">
      <p>
        <a href="/blog/feed/index.xml">RSS</a>
        <a href="http://kitchinresearchgroup.disqus.com/latest.rss">Comments RSS Feed</a>.
      </p>
    </div>
    <div class="grid_4" id="credits">
      <p>
        Copyright 2018
        John Kitchin
      </p>
      <p>
        Powered by <a href="http://www.blogofile.com">Blogofile</a>
      </p>
    </div>
  </div>
</footer>

    </div>
      <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/js/libs/jquery-1.5.1.min.js"%3E%3C/script%3E'))</script>
  <script src="/js/plugins.js"></script>
  <script src="/js/script.js"></script>
  <script src="/js/jquery.tweet.js"></script>  
  <script src="/js/site.js"></script>
  <!--[if lt IE 7 ]>
  <script src="js/libs/dd_belatedpng.js"></script>
  <script> DD_belatedPNG.fix('img, .png_bg');</script>
  <![endif]-->
  <script>
      var _gaq=[['_setAccount','UA-35731398-1'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.async=1;
      g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
  </script>
  <script>
  (function() {
      var links = document.getElementsByTagName('a');
      var query = '?';
      for(var i = 0; i < links.length; i++) {
          if(links[i].href.indexOf('#disqus_thread') >= 0) {
              query += 'url' + i + '=' + encodeURIComponent(links[i].href) + '&';
          }
      }
      document.write('<script charset="utf-8" type="text/javascript" src="http://disqus.com/forums/kitchinresearchgroup/get_num_replies.js' + query + '"></' + 'script>');
  })();
  </script>

  </body>
</html>






<script src="http://ajax.microsoft.com/ajax/jquery/jquery-1.4.2.min.js" type="text/javascript"></script>
<script src="/js/git.js" type="text/javascript"></script>
<script type="text/javascript">
    $(function() {
     $("#my-github-projects").loadRepositories("jkitchin");
    });
</script>



