* New publication - Uncertainty Quantification in Graph Neural Networks With    Shallow Ensembles
:PROPERTIES:
:categories: news,publication
:date:     2025/09/27 11:50:48
:updated:  2025/09/27 11:50:48
:org-url:  https://kitchingroup.cheme.cmu.edu/org/2025/09/27/New-publication---Uncertainty-Quantification-in-Graph-Neural-Networks-With-Shallow-Ensembles.org
:permalink: https://kitchingroup.cheme.cmu.edu/blog/2025/09/27/New-publication---Uncertainty-Quantification-in-Graph-Neural-Networks-With-Shallow-Ensembles/index.html
:END:

[[./schnet_uncertainty_adventure.png]]

In our latest work, we tackled a critical challenge in materials modeling: ensuring that AI models don't just make predictions, but also tell us /how confident/ they are in those predictions. When Graph Neural Networks (GNNs) encounter new, "out-of-domain" materials they haven't seen during training, their predictions can become unreliable, and it's tough to know when that's happening. So, we integrated a clever, lightweight technique called Direct Propagation of Shallow Ensembles (DPOSE) into a GNN model called SchNet. Essentially, DPOSE allows the model to estimate its own uncertainty efficiently. Our findings showed that this approach is really effective at flagging when the model is venturing into unfamiliar territory, giving us higher uncertainty for novel molecules or material structures across various datasets. While it performed well, we also learned about its limitations in distinguishing very subtle structural differences. Ultimately, this work is a step towards building more trustworthy AI for materials discovery, paving the way for smarter active learning strategies where the AI itself helps decide what new data to explore.


#+BEGIN_SRC bibtex
@article{vinchurkar-2025-uncer-quant,
  author =	 {Tirtha Vinchurkar and Kareem Abdelmaqsoud and John R Kitchin},
  title =	 {Uncertainty Quantification in Graph Neural Networks With
                  Shallow Ensembles},
  journal =	 {Machine Learning: Science and Technology},
  volume =	 {nil},
  number =	 {nil},
  pages =	 {nil},
  year =	 2025,
  doi =		 {10.1088/2632-2153/ae0bf0},
  url =		 {https://doi.org/10.1088/2632-2153/ae0bf0},
  DATE_ADDED =	 {Sat Sep 27 11:42:36 2025},
}

#+END_SRC


altmetric:10.1088/2632-2153/ae0bf0

Curious about using an LLM to interact with this paper? Check out

#+BEGIN_EXPORT html
<iframe width="560" height="315" src="https://www.youtube.com/embed/kHsbUjgCGBY?si=bejDCZJqdXTExL0J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
#+END_EXPORT
